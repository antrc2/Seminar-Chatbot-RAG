{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b281b432",
   "metadata": {},
   "source": [
    "# Mô hình hoạt động của RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4209dc35",
   "metadata": {},
   "source": [
    "![Mô hình hoạt động của RAG](415525150_261742853591748_3615540183803465017_n.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9119f3",
   "metadata": {},
   "source": [
    "# Cài thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3502474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai langchain numpy pandas faiss-cpu PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607d4f2d",
   "metadata": {},
   "source": [
    "# Import các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc12375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter # Chia nhỏ văn bản thành các đoạn\n",
    "from langchain.schema import Document # Kiểu dữ liệu \n",
    "import faiss # Cơ sở dữ liệu\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# import json\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://26.203.51.178:5555/v1\",\n",
    "    api_key=\"dont_need\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3339e92a",
   "metadata": {},
   "source": [
    "# Đọc file pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9571f46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openPdfFile(pdf_path):\n",
    "    documents = []\n",
    "    pdf_reader = PdfReader(pdf_path)\n",
    "    \n",
    "    for page_num, page in enumerate(pdf_reader.pages):\n",
    "        page_text = page.extract_text()\n",
    "        document = Document(\n",
    "              page_content=page_text,\n",
    "              metadata= {\n",
    "                    \"source\": pdf_path,\n",
    "                    \"page\": page_num,\n",
    "                    \"content\": \"\"\n",
    "              }\n",
    "        )\n",
    "        documents.append(document)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbb1956f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 0}, page_content='ANDREW NG\\nKhátKhaoHọcMáy\\nMachineLearningYearning\\nChiến lược kỹ thuật cho các kỹ sư AI\\ntrong kỷ nguyên Học Sâu\\nNhómDịchThuật\\nMachineLearningCơBản'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 1}, page_content='MỤC LỤC\\nGiới thiệu\\n1. Tại sao cần chiến lược Học Máy\\n2. Cách sử dụng cuốn sách khi làm việc nhóm\\n3. Kiến thức tiền đề và Ký hiệu\\n4. Quy mô là động lực phát triển học máy\\nPhần 1: Chuẩn bị tập phát triển và tập kiểm tra\\n5. Tập phát triển và tập kiểm tra\\n6. Tập phát triển và tập kiểm tra nên có cùng phân phối\\n7. Tập phát triển/kiểm tra cần lớn đến mức nào?\\n8. Thiết lập một phép đo đơn trị làm mục tiêu tối ư u\\n9. Phép đo để tối ưu và phép đo thỏa mãn\\n10. Xây dựng một tập phát triển và một phép đo sẽ t ăng tốc quá trình làm\\nviệc\\n11. Khi nào cần thay đổi tập phát triển/kiểm tra và  các phép đo\\n12. Điều cần nhớ: Thiết lập các tập phát triển và k iểm tra\\nPhần 2: Phân tích lỗi cơ bản\\n13. Bạn mong muốn xây dựng một hệ thống phòng chống  email rác mới.\\nNhóm của bạn có rất nhiều ý tưởng:\\n14. Phân tích lỗi: đánh giá ý tưởng dựa trên tập ph át triển\\n15. Đánh giá song song các ý tưởng trong quá trình phân tích lỗi\\n16. Dọn dẹp những mẫu bị gán nhãn nhầm trong tập ph át triển và tập kiểm\\ntra\\n17. Nếu bạn có một tập phát triển lớn, chia nó thàn h hai tập con và chỉ phân\\ntích trên một tập\\n18. Tập phát triển Eyeball và Blackbox nên lớn như thế nào?\\n19. Điều cần nhớ: Phân tích lỗi cơ bản\\nPhần 3: Độ chệch và Phương sai\\n20. Độ chệch và Phương sai: Hai nguồn lớn của lỗi\\n21. Những ví dụ về Độ chệch và Phương sai\\n22. So sánh với tỉ lệ lỗi tối ưu\\n23. Xử lý Độ chệch và Phương sai\\n24. Đánh đổi giữa Độ chệch và Phương sai\\n25. Kỹ thuật giảm độ chệch có thể tránh được\\n26. Phân tích lỗi trên tập huấn luyện\\n27. Các kỹ thuật giảm phương sai\\nPhần 4: Đồ thị quá trình học\\n28. Chẩn đoán độ chệch và phương sai: Đồ thị quá tr ình học\\n29. Vẽ đồ thị sai số huấn luyện\\n1'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 2}, page_content='30. Diễn giải đồ thị quá trình học: Độ chệch cao\\n31. Giải nghĩa các đồ thị quá trình học: Những trườ ng hợp khác\\n32. Vẽ đồ thị quá trình học\\nPhần 5: So sánh với chất lượng mức con người\\n33. Tại sao cần so sánh chất lượng mức con người?\\n34. Cách xác định chất lượng mức con người\\n35. Vượt qua chất lượng mức con người\\nPhần 6: Huấn luyện và kiểm tra trên các phân phối k hác nhau\\n36. Khi nào bạn nên huấn luyện và kiểm tra trên nhữ ng phân phối khác nhau\\n37. Làm sao để quyết định có nên sử dụng toàn bộ dữ  liệu?\\n38. Làm thế nào để quyết định có nên bao gồm dữ liệ u không nhất quán\\n39. Đánh trọng số dữ liệu\\n40. Tổng quát hóa từ tập huấn luyện đến tập phát tr iển\\n41. Xác định lỗi về độ chệch, phương sai và dữ liệu  không tương đồng\\n42. Xử lý dữ liệu không tương đồng\\n43. Tổng hợp dữ liệu nhân tạo\\nPhần 7: Gỡ lỗi các Thuật toán suy luận\\n44. Bài kiểm tra xác minh tối ưu\\n45. Dạng tổng quát của bài kiểm tra xác minh tối ưu\\n46. Ví dụ về Học tăng cường\\nPhần 8: Học sâu đầu-cuối\\n47. Sự trỗi dậy của học đầu-cuối\\n48. Những ví dụ học đầu-cuối khác\\n49. Ưu nhược điểm của học đầu-cuối\\n50. Lựa chọn các thành phần cho pipeline: Tính sẵn có của dữ liệu\\n51. Lựa chọn các thành phần cho pipeline: tính đơn giản của tác vụ\\n52. Trực tiếp học những đầu ra phức tạp\\nPhần 9: Phân tích lỗi từng phần\\n53. Phân tích lỗi từng phần\\n54. Quy lỗi cho một thành phần\\n55. Trường hợp tổng quát của việc quy lỗi\\n56. Phân tích lỗi từng phần và so sánh với chất lượ ng mức con người\\n57. Phát hiện một pipeline học máy bị lỗi\\nPhần 10: Tổng kết\\n58. Xây dựng một biệt đội siêu anh hùng - Hãy để đồ ng đội của bạn đọc điều\\nnày\\nBảng thuật ngữ Anh-Việt\\nLời Nhóm Dịch\\n2'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 3}, page_content='Giới thiệu\\n3'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 4}, page_content='1. Tại sao cần chiến lược Học Máy\\nHọc Máy là nền tảng cho hàng loạt ứng dụng quan trọ ng như tìm kiếm trang web,\\nlọc thư điện tử spam, nhận dạng giọng nói, gợi ý sả n phẩm, và nhiều ứng dụng khác\\nnữa. Nếu bạn cùng các thành viên trong nhóm đang là m một dự án học máy và rất\\nmuốn tiến triển nhanh chóng, thì quyển sách này là dành cho bạn.\\nVí dụ: Xây dựng Startup về ảnh mèo\\nGiả sử bạn xây dựng công ty khởi nghiệp cung cấp kh ông giới hạn ảnh mèo cho\\nnhững người yêu thích.\\nBạn dùng mạng nơ-ron cho hệ thống thị giác máy nhằm  phát hiện mèo trong ảnh.\\nNhưng dở một cái là thuật toán bạn dùng chưa đủ độ chính xác. Bạn đang chịu rất\\nnhiều áp lực để tăng chất lượng bộ phát hiện mèo. B ạn sẽ làm thế nào?\\nNhóm bạn có thể đưa ra rất nhiều ý tưởng như:\\nLấy thêm dữ liệu: Sưu tầm thêm nhiều ảnh mèo.\\nLấy tập huấn luyện đa dạng hơn. Ví dụ như: ảnh mèo ở vị trí độc lạ, ảnh mèo với\\nmàu sắc khác thường, ảnh mèo được chụp với cấu hình  máy ảnh khác nhau .v.v.\\nHuấn luyện thuật toán lâu hơn bằng cách chạy thêm n hiều vòng lặp hạ gradient.\\nThử nghiệm mạng nơ-ron lớn hơn với nhiều tầng/nút ẩ n/tham số hơn.\\nThử nghiệm mạng nơ-ron nhỏ hơn.\\nThử nghiệm kỹ thuật điều chuẩn -- regularization  (ví dụ như điều chuẩn L2)\\nThay đổi kiến trúc mạng nơ-ron (ví dụ: hàm kích hoạ t, số lượng nút ẩn, .v.v)\\n...\\n4'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 5}, page_content='Nếu chọn đúng một trong những hướng kể trên, có thể  bạn sẽ xây dựng nên một\\nnền tảng ảnh mèo và startup thành công. Ngược lại, nếu chọn nhầm hướng, bạn có\\nthể đánh mất cả tháng trời. Vậy phải làm như thế nà o?\\nCuốn sách này sẽ giúp bạn trả lời câu hỏi đó. Phần lớn các vấn đề về học máy đều\\ncó những dấu hiệu riêng ẩn chứa gợi ý về phương hướ ng giải quyết. Việc học để\\nphát hiện ra những dấu hiệu đó sẽ giúp bạn tiết kiệ m hàng tháng hay thậm chí hàng\\nnăm trời phát triển sản phẩm.\\n5'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 6}, page_content='2. Cách sử dụng cuốn sách khi làm việc nhóm\\nSau khi đọc xong cuốn sách này, bạn sẽ hiểu sâu hơn  về cách lựa chọn hướng giải\\nquyết kỹ thuật cho đề tài học máy.\\nNhưng có thể cộng sự chưa rõ tại sao bạn lại chọn h ướng đi như vậy. Ví dụ bạn\\nmuốn cả đội xác định và dùng một phép đo đơn trị, n hưng nếu mọi người không\\nđồng tình, thì bạn sẽ làm gì để thuyết phục họ?\\nĐó là lý do tôi chủ tâm viết những chương rất ngắn.  Bạn có thể dễ dàng thuyết phục\\nquý đồng nghiệp bằng cách chia sẻ 1-2 trang của chư ơng liên quan.\\nChỉ với một vài thay đổi nhỏ về thứ tự ưu tiên có t hể tác động lớn tới năng suất công\\nviệc của cả nhóm. Và bằng những thay đổi đó, tôi hi  vọng bạn sẽ sớm trở thành siêu\\nnhân Học Máy của cả đội!\\n6'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 7}, page_content='3. Kiến thức tiền đề và Ký hiệu\\nNếu bạn đã từng học một lớp về Học Máy, ví dụ như l ớp MOOC của tôi trên Coursera,\\nhoặc bạn có kinh nghiệm áp dụng học có giám sát thì  cuốn sách này sẽ dễ hiểu đối\\nvới bạn.\\nTôi giả định rằng bạn đã quen thuộc với học có giám sát : học một hàm ánh xạ từ x\\ntới y, sử dụng các cặp dữ liệu có nhãn (x,y). Các t huật toán học có giám sát bao gồm\\nhồi quy tuyến tính, hồi quy logistic và mạng nơ-ron . Học Máy có rất nhiều dạng tuy\\nnhiên phần lớn các giá trị thực tiễn của nó hiện na y đến từ học có giám sát.\\nTôi sẽ thường xuyên đề cập đến mạng nơ-ron (còn đượ c biết đến là \"học sâu\"). Bạn\\nchỉ cần nắm được một số khái niệm cơ bản về mạng nơ -ron là có thể hiểu được nội\\ndung cuốn sách.\\nNếu những khái niệm nêu trên còn mới với bạn thì bạ n hãy xem các video ba tuần\\nđầu tiên của khóa học Machine Learning trên Courser a tại http://ml-class.org\\n7'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 8}, page_content='4. Quy mô là động lực phát triển học máy\\nRất nhiều những ý tưởng của học sâu (mạng nơ-ron) đ ã xuất hiện từ hàng thập kỷ\\ntrước. Vậy tại sao tới bây giờ chúng mới bùng nổ nh ư vậy?\\nHai nguyên nhân chính là:\\nSự sẵn có của dữ liệu.  Ngày nay, mọi người dành nhiều thời gian hơn bên\\nnhững thiết bị số như máy tính xách tay, thiết bị d i động, .v.v. Việc này tạo ra\\nnguồn dữ liệu cực lớn dùng cho những thuật toán học  máy.\\nQuy mô năng lực tính toán.  Chỉ tới một vài năm gần đây ta mới có thể huấn\\nluyện mạng nơ-ron đủ lớn để tận dụng những bộ dữ li ệu khổng lồ này.\\nCho dù có thêm nhiều nhiều dữ liệu nữa, thường thì chất lượng của các thuật toán\\nhọc máy cổ điển, như hồi quy logistic, cũng không t ốt hơn. Nghĩa là đồ thị quá trình\\nhọc chững lại và thuật toán ngừng cải thiện ngay cả  khi có thêm dữ liệu:\\nNhư thể thuật toán cổ điển không biết xử lý thế nào  với tất cả lượng dữ liệu ta đang\\ncó.\\nNếu bạn huấn luyện một mạng nơ-ron nhỏ cho cùng một  tác vụ học có giám sát,\\nbạn có thể đạt chất lượng cao hơn một chút:\\n8'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 9}, page_content='\"Mạng neural nhỏ\" ở đây có nghĩa là mạng nơ-ron với  ít nút ẩn/tầng/tham số. Sau\\ncùng, bạn có thể cải thiện chất lượng thêm nữa nếu dùng các mạng nơ-ron lớn hơn\\n[1]:\\nNhư vậy bạn đạt được chất lượng tốt nhất khi (i) hu ấn luyện mạng nơ-ron rất lớn --\\ntương ứng với đường chất lượng màu xanh lục và (ii)  có lượng dữ liệu lớn.\\nNhiều chi tiết khác như kiến trúc mạng nơ-ron cũng rất quan trọng, và có nhiều phát\\nkiến trong lĩnh vực này. Tuy nhiên, một trong những  cách đáng tin cậy hơn để tăng\\nchất lượng thuật toán vẫn là (i) huấn luyện mạng lớ n hơn và (ii) lấy thêm dữ liệu.\\nCHÚ THÍCH:\\n[1] Mặc dù hình vẽ thể hiện mạng nơ-ron cho kết quả  tốt hơn với tập dữ liệu nhỏ,\\nhiện tượng này ít nhất quán so với việc mạng nơ-ron  hoạt động tốt với dữ liệu lớn.\\nVới dữ liệu nhỏ, chất lượng thuật toán cổ điển có t hể tốt hoặc kém hơn mạng nơ-ron\\nvà phụ thuộc vào các đặc trưng thủ công. Nếu ta chỉ  có 20 mẫu huấn luyện thì việc\\ndùng hồi quy logistic hay mạng nơ-ron không khác bi ệt nhiều; chọn khéo các đặc\\ntrưng thủ công sẽ giúp ích nhiều hơn so với việc ch ọn thuật toán. Còn nếu có một\\ntriệu mẫu, thì tôi sẽ chọn dùng mạng nơ-ron.\\n9'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 10}, page_content='Để đạt được (i) và (ii) là một quá trình đặc biệt p hức tạp. Vấn đề này sẽ được thảo\\nluận đầy đủ và chi tiết trong cuốn sách này. T a sẽ bắt đầu với các chiến lược thông\\nthường và hữu ích cho cả thuật toán truyền thống lẫ n mạng nơ-ron, từ đó hình thành\\ncác chiến lược tân tiến nhất để xây dựng các hệ thố ng học sâu.\\n10'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 11}, page_content='Phần 1: Chuẩn bị tập phát\\ntriển và tập kiểm tra\\n11'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 12}, page_content='5. Tập phát triển và tập kiểm tra\\nTrở lại với ví dụ bức ảnh mèo ở phần trước: khi bạn  có một ứng dụng di động, và\\nngười dùng tải rất nhiều loại ảnh khác nhau lên ứng  dụng của bạn. Bạn muốn tự\\nđộng tìm ra đâu là các bức ảnh mèo.\\nNhóm của bạn xây dựng một tập huấn luyện lớn bằng c ách tải các bức ảnh mèo\\n(các mẫu dương) và các bức ảnh không phải mèo (các mẫu âm) từ nhiều website\\nkhác nhau. Tập dữ liệu này sau đó được chia 70%/30%  thành tập huấn luyện và tập\\nkiểm tra. Sử dụng tập dữ liệu này, bạn tạo ra một b ộ phát hiện mèo hoạt động tốt ở\\ncả tập huấn luyện và tập kiểm tra.\\nTuy nhiên, khi triển khai bộ phát hiện mèo này lên ứng dụng di động của bạn, bạn\\nphát hiện ra chất lượng rất tệ!\\nĐiều gì đã xảy ra?\\nBạn nhận ra rằng các bức ảnh được người dùng tải lê n có những tính chất khác so\\nvới những bức ảnh trên mạng mà bạn dùng để xây dựng  tập huấn luyện: các bức\\nảnh được chụp bằng điện thoại có xu hướng có độ phâ n giải thấp hơn, bị nhòe (mờ)\\nhoặc tối hơn. Do tập huấn luyện và tập kiểm tra của  bạn được tạo lên từ ảnh trên\\nmạng, nó không thể được sử dụng để khái quát tốt ch o tính chất của phân phối mà\\nbạn nhắm đến: ảnh chụp từ điện thoại.\\nTrước kỷ nguyên big data, có một nguyên tắc chung t rong học máy là chia ngẫu\\nnhiên tập huấn luyện và kiểm tra theo tỉ lệ 70%/30% . Tuy có thể dùng cách chia\\nnày, nhưng đây không phải là một ý hay vì ngày càng  có nhiều ứng dụng với phân\\nphối của tập huấn luyện (ảnh trên mạng trong ví dụ trên đây) khác phân phối mà\\nbạn thực sự quan tâm (ảnh chụp từ điện thoại).\\n12'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 13}, page_content='Chúng ta thường định nghĩa như sau:\\nTập huấn luyện  — Là tập dữ liệu để chạy thuật toán học.\\nTập phát triển  — Là tập dữ liệu được dùng để hiệu chỉnh các tham s ố, lựa chọn\\nđặc trưng và quyết định các thay đổi liên quan đến thuật toán học. Đôi khi, nó\\ncòn được gọi là tập kiểm định chéo.\\nTập kiểm tra  — Là tập dữ liệu dùng để đánh giá chất lượng của t huật toán học,\\nnhưng không được dùng để quyết định các thay đổi li ên quan đến thuật toán học\\nhay các tham số.\\nSau khi định nghĩa tập phát triển và tập kiểm tra, nhóm của bạn có thể thử nhiều ý\\ntưởng khác nhau, ví dụ như các tham số khác nhau ch o thuật toán học, để tìm ra ý\\ntưởng tốt nhất. Tập phát triển và tập kiểm tra cho phép nhóm của bạn có thể đánh\\ngiá khả năng hoạt động của thuật toán một cách nhan h chóng.\\nNói cách khác, mục đích của tập phát triển và tập kiểm tra là hướng  nhóm\\ncủa bạn tới những thay đổi quan trọng nhất có thể là m để cải thiện trong\\nhệ thống học máy .\\nVì vậy, bạn nên làm những điều sau đây:\\nLựa chọn tập phát triển và tập kiểm tra để phản ánh  đúng dữ liệu bạn sẽ gặp phải\\ntrong tương lai và muốn hoạt động tốt trên nó.\\nNói cách khác, tập kiểm tra không nên chỉ đơn thuần  là 30% dữ liệu hiện có, đặc\\nbiệt là khi dữ liệu tương lai (ảnh chụp từ điện tho ại) về bản chất sẽ khác với dữ liệu\\ntrong tập huấn luyện (ảnh từ trên mạng).\\nKhi ứng dụng di động của bạn chưa được triển khai t hì có thể bạn chưa có người\\ndùng nào cả, nên việc có thể có được dữ liệu phản á nh chính xác dữ liệu tương lai là\\nrất khó. Nhưng bạn vẫn có thể thử làm gần giống dữ liệu đó. Ví dụ, bạn có thể nhờ\\nbạn bè chụp những bức ảnh mèo bằng điện thoại và gử i cho bạn. Một khi ứng dụng\\nđược triển khai, bạn có thể cập nhật tập phát triển /kiểm tra bằng dữ liệu người dùng\\nthực tế.\\nNếu bạn thực sự không có cách nào để có được dữ liệ u gần giống với dữ liệu tương\\nlai, có lẽ bạn có thể bắt đầu bằng việc sử dụng ảnh  từ những trang web. Nhưng bạn\\nnên nhận thức được nguy cơ việc này dẫn đến một hệ thống không có khả năng khái\\nquát hóa tốt.\\nVấn đề này đòi hỏi khả năng phán đoán để quyết định  cần phải đầu tư bao nhiêu\\ncho việc xây dựng tập phát triển và tập kiểm tra. T uy nhiên đừng giả định phân phối\\ncủa tập huấn luyện giống phân phối của tập kiểm tra . Hãy cố chọn ra những mẫu\\nkiểm tra phản ánh điều mà bạn thực sự muốn thực hiệ n tốt, hơn là bất kì dữ liệu nào\\nbạn tình cờ có được cho việc huấn luyện.\\n13'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 14}, page_content='6. Tập phát triển và tập kiểm tra nên có cùng\\nphân phối\\nBạn có thể chia tập dữ liệu của ứng dụng ảnh mèo dự a theo bốn thị trường lớn nhất:\\n(i) Hoa Kỳ, (ii) Trung Quốc, (iii) Ấn Độ, và (iv) K hu vực khác. Chúng ta có thể lấy dữ\\nliệu từ Hoa Kỳ và Ấn Độ làm tập phát triển trong kh i lấy Trung Quốc và Khu vực khác\\nlàm tập kiểm tra. Nói cách khác, liệu việc chọn ngẫ u nhiên dữ liệu ảnh từ hai trong\\nbốn khu vực trên làm tập phát triển và hai khu vực còn lại làm tập kiểm tra có đúng\\nhay không?\\nMột khi định nghĩa được tập phát triển và tập kiểm tra, nhóm của bạn sẽ tập trung\\ncải thiện chất lượng trên tập phát triển. Bởi vậy, tập phát triển cần phản ánh tác vụ\\nbạn muốn cải thiện nhất đó là: hoạt động tốt trên k hông chỉ hai mà cả bốn thị\\ntrường.\\nCó một vấn đề nữa với việc tập phát triển và tập ki ểm tra có phân phối khác nhau:\\nCó khả năng nhóm của bạn sẽ xây dựng một thuật toán  nào đó hoạt động tốt trên\\ntập phát triển nhưng lại kém trên tập kiểm tra. Tôi  đã từng thấy việc này dẫn đến\\nnhững hệ quả gây thất vọng và lãng phí công sức. Hã y cố gắng tránh để điều này\\nxảy ra.\\nVí dụ, nhóm của bạn phát triển một hệ thống hoạt độ ng tốt trên tập phát triển\\nnhưng kém trên tập kiểm tra. Nếu tập phát triển và tập kiểm tra có cùng một phân\\nphối, thì bạn có thể xác định ngay vấn đề: Mô hình của bạn đã quá khớp ( overfit )\\ntập phát triển. Cách xử lý hiển nhiên nhất đó là bổ  sung thêm dữ liệu cho tập phát\\ntriển.\\nNhưng nếu tập phát triển và tập kiểm tra có phân ph ối khác nhau, thì việc xác định\\nvấn đề sẽ phức tạp hơn. Rất nhiều vấn đề có thể xảy  ra như:\\n1. Bạn đã quá khớp tập phát triển.\\n2. Tập kiểm tra khó hơn tập phát triển. Vì thế thuậ t toán của bạn có thể đã hoạt\\nđộng tốt hết mức có thể và không thể có thiện thêm nhiều nữa.\\n3. Tập kiểm tra không nhất thiết khó hơn, nhưng lại  khác biệt so với tập phát triển.\\nDo đó, việc thuật toán hoạt động tốt trên tập phát triển và kém trên tập kiểm tra\\nlà dễ hiểu. Trong trường hợp này, bỏ quá nhiều công  sức cố gắng cải thiện chất\\nlượng trên tập phát triển có thể trở nên vô nghĩa.\\n14'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 15}, page_content='Làm việc với các ứng dụng học máy vốn dĩ đã khó. Vi ệc không nhất quán giữa tập\\nphát triển và kiểm tra khiến bạn càng khó chắc chắn  về \"liệu cải thiện chất lượng\\ntrên tập phát triển có đồng nghĩa với tăng chất lượ ng trên tập kiểm tra hay không?\".\\nViệc không đồng nhất giữa tập phát triển và tập kiể m tra khiến việc xác định những\\nkỹ thuật giúp cải tiến chất lượng khó khăn hơn từ đ ó khó xắp xếp thứ tự ưu tiên giữa\\ncác tác vụ.\\nNếu bạn đang làm việc với một bài toán đánh giá xếp  hạng của bên thứ ba, họ có\\nthể đã chỉ định tập phát triển và tập kiểm tra có p hân phối khác nhau. So với bài\\ntoán có tập phát triển và tập kiểm tra có cùng một phân phối, thì chất lượng thuật\\ntoán của bạn trên bài toán đánh giá xếp hạng ở trên  phụ thuộc nhiều vào may mắn\\nhơn là kỹ năng. Việc phát triển thuật toán học mà đ ược huấn luyện trên một phân\\nphối này mà có thể khái quát hóa tốt trên một phân phối khác là một chủ đề nghiên\\ncứu quan trọng. Tuy nhiên, nếu mục tiêu của bạn là cải tiến một ứng dụng học máy\\ncụ thể thay vì làm nghiên cứu, thì tôi khuyên bạn c họn tập phát triển và tập kiểm tra\\ncó cùng một phân phối. Điều này sẽ khiến nhóm của b ạn làm việc hiệu quả hơn.\\n15'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 16}, page_content='7. Tập phát triển/kiểm tra cần lớn đến mức nào?\\nTập phát triển phải đủ lớn để nhận ra sự khác biệt giữa các thuật toán bạn đang thử\\nnghiệm. Ví dụ, nếu bộ phân loại A có độ chính xác 9 0,0% và bộ phân loại B có độ\\nchính xác 90,1%, thì một tập phát triển có 100 mẫu sẽ không thể phát hiện sự khác\\nbiệt 0,1% này. So với các bài toán học máy khác mà tôi đã thấy, một tập phát triển\\nchỉ với 100 mẫu là nhỏ. Các tập phát triển thường c ó từ 1.000 tới 10.000 mẫu. Với\\n10.000 mẫu, nhiều khả năng bạn sẽ thấy được mức cải  thiện 0,1%. [2]\\nTrong các ứng dụng quan trọng và đã đã đưa vào khai  thác -- ví dụ như quảng cáo,\\ntìm kiếm trên web và gợi ý sản phẩm -- tôi đã thấy nhiều nhóm rất muốn cải thiện\\nchất lượng thuật toán dù chỉ là 0,01%, vì nó có ảnh  hưởng trực tiếp đến lợi nhuận\\ncủa công ty. Trong trường hợp này, tập phát triển c ó thể lớn hơn 10.000 mẫu rất\\nnhiều để có thể phát hiện ra những cải tiến thậm ch í nhỏ hơn.\\nVậy còn kích thước của tập kiểm tra thì sao? Nó cần  đủ lớn để mang lại độ tin cậy\\ncao về chất lượng tổng thể của hệ thống. Một công t hức thực nghiệm phổ biến là sử\\ndụng 30% dữ liệu làm tập kiểm tra. Cách làm này hiệ u quả với những tập dữ liệu với\\nlượng mẫu khiêm tốn từ 100 tới 10.000 mẫu. Tuy nhiê n, trong kỷ nguyên big data\\nvới những bài toán học máy đôi khi có nhiều hơn một  tỷ mẫu, tỉ lệ dữ liệu giữa tập\\nphất triển và tập kiểm tra đã giảm xuống đáng kể, m ặc dù số lượng mẫu trong hai\\ntập này vẫn tăng lên. Thực sự không cần có tập phát  triển/kiểm tra lớn quá mức để\\nđánh giá chất lượng của các thuật toán.\\nCHÚ THÍCH:\\n[2] Trên lý thuyết, ta cũng có thể kiểm tra xem một  thay đổi trong thuật toán có tạo\\nra sự khác biệt đáng kể về mặt thống kê trên tập ph át triển hay không. Trong thực\\ntế, hầu hết mọi người đều không quan tâm đến điều n ày (trừ khi họ muốn công bố\\ncác các bài báo khoa học). Tôi thường thấy các bài kiểm định thống kê không mấy\\nhữu ích trong việc đánh giá tiến độ phát triển.\\n16'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 17}, page_content='8. Thiết lập một phép đo đơn trị làm mục tiêu\\ntối ưu\\nĐộ chính xác trong phân loại là ví dụ của phép đo đơn trị  -- phép đo được biểu\\ndiễn bằng chỉ một con số. Khi chạy bộ phân loại trê n một tập phát triển (hoặc tập\\nkiểm tra), độ chính xác được tính bằng số mẫu được phân loại đúng trên tổng số\\nmẫu trong tập đó. Theo phép đo này, nếu độ chính xá c của bộ phân loại A là 97% và\\ncủa bộ phân loại B là 90% thì ta kết luận rằng bộ p hân loại A cho kết quả tốt hơn.\\nNgược lại, Precision và Recall[3] không phải là một  phép đo đơn trị: chúng đưa ra hai\\nchỉ số để đánh giá bộ phân loại. Việc so sánh các t huật toán với nhau sẽ trở nên khó\\nhơn với những phép đo đa trị -- những phép đo được biểu diễn bằng nhiều hơn một\\nsố. Giả sử thuật toán trả về kết quả như sau:\\nỞ đây, không bộ phân loại nào tốt hơn một cách rõ r àng, vì vậy dựa vào kết quả\\ntrên ta không thể ngay lập tức chọn ra một bộ phân loại tốt hơn.\\nBộ Phân Loại Precision Recall\\nA 95% 90%\\nB 98% 85%\\nTrong quá trình phát triển, nhóm bạn sẽ thử rất nhi ều ý tưởng liên quan đến cấu\\ntrúc thuật toán, tham số mô hình, lựa chọn các đặc trưng, v.v.. Việc có một phép đo\\nđơn trị  như độ chính xác sẽ giúp xếp hạng các mô mình dựa theo những chất lượng\\ntrả về qua phép đo đó, từ đó nhanh chóng quyết định  mô hình nào hoạt động tốt\\nnhất.\\nNếu bạn thực sự quan tâm đến cả Precision lẫn Recal l. Tôi gợi ý sử dụng một trong\\nnhững cách tiêu chuẩn để kết hợp các chỉ số đó thàn h một chỉ số duy nhất. Ví dụ, có\\nthể lấy giá trị trung bình của Precision và Recall rồi thu về một phép đo đơn trị. Hoặc\\nthay vào đó, bạn có thể tính \"chỉ số F1\", một biến thể của trung bình cộng và hoạt\\nđộng tốt hơn việc chỉ lấy giá trị trung bình.\\nViệc có một phép đo đơn trị sẽ giúp tăng tốc khả nă ng đưa ra quyết định của bạn\\nkhi bạn phải lựa chọn một trong số lượng lớn các bộ  phân loại. Phép đo đơn trị đưa\\nra một thứ hạng ưu tiên rõ ràng giữa những thuật to án đó, tạo ra một đường hướng\\nrõ ràng để phát triển.\\nBộ Phân Loại Precision Recall Chỉ số F1\\nA 95% 90% 92.4%\\nB 98% 85% 91.0%\\nMột ví dụ cuối cùng, giả sử bạn đang theo dõi riêng  biệt độ chính xác của bộ phân\\nloại mèo trong bốn thị trường trọng điểm: (i) Mỹ, ( ii) Trung Quốc, (iii) Ấn Độ, và (iv)\\nnhững nước khác. Bạn sẽ thu về bốn phép đo. Bằng cá ch lấy giá trị trung bình hoặc\\ngiá trị trung bình có trọng số của bốn chỉ số này, bạn sẽ thu được một phép đo đơn\\n17'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 18}, page_content='trị. Tính toán giá trị trung bình hoặc giá trị trun g bình có trọng số là một trong những\\ncách phổ biển nhất để kết hợp nhiều phép đo thành m ột.\\nCHÚ THÍCH:\\n[3] Precision của một bộ phân loại mèo là tỉ lệ chí nh xác trong số ảnh được phân loại\\n(là mèo) trong tập phát triển (hoặc tập kiểm tra). Trong khi đó Recall là tỉ lệ của số\\nảnh mèo ở trong tập phát triển (hoặc tập kiểm tra) được phân loại chính xác (là\\nmèo). Thường có một sự đánh đổi giữa việc có chỉ số  precision cao và chỉ số recall\\ncao.\\n[4] Nếu bạn muốn đọc thêm về chỉ số F1, xem\\nhttps://en.wikipedia.org/wiki/F1_score . Chỉ số F1 là \"trung bình điều hoà\" của\\nPrecision và Recall, được tính bằng 2/((1/Precision ) + (1/Recall))\\n18'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 19}, page_content='9. Phép đo để tối ưu và phép đo thỏa mãn\\nĐây là một cách khác để kết hợp nhiều phép đánh giá .\\nGiả sử bạn quan tâm đến cả độ chính xác lẫn thời gi an chạy của một thuật toán học.\\nBạn cần phải chọn trong ba bộ phân loại sau:\\nBộ phân loại Độ chính xác Thời gian chạy\\nA 90% 80ms\\nB 92% 95ms\\nC 95% 1,500ms\\nViệc tạo ra một phép đo đơn trị bằng cách gộp độ ch ính xác và thời gian chạy vào\\ntrong cùng một công thức khá là gượng ép, chẳng hạn :\\nĐộ chính xác - 0.5*(Thời gian chạy)\\nThay vào đó, bạn có thể: Trước hết, hãy định nghĩa thời gian chạy như thế nào là\\n\"chấp nhận được\" - ví dụ mức dưới 100ms. Sau đó hãy  cực đại hóa độ chính xác, với\\nràng buộc là bộ phân loại vẫn đảm bảo yêu cầu về th ời gian chạy. Ở đây, thời gian\\nchạy là một \"phép đo thỏa mãn\" —- bộ phân loại chỉ cần \"đủ tốt\" trên thang đo này,\\ntức chỉ tốn tối đa 100ms để chạy xong. Độ chính xác  mới là \"phép đo để tối ưu\".\\nNếu bạn phải cân bằng giữa N tiêu chí khác nhau, ví  dụ như kích thước ﬁle nhị phân\\ncủa mô hình (điều này quan trọng với các ứng dụng d i động vì người dùng không\\nmuốn tải các ứng dụng có kích thước lớn), thời gian  chạy, và độ chính xác, bạn có\\nthể cân nhắc đặt N-1 trong số đó làm các phép đo cầ n \"thỏa mãn\". Tức là bạn chỉ\\ncần yêu cầu chúng đạt tới một giá trị xác định. Sau  đó coi tiêu chí còn lại là phép đo\\nđể \"tối ưu\". Ví dụ như đặt mức ngưỡng chấp nhận đượ c cho kích thước ﬁle nhị phân\\nvà thời gian chạy, sau đó tối ưu độ chính xác mà vẫ n thỏa mãn các điều kiện các\\nràng buộc trên.\\nVí dụ cuối cùng, giả sử bạn cần xây dựng một thiết bị phần cứng có microphone để\\nnghe người dùng nói một từ \"đánh thức\" đặc biệt nào  đó để đánh thức hệ thống. Ví\\ndụ về từ đánh thức có: Amazon Echo với \"Alexa\"; App le Siri với \"Hey Siri\"; Android\\nvới \"Hey Google\" hay các ứng dụng của Baidu với \"He llo Baidu\". Bạn quan tâm đến\\ncả tần suất dương tính giả (hay báo động nhầm) -- t ần suất mà hệ thống thức dậy\\nkhi không ai nói cụm đánh thức -- cũng như tần suất  âm tính giả (hay bỏ sót) -- tần\\nsuất hệ thống không thức dậy khi có người nói cụm đ ánh thức. Một mục tiêu khả dĩ\\ncho hệ thống này là tối thiểu hóa tần suất âm tính giả (phép đo để tối ưu), với điều\\nkiện chỉ có tối đa một báo động nhầm cho mỗi 24 giờ  hoạt động (phép đo thỏa\\nmãn).\\nMột khi nhóm của bạn đã thống nhất phép đánh giá nà o cần được tối ưu, cả nhóm\\nsẽ đạt tiến độ nhanh hơn.\\n19'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 20}, page_content='10. Xây dựng một tập phát triển và một phép\\nđo sẽ tăng tốc quá trình làm việc\\nThật sự rất khó để biết trước phương án tiếp cận nà o là tốt nhất cho một vấn đề\\nmới. Kể cả những nhà nghiên cứu học máy dày dặn kin h nghiệm cũng thường thử\\nnghiệm cả chục ý tưởng mới khám phá ra một hướng đi  thoả đáng. Khi xây dựng\\nmột hệ thống học máy, tôi thường:\\n1. Bắt đầu bằng một vài ý tưởng  về cách xây dựng hệ thống đó.\\n2. Hiện thực hóa ý tưởng dưới dạng mã nguồn.\\n3. Tiến hành một thí nghiệm  để đo mức hiệu quả của ý tưởng. (Thường thì những ý\\ntưởng đầu tiên của tôi sẽ không hoạt động!) Học đượ c từ những kết quả đó, tôi\\nquay lại thử nghiệm thêm những ý tưởng mới, và cứ t hế lặp lại cả quy trình.\\nĐây là một quy trình lặp đi lặp lại. Bạn thực hiện vòng lặp này càng nhanh thì tốc độ\\ncải tiến kết quả càng cao. Đó là lý do tại sao có t ập phát triển/thử nghiệm và một\\nphép đo là rất quan trọng: Việc đánh giá chất lượng  của mỗi ý tưởng trên tập phát\\ntriển giúp ta xác định được liệu mình có đang đi đú ng hướng.\\nNgược lại, giả sử bạn không có một tập phát triển v à phép đo nào cụ thể. Như vậy\\nmỗi khi nhóm của bạn phát triển một bộ phân loại mè o mới, bạn sẽ lại phải tích hợp\\nnó vào ứng dụng, và thử nghiệm ứng dụng đó một vài tiếng để kiểm tra liệu bộ phân\\nloại mới có tốt hơn hay không. Như vậy sẽ cực kì ch ậm! Đồng thời, nhóm của bạn sẽ\\nrất khó nhận ra sự khác biệt nếu độ chính xác chỉ c ải thiện từ 95.0% lên 95.1%, bạn\\nsẽ không thể nhận ra những cải tiến 0.1% đó chỉ qua  việc dùng thử ứng dụng. Thế\\nnhưng, phần lớn những cải tiến đến từ việc tích lũy  nhiều bước cải thiện 0.1% này.\\nViệc có một tập phát triển và phép đo cho phép bạn nhanh chóng phát hiện ra ý\\ntưởng nào đang đem lại những cải tiến nhỏ (hoặc lớn ) và giúp bạn ra quyết định ý\\ntưởng nào cần cải thiện thêm hoặc loại bỏ.\\n20'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 21}, page_content='11. Khi nào cần thay đổi tập phát triển/kiểm tra\\nvà các phép đo\\nKhi bắt đầu một dự án, tôi luôn cố gắng chọn tập ph át triển/kiểm tra thật nhanh để\\ntạo một mục tiêu rõ ràng cho cả nhóm.\\nTôi thường yêu cầu các nhóm của tôi xác định tập ph át triển/kiểm tra và một phép\\nđo ban đầu hiếm khi lâu hơn một tuần. Tốt hơn hết l à có được tập phát triển/kiểm\\ntra và phép đánh giá đơn trị, dù là chưa hoàn hảo đ ể bắt đầu nhanh chóng, hơn là\\nsuy nghĩ quá nhiều về chúng. Tuy nhiên, thời hạn mộ t tuần không áp dụng với các\\nứng dụng đã phát triển. Ví dụ, chống thư rác là một  ứng dụng học sâu đã phát triển.\\nTôi từng thấy các nhóm làm việc với những hệ thống đã phát triển dành hàng tháng\\nđể tạo được những tập phát triển/kiểm tra tốt hơn.\\nNếu sau đó bạn nhận ra rằng tập phát triển/kiểm tra  hoặc phép đo ban đầu không\\nphù hợp với mục tiêu đặt ra, bằng mọi giá hãy thay đổi chúng một cách nhanh\\nchóng. Chẳng hạn, nếu phép đo trên tập phát triển x ếp hạng bộ phân loại A tốt hơn\\nbộ phân loại B, nhưng nhóm nghĩ rằng bộ phân loại B  thực ra lại tốt hơn cho sản\\nphẩm của bạn, đây có thể là dấu hiệu cần thay đổi t ập phát triển/kiểm tra hoặc\\nphép đánh giá.\\nBa nguyên nhân chính khiến tập phát triển/phép đánh  giá xếp hạng bộ phân loại A\\ncao hơn:\\n1. Phân phối thực tế mà bạn cần làm tốt khác với ph ân phối của tập phát\\ntriển/kiểm tra.\\nGiả sử tập phát triển/kiểm tra ban đầu chứa chủ yếu  ảnh mèo trưởng thành. Sau khi\\n21'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 22}, page_content='ra mắt ứng dụng, bạn nhận ra rằng người dùng lại tả i lên ảnh mèo con nhiều hơn dự\\ntính. Khi đó, phân phối của tập phát triển/kiểm tra  không đại diện cho phân phối\\nthực tế mà cần bạn hướng tới. Trong trường hợp này,  bạn cần cập nhật tập phát\\ntriển/kiểm tra sao cho chúng có tính đại diện hơn.\\n2. Mô hình của bạn đã quá khớp tập phát triển.\\nQuá trình đánh giá ý tưởng trên tập phát triển được  lặp đi lặp lại khiến thuật toán\\ndần \"quá khớp\" tập dữ liệu này. Sau khi phát triển xong, bạn sẽ đánh giá mô hình\\ntrên tập kiểm tra. Nếu bạn thấy rằng chất lượng trê n tập phát triển tốt hơn nhiều so\\nvới chất lượng trên tập kiểm tra, đây là dấu hiệu b ạn đã quá khớp tập phát triển.\\nTrong trường hợp này, bạn hãy tạo một tập phát triể n mới hoàn toàn.\\nNếu bạn cần theo dõi tiến độ của nhóm, bạn cũng có thể đánh giá hệ thống trên tập\\nkiểm tra thường xuyên, chẳng hạn mỗi tuần hoặc mỗi tháng một lần. Tuy nhiên,\\nkhông được sử dụng tập kiểm tra để đưa ra bất kì qu yết định nào liên quan tới thuật\\ntoán, bao gồm việc quay lui về hệ thống trước đó. N ếu làm vậy, bạn sẽ bắt đầu quá\\nkhớp tập kiểm tra và không thể tiếp tục dựa vào nó để tạo ra một đánh giá hoàn\\ntoàn không thiên lệch cho chất lượng của hệ thống ( bạn sẽ cần đánh giá như vậy khi\\nbạn xuất bản công trình nghiên cứu hoặc là để đưa r a những quyết định kinh doanh\\nquan trọng dựa trên phép đo này).\\n3. Phép đo không phù hợp với mục tiêu tối ưu của dự án.\\nGiả sử trong ứng dụng mèo, phép đo của bạn là độ ch ính xác phân loại. Phép đo này\\nhiện tại xếp hạng bộ phân loại A tốt hơn bộ phân lo ại B. Tuy nhiên, giả sử bạn thử cả\\nhai thuật toán, và nhận ra rằng bộ phân loại A thi thoảng chấp nhận những bức ảnh\\nkhiêu dâm. Ngay cả khi bộ phân loại A chính xác hơn , ấn tượng xấu gây ra bởi một\\nvài bức ảnh khiêu dâm đồng nghĩa với việc chất lượn g của nó là không chấp nhận\\nđược. Bạn sẽ làm gì?\\nỞ đây, phép đo thất bại trong việc xác định được th ực tế Thuật toán B tốt hơn Thuật\\ntoán A cho sản phẩm của bạn. Bởi vậy, bạn không thể  dựa vào phép đo này để chọn\\nthuật toán tốt nhất. Đây là lúc phải thay đổi phép đo. Ví dụ, bạn có thể thay đổi\\nphép đo sao cho nó \"phạt\" thật nặng nếu một thuật t oán chấp nhận ảnh khiêu dâm.\\nTôi khuyên bạn chọn một phép đo mới và sử dụng nó đ ể định nghĩa lại thật rõ ràng\\nmục tiêu của nhóm, hơn là cứ tiếp tục chọn thủ công  trong số các bộ phân loại khi\\nkhông có một phép đo đáng tin cậy.\\nViệc thay đổi tập phát triển/kiểm tra hoặc phép đo giữa dự án khá là phổ biến. Có\\nmột tập phát triển/kiểm tra và phép đo ban đầu giúp  bạn hoàn thành chu kỳ phát\\ntriển một cách nhanh chóng. Nếu bạn nhận ra rằng tậ p phát triển/kiểm tra hoặc\\nphép đo không còn giúp nhóm đi đúng hướng, không sa o cả! Chỉ cần thay chúng và\\nđảm bảo cả nhóm đều biết về hướng đi mới này.\\n22'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 23}, page_content='12. Điều cần nhớ: Thiết lập các tập phát triển\\nvà kiểm tra\\nChọn tập phát triển và kiểm tra từ một phân phối ph ản ánh được dữ liệu bạn dự\\ntính sẽ cần xử lý trong tương lai và muốn hoạt động  tốt với chúng. Phân phối này\\ncó thể không giống phân phối trên dữ liệu huấn luyệ n của bạn.\\nNếu có thể, hãy chọn tập phát triển và kiểm tra từ cùng một phân phối xác suất.\\nHãy chọn một phép đo đơn trị để tối ưu hóa. Nếu có nhiều mục tiêu cần quan tâm\\nđến, hãy kết hợp chúng thành một công thức duy nhất  (chẳng hạn như lấy trung\\nbình các phép đo sai số) hoặc xác định ra phép đo t hỏa mãn và phép đo để tối\\nưu.\\nHọc máy là một quá trình lặp đi lặp lại: Bạn có thể  phải thử hàng tá ý tưởng trước\\nkhi tìm thấy một ý tưởng mà bạn hài lòng.\\nCó tập phát triển/kiểm tra và một phép đo đơn trị g iúp bạn nhanh chóng đánh giá\\ncác thuật toán và do đó lặp lại nhanh hơn.\\nKhi bắt đầu trên một ứng dụng hoàn toàn mới, hãy nh anh chóng thiết lập tập\\nphát triển/kiểm tra và một phép đo trong vòng một t uần. Với các ứng dụng đã\\nphát triển, quá trình này có thể kéo dài hơn.\\nCách chia dữ liệu huấn luyện/kiểm tra với tỉ lệ 70% /30% theo kinh nghiệm cũ\\nkhông áp dụng cho các bài toán với nhiều dữ liệu; t ập phát triển và kiểm tra có\\nthể chiếm ít hơn con số 30% rất nhiều.\\nTập phát triển của bạn phải đủ lớn để phát hiện các  thay đổi có ý nghĩa đối với độ\\nchính xác của thuật toán, nhưng không nhất thiết ph ải lớn hơn nhiều. Tập kiểm\\ntra phải đủ lớn để cung cấp cho bạn ước lượng đáng tin cậy về chất lượng cuối\\ncùng của hệ thống.\\nNếu tập phát triển và phép đo không còn chỉ cho nhó m của bạn đi đúng hướng,\\nhãy nhanh chóng thay đổi chúng: (i) Nếu thuật toán đã quá khớp tập phát triển,\\nhãy thu thập thêm dữ liệu cho tập này. (ii) Nếu phâ n phối xác suất thực tế mà\\nbạn quan tâm khác với phân phối xác suất của tập ph át triển/kiểm tra, hãy tạo\\ntập phát triển và kiểm tra mới. (iii) Nếu phép đo k hông còn đo lường được điều\\nquan trọng nhất với bạn, hãy thay đổi phép đo.\\n23'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 24}, page_content='Phần 2: Phân tích lỗi cơ\\nbản\\n24'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 25}, page_content='13. Bạn mong muốn xây dựng một hệ thống\\nphòng chống email rác mới. Nhóm của bạn có\\nrất nhiều ý tưởng:\\nThu thập một tập huấn luyện lớn về email rác. Ví dụ  như thiết lập một Honeypot\\n(Mồi nhử): cố ý gửi các địa chỉ email giả đến những  spammer đã biết, và bạn có thể\\nthu thập các tin nhắn rác mà họ gửi đến địa chỉ đó một cách tự động.\\nPhát triển những tính năng để hiểu được nội dung vă n bản trong email.\\nPhát triển những tính năng để hiểu được các đặc tín h của phông thư/nhãn thư từ\\nemail nhằm hiển thị tập hợp các máy chủ internet mà  thư đã đi qua.\\nvà nhiều hơn thế.\\nMặc dù tôi đã kinh qua rất nhiều trong việc phòng c hống email rác, tôi vẫn sẽ gặp\\nkhó khăn khi phải chọn một trong các hướng đi trên.  Điều này sẽ còn khó hơn nếu\\nbạn không phải là một chuyên gia trong lĩnh vực này .\\nVì vậy, bạn không nên bắt đầu bằng việc thiết kế và  xây dựng một hệ thống hoàn\\nhảo. Thay vào đó, hãy xây dựng và huấn luyện nhanh một hệ thống cơ bản -- có thể\\nlà trong vài ngày[5]. Ngay cả khi hệ thống cơ bản k hác xa với hệ thống tốt nhất mà\\nbạn có thể xây dựng, khám phá cách thức hoạt động c ủa hệ thống cơ bản này vẫn\\nđem lại nhiều giá trị: bạn sẽ nhanh chóng tìm ra đư ợc những dấu hiệu cho những\\nhướng đi hứa hẹn nhất để đầu tư thời gian. Trong nh ững chương tiếp theo sẽ chỉ cho\\nbạn cách tìm thấy những dấu hiệu này.\\nCHÚ THÍCH:\\nLời khuyên này dành cho những độc giả có mong muốn xây dựng các ứng dụng AI,\\nhơn là những người có mục tiêu là xuất bản những bà i báo học thuật. Tôi sẽ quay trở\\nlại với chủ đề nghiên cứu này sau.\\n25'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 26}, page_content='14. Phân tích lỗi: đánh giá ý tưởng dựa trên tập\\nphát triển\\nKhi kiểm thử ứng dụng nhận dạng mèo, bạn thấy rẳng một số bức ảnh chó bị nhận\\nnhầm. Nhìn chúng tương đối giống mèo!\\nMột thành viên trong nhóm đề xuất tích hợp phần mềm  của bên thứ ba nhằm giúp\\nhệ thống phân biệt tốt hơn các bức ảnh chó. Có thể mất một tháng để hoàn thành\\nquá trình tích hợp và người đề xuất rất hào hứng. L iệu bạn có nên yêu cầu thành\\nviên đó bắt đầu công việc?\\nTrước khi đầu tư cả một tháng, bạn nên ước lượng vi ệc này có thể cải thiện độ chính\\nxác của hệ thống tới mức nào. Từ đó, bạn sẽ có thể quyết định xem có đáng bỏ ra\\nchừng đó thời gian vào việc phát triển hay là dành nó cho những việc khác.\\nCụ thể, bạn có thể làm theo các bước sau:\\n1. Thu thập 100 mẫu trong tập phát triển mà ứng dụn g của bạn phân loại nhầm —\\nkhông phải mèo nhưng được phân loại là mèo và ngược  lại.\\n2. Nhìn vào những mẫu trên và đếm xem bao nhiêu tro ng số đó là ảnh chó.\\nQuá trình nhìn vào những mẫu bị phân loại nhầm được  gọi là phân tích lỗi . Trong ví\\ndụ này, nếu bạn nhận thấy rằng chỉ 5% lỗi là chó nh ầm thành mèo thì cho dù cải\\nthiện thuật toán theo hướng tích hợp phần mềm nhận dạng chó vào ứng dụng, bạn\\nkhông thể loại bỏ quá 5% số ảnh bị nhận dạng sai. N ói cách khác, 5% là \"cận trên\"\\n(số lượng tối đa có thể đạt được) cho mức độ cải th iện mà hướng đi trên có thể giúp\\ncho hệ thống. Nếu như độ chính xác ban đầu của ứng dụng là 90% (10% lỗi), việc\\ncải thiện chỉ làm cho hệ thống của bạn đạt được độ chính xác mới là 90,5% (9,5%\\nlỗi, ít hơn 5% so với số lượng lỗi ban đầu).\\nNgược lại, nếu bạn nhận thấy rằng 50% lỗi là do chó  bị nhầm thành mèo thì bạn có\\nthể tự tin rằng phương án được đề xuất sẽ có tác độ ng lớn. Nó có thể cải thiện đáng\\nkể độ chính xác của hệ thống từ 90% lên 95% (giảm 5 0% tổng số lỗi, từ 10% xuống\\n5%).\\nCách phân tích lỗi đơn giản ở trên giúp bạn ước lượ ng nhanh hiệu quả của việc tích\\nhợp phần mềm nhận dạng chó của bên thứ ba vào hệ th ống nhận dạng mèo. Đây\\ncũng là cơ sở định lượng để bạn lựa chọn xem có nên  đi theo hướng này hay không.\\nViệc phân tích lỗi  thường giúp bạn nhìn thấy được triển vọng của nhữn g hướng giải\\n26'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 27}, page_content='quyết khác nhau. Tôi thấy nhiều kỹ sư tiến hành phâ n tích lỗi môt cách miễn cưỡng.\\nDường như đối với họ ngay lập tức thực hiện một số ý tưởng sẽ thú vị hơn là tự hỏi\\nxem ý tưởng đó có thật sự đáng để bạn bỏ thời gian thực hiện. Đây là một lỗi phổ\\nbiến: nó có thể gây lãng phí hàng tháng chỉ để nhận  ra rằng sự cải thiện là không\\nđáng kể.\\nQuan sát 100 mẫu để phân tích lỗi không tốn nhiều t hời gian. Kể cả khi bạn bỏ ra\\nmột phút để kiểm tra từng ảnh, thời gian tổng cộng vẫn nhỏ hơn hai giờ. Nếu như ý\\ntưởng kia không tốt, bỏ ra hai giờ phân tích lỗi nà y có thể giúp bạn tiết kiệm được\\nmột tháng.\\nViệc phân tích lỗi là quá trình kiểm tra các mẫu tr ong tập phát triển bị phân loại\\nnhầm, từ đó bạn có thể hiểu được nguyên nhân. Hiểu rõ nguyên nhân tạo ra lỗi sẽ\\ngiúp bạn nhìn ra những hướng giải quyết mới mà chún g ta sẽ thảo luận ở phần sau.\\nMột số chương tiếp theo sẽ trình bày những \"best pr actices\" được dùng để phân tích\\nlỗi.\\n27'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 28}, page_content='15. Đánh giá song song các ý tưởng trong quá\\ntrình phân tích lỗi\\nNhóm của bạn có một số ý tưởng cải thiện bộ phát hi ện mèo:\\nSửa lỗi nhận dạng chó thành mèo trong thuật toán.\\nSửa lỗi nhận dạng thú họ mèo (sư tử, báo, v.v) thàn h mèo nhà (thú nuôi).\\nCải thiện chất lượng của hệ thống trên ảnh mờ.\\n...\\nBạn có thể đánh giá song song tất cả các ý kiến trê n một cách hiệu quả. Tôi thường\\ntạo một bảng và điền vào đó khi phân tích ~100 ảnh phân loại nhầm trong tập phát\\ntriển. Tôi cũng ghi chú ngắn gọn để ghi nhớ những t rường hợp đặc biệt. Để minh\\nhọa cho quá trình này, bạn có thể tham khảo bảng đư ợc tạo ra từ một tập phát triển\\nnhỏ với bốn mẫu dưới đây:\\nẢnh ChóThú Họ\\nMèoẢnh\\nMờGhi chú\\n1 ✔ Chó pitbull có màu lạ\\n2 ✔\\n3 ✔ ✔Ảnh sư tử chụp ở sở thú trong một ngày\\nmưa\\n4 ✔ Một con báo bị khuất sau cây\\nTổng\\n%25% 50% 50%\\nẢnh #3 ở trên có cả hai cột Thú Họ Mèo và Ảnh Mờ đư ợc đánh dấu. Thêm vào đó, bởi\\nvì một mẫu có thể nằm ở nhiều hạng mục, tổng phần t răm của hàng cuối có thể\\nkhông đạt 100%.\\nMặc dù bạn có thể tạo từ trước các hạng mục (Chó, T hú Họ Mèo, Ảnh Mờ) và sau đó\\nphân loại các mẫu thủ công, trong quá trình phân tí ch mẫu, bạn có thể nảy ra những\\ný tưởng về các hạng mục mới. Ví dụ: bạn phân loại h àng chục bức ảnh và nhận ra\\nnhiều lỗi xảy ra ở những tấm ảnh chỉnh bởi bộ lọc I nstagram. Bạn có thể quay lại và\\nthêm cột \"Instagram\" vào bảng. Bằng cách nhìn vào t ừng mẫu mà thuật toán phân\\nloại nhầm và đặt câu hỏi làm thế nào/liệu rằng con người có thể nhận dạng mẫu này\\nmột cách chính xác, nhiều khả năng là bạn sẽ tìm đư ợc các hạng mục lỗi và giải\\npháp mới.\\nNhững hạng mục lỗi hữu ích nhất sẽ là những lỗi mà bạn có thể khắc phục. Ví dụ,\\nhạng mục Instagram sẽ là hữu ích nhất để thêm vào n ếu bạn biết cách \"đảo ngược\"\\nbộ lọc Instagram và phục hồi ảnh gốc. Tuy nhiên bạn  không nhất thiết phải giới hạn\\nbản thân chỉ với những hạng mục mà bạn biết cách cả i thiện; mục tiêu của quá trình\\nnày là xây dựng một góc nhìn rõ hơn về những đặc tr ưng tiềm năng mà bạn nên tập\\n28'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 29}, page_content='trung vào.\\nPhân tích lỗi là một quá trình lặp đi lặp lại. Đừng  lo nếu bạn bắt đầu mà vẫn chưa\\nnghĩ được hạng mục nào. Bạn sẽ có thêm ý tưởng về c ác hạng mục lỗi mới sau khi\\nphân tích một vài tấm ảnh. Sau khi phân loại thủ cô ng một số hình ảnh, bạn có thể\\nnghĩ ra các hạng mục mới và đối chiếu lại các mẫu ả nh theo hạng mục mới đó.\\nGiả sử bạn hoàn thành việc phân tích lỗi 100 mẫu bị  phân loại nhầm trên tập phát\\ntriển và có được kết quả như sau:\\nẢnh ChóThú Họ\\nMèoẢnh\\nMờGhi chú\\n1 ✔ Chó pitbull có màu lạ\\n2 ✔\\n3 ✔ ✔Ảnh sư tử chụp ở sở thú trong một ngày\\nmưa\\n4 ✔ Một con báo bị khuất sau cây\\n... ... ... ... ...\\nTổng\\n%8% 43% 61%\\nBạn thấy rằng việc khắc phục lỗi phân loại nhầm trê n hạng mục Chó có thể loại bỏ\\ntối đa 8% lỗi. Khắc phục các lỗi trên hạng mục Thú Họ Mèo và Ảnh Mờ có thể loại bỏ\\nđược nhiều lỗi hơn. Vì vậy bạn có thể chọn một tron g hai hạng mục trên để tập\\ntrung vào. Nếu nhóm của bạn có đủ nhân lực để khắc phục nhiều hạng mục lỗi song\\nsong, bạn có thể phân công một số kỹ sư khắc phục l ỗi trên hạng mục Thú Họ Mèo,\\nnhững người còn lại khắc phục lỗi trên hạng mục Ảnh  Mờ.\\nPhân tích lỗi không tạo ra một công thức toán học c ứng nhắc cho bạn biết hạng mục\\nnào có độ ưu tiên cao nhất. Bạn cũng cần đánh giá k hả năng cải thiện có thể đạt\\nđược trên các hạng mục cũng như khối lượng công việ c cần thiết để giải quyết từng\\nhạng mục đó.\\n29'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 30}, page_content='16. Dọn dẹp những mẫu bị gán nhãn nhầm\\ntrong tập phát triển và tập kiểm tra\\nTrong quá trình phân tích lỗi, bạn có thể nhận thấy  rằng một vài mẫu trong trong\\ntập phát triển bị gán nhãn nhầm. Khi nói \"bị gán nh ãn nhầm\", ý tôi là những tấm\\nảnh đã bị gán nhãn nhầm bởi người dán nhãn trước cả  khi chạy thuật toán. Hay nói\\ncách khác, nhãn lớp của một mẫu (x,y) có giá trị y sai. Ví dụ, có thể một số ảnh\\nkhông chứa mèo bị gán nhãn nhầm thành có mèo và ngư ợc lại. Nếu bạn nghi ngờ\\nrằng tỷ lệ những ảnh bị gán nhãn nhầm là đáng kể, h ãy thêm một hạng mục để\\ntheo dõi tỷ lệ các mẫu bị gán nhãn nhầm:\\nẢnh ChóThú họ\\nmèoẢnh\\nmờDán\\nnhãn saiGhi chú\\n...\\n98 ✔Người dán nhãn đã bỏ qua con\\nmèo ở phần nền\\n99 ✔\\n100 ✔Bức vẽ của con mèo, không phải\\ncon mèo thật\\nTổng\\n%8% 43% 61% 6%\\nVậy bạn có nên sửa lại những nhãn sai trong tập phá t triển không? Hãy nhớ rằng\\nmục tiêu của tập phát triển là giúp bạn nhanh chóng  đánh giá các thuật toán nhờ đó\\nbạn có thể biết liệu Thuật toán A hay Thuật toán B là tốt hơn. Nếu tỷ lệ bị gán nhãn\\nnhầm trong tập phát triển cản trở khả năng ra những  quyết định này của bạn, thì sẽ\\nđáng để bỏ thời gian ra để sửa lại những nhãn bị gá n nhầm của tập phát triển.\\nĐể ví dụ, giả sử chất lượng bộ phân loại của bạn là :\\nĐộ chính xác tổng thể trên tập phát triển.......... .......... 90% (10% lỗi tổng thể.)\\nNhững lỗi gây ra bởi các mẫu bị gán nhãn nhầm...... . 0,6% (6% các lỗi trong tập\\nphát triển.)\\nNhững lỗi do các nguyên nhân khác.................. ... 9,4% (94% các lỗi trong tập\\nphát triển)\\nỞ đây, tỷ lệ 0,6% sai do gán nhầm nhãn có thể không  quá đáng kể so với tỷ lệ 9,4%\\ncác lỗi mà bạn có thể cải thiện. Không có một tác h ại nào trong việc sửa thủ công\\nnhững ảnh bị gán nhẫn nhầm trong tập phát triển cả,  nhưng nó không quá quan\\ntrọng để làm vậy: Việc bạn không biết liệu hệ thống  của mình có 10% hay 9,4% lỗi\\nchung là có thể chấp nhận được.\\nGiả sử bạn tiếp tục cải thiện bộ nhận dạng mèo và đ ạt chất lượng:\\nĐộ chính xác tổng thể trên tập phát triển.......... .......... 98,0% (2,0% lỗi tổng thể.)\\n30'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 31}, page_content='Những lỗi gây ra do các mẫu bị gán nhãn nhầm.......  0,6%. (30% các lỗi trong tập\\nphát triển.)\\nNhững lỗi do các nguyên nhân khác.................. ... 1,4% (70% các lỗi trong tập\\nphát triển)\\n30% lỗi của bạn đến từ những ảnh bị gán nhãn nhầm t rong tập phát triển, việc này\\nthêm một lượng đáng kể lỗi vào các đánh giá độ chín h xác của bạn. Trong trường\\nhợp này, cải thiện chất lượng của các nhãn trong tậ p phát triển là một việc đáng\\nlàm. Xử lý những mẫu bị gán nhãn nhầm sẽ giúp bạn b iết được lỗi của bộ phân loại\\ngần với 1,4% hay 2% -- một sự khác biệt đáng kể.\\nThông thường, trong giai đoạn đầu, bỏ qua một vài n hãn sai trong tập phát\\ntriển/kiểm tra là chấp nhận được. Khi hệ thống được  cải thiện, số mẫu bị gán nhãn\\nsai dần chiếm tỷ lệ tương đối lớn trong tập lỗi, lú c này ta mới tiến hành sửa lại các\\nnhãn đó.\\nChương trước đã hướng dẫn cách bạn có thể cải thiện  các hạng mục lỗi như Chó,\\nThú Họ Mèo và Ảnh Mờ qua những cải tiến về thuật to án. Bạn đã học trong chương\\nnày rằng bạn cũng có thể xử lý thêm hạng mục Bị Gán  Nhãn Sai nữa -- thông qua cải\\nthiện các nhãn của dữ liệu.\\nBất kể quy trình bạn áp dụng để sửa các nhãn trong tập huấn luyện là gì, hãy nhớ\\náp dụng cùng một quy trình cho các nhãn của tập kiể m tra, để đảm bảo tập phát\\ntriển và kiểm tra vẫn được lấy ra từ cùng một phân phối. Chỉnh sửa các tập phát\\ntriển và kiểm tra cùng nhau sẽ giúp tránh được nhữn g vấn đề chúng ta đã bàn trong\\nChương 6, khi nhóm của bạn tối ưu chất lượng cho tậ p phát triển để rồi phát hiện ra\\nsau đó là chúng đang được đánh giá dựa trên một tiê u chuẩn khác dựa trên một tập\\nkiểm tra khác.\\nNếu bạn quyết định cải thiện chất lượng nhãn, hãy x em xét việc kiểm tra kỹ các\\nnhãn của những mẫu mà hệ thống của bạn đã phân loại  nhầm cũng như các nhãn\\ncủa những mẫu mà nó đã phân loại chính xác. Rất có thể là cả nhãn gốc và thuật\\ntoán học máy của bạn đều đã sai trên một mẫu. Nếu b ạn chỉ sửa những nhãn của\\nmẫu mà hệ thống đã phân loại nhầm, bạn có thể đã gâ y ra thiên lệch trong đánh\\ngiá. Nếu bạn có 1.000 mẫu trong tập phát triển, và nếu bộ phân loại của bạn có\\n98,0% độ chính xác, sẽ dễ hơn khi kiểm tra 20 mẫu đ ã bị phân loại nhầm hơn là cả\\n980 mẫu được phân loại chính xác. Bởi vì trên thực tế, sẽ dễ hơn khi chỉ kiểm tra\\nnhững mẫu bị phân loại nhầm, do đó sự thiên lệch sẽ  lẻn vào một vài tập phát triển.\\nSự thiên lệch này là chấp nhận được nếu bạn chỉ qua n tâm vào việc phát triển một\\nsản phẩm hay một ứng dụng, nhưng nó sẽ là một vấn đ ề nếu bạn định sử dụng kết\\nquả trong một bài báo nghiên cứu khoa học hay cần m ột phép đo hoàn toàn không\\nthiên lệch cho độ chính xác của tập kiểm tra.\\n31'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 32}, page_content='17. Nếu bạn có một tập phát triển lớn, chia nó\\nthành hai tập con và chỉ phân tích trên một tập\\nGiả sử bạn có một tập phát triển lớn gồm 5000 mẫu, với tỉ lệ lỗi là 20%. Ở đây,\\nthuật toán của bạn đang phân loại nhầm khoảng 1000 mẫu ảnh của tập phát triển.\\nSẽ rất lâu để phân tích thủ công 1000 ảnh này, vì v ậy, chúng ta có thể quyết định\\nkhông sử dụng tất cả 1000 ảnh đó trong phân tích lỗ i.\\nTrong trường hợp này, tôi sẽ chia tập phát triển th ành hai tập con riêng biệt: một\\ntập sẽ được phân tích thủ công (bằng cách nhìn vào từng mẫu), tập còn lại thì\\nkhông. Thuật toán sẽ quá khớp phần được phân tích t hủ công nhanh hơn. Phần còn\\nlại có thể được sử dụng để điều chỉnh tham số.\\nHãy cùng tiếp tục với ví dụ ở trên: ví dụ thuật toá n đang phân loại nhầm 1000 mẫu\\ntrên tổng số 5000 mẫu trong tập phát triển. Giả sử chúng ta muốn kiểm tra một\\ncách thủ công 100 mẫu bị phân lọại nhầm để phân tíc h lỗi (10% tổng số lỗi). Bạn\\nnên chọn ra 10% mẫu trong tập phát triển một cách n gẫu nhiên và đặt nó vào trong\\nmột tập mà chúng ta sẽ gọi là tập phát triển Eyeball  để tự nhắc chúng ta rằng\\nchúng ta sẽ trực tiếp nhìn vào bằng mắt. (Đối với n hững dự án nhận diện giọng nói\\nmà bạn phải nghe các clip audio, có lẽ bạn sẽ gọi t ập này là tập phát triển Ear). Tập\\nphát triển Eyeball chứa 500 mẫu, trong đó chúng ta kỳ vọng thuật toán sẽ phân loại\\nnhầm khoảng 100 mẫu.\\nTập con thứ hai của tập phát triển, được gọi là tập phát triển Blackbox , sẽ chứa\\n4500 mẫu còn lại. Bạn có thể sử dụng tập phát triển  Blackbox để đánh giá các bộ\\nphân loại một cách tự động bằng cách đo tỉ lệ lỗi c ủa chúng. Bạn cũng có thể sử\\ndụng tập này để lựa chọn giữa các thuật toán hoặc đ iều chỉnh các siêu tham số. Tuy\\nnhiên, bạn nên tránh trực tiếp phân tích thủ công t rên tập này. Chúng ta sử dụng\\nthuật ngữ \"Blackbox\" vì chúng ta chỉ sử dụng tập co n này để thu về những đánh giá\\n\"Blackbox\" của các bộ phân loại.\\n32'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 33}, page_content='Tại sao chúng ta lại chia tập phát triển một cách r iêng biệt thành tập phát triển\\nEyeball và tập phát triển Blackbox? Bởi vì bạn sẽ h iểu rõ hơn về các mẫu trong tập\\nphát triển Eyeball, bạn sẽ bắt đầu quá khớp tập phá t triển đó nhanh hơn. Nếu bạn\\nthấy chất lượng của mô hình trên tập phát triển Eye ball đang tăng nhanh hơn nhiều\\nso với trên tập phát triển Blackbox, bạn đã quá khớ p tập phát triển Eyeball. Trong\\ntrường hợp này, bạn có thể phải loại bỏ tập Eyeball  đi, tìm một tập Eyeball khác\\nthay thế bằng cách chuyển các mẫu từ tập phát triển  Blackbox thành tập phát triển\\nEyeball mới, hoặc thu thập những mẫu có nhãn mới.\\nViệc phân chia tập phát triển thành hai tập riêng b iệt -- tập phát triển Eyeball và tập\\nphát triển Blackbox -- cho bạn biết khi nào việc ph ân tích lỗi thủ công đang khiến\\nbạn quá khớp tập Eyeball.\\n33'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 34}, page_content='18. Tập phát triển Eyeball và Blackbox nên lớn\\nnhư thế nào?\\nTập phát triển Eyeball phải đủ lớn để giúp bạn có c ái nhìn về các hạng mục lỗi chính\\ncủa thuật toán. Nếu bạn đang làm một tác vụ mà con người làm tốt (chẳng hạn như\\nnhận diện mèo trong các ảnh), dưới đây là một vài h ướng dẫn sơ bộ.\\nMột tập phát triển Eyeball ở đó các bộ phân loại tạ o ra 10 lỗi có thể được coi là\\nrất nhỏ. Với chỉ 10 lỗi, rất khó để ước lượng chuẩn  xác ảnh hưởng của những\\nhạng mục lỗi khác nhau. Nhưng nếu bạn có rất ít dữ liệu và không thể tăng số\\nmẫu trong tập phát triển Eyeball, việc này vẫn tốt hơn so với không có gì và sẽ\\ngiúp ích đối với việc sắp xếp ưu tiên của dự án.\\nNếu bộ phân loại tạo ra khoảng 20 lỗi trong tập phá t triển Eyeball, bạn sẽ bắt đầu\\ncảm nhận được sơ bộ về các nguồn lỗi chính.\\nVới khoảng 50 lỗi, bạn sẽ có cảm nhận tốt về các ng uồn lỗi chính.\\nVới khoảng 100 lỗi, bạn sẽ cảm nhận được rất tốt cá c nguồn lỗi chính. Tôi đã\\nchứng kiến nhiều người phân tích thủ công nhiều lỗi  hơn, đôi khi tới 500 lỗi. Điều\\nđó không gây hại miễn là bạn có đủ dữ liệu.\\nGiả sử bộ phân loại của bạn có tỷ lệ lỗi 5%. Để đảm  bảo bạn có khoảng 100 mẫu bị\\nphân loại sai trong tập phát triển Eyeball, tập phá t triển Eyeball sẽ phải có khoảng\\n2.000 mẫu (bởi vì 0,05 * 2.000 = 100). Tỷ lệ lỗi do  bộ phân loại gây ra càng thấp,\\ntập phát triển Eyeball càng phải lớn để có được một  tập lỗi đủ lớn cho phân tích.\\nNếu bạn đang làm việc trong một tác vụ mà ngay cả c on người cũng không thể làm\\ntốt, thì việc kiểm tra tập phát triển Eyeball sẽ kh ông hữu ích như trong trường hợp\\ntrên vì khó hình dung tại sao thuật toán không phân  loại mẫu một cách chính xác.\\nTrong trường hợp này, bạn có thể bỏ qua việc thiết lập tập phát triển Eyeball. Chúng\\nta thảo luận hướng dẫn cho những vấn đề này trong m ột chương sau.\\n34'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 35}, page_content='Tập phát triển Blackbox thì sao? Trước đây chúng ta  đã khẳng định rằng các tập\\nphát triển khoảng 1.000-10.000 mẫu là khá phổ biến.  Để củng cố nhận định đó, một\\ntập phát triển Blackbox gồm 1.000-10.000 mẫu thường  cung cấp đủ dữ liệu để tinh\\nchỉnh siêu tham số và lựa chọn giữa các mô hình, mặ c dù có ít bất lợi khi có nhiều\\ndữ liệu hơn. Một tập phát triển Blackbox với 100 mẫ u sẽ nhỏ nhưng vẫn hữu ích.\\nNếu bạn có một tập phát triển nhỏ thì bạn có thể kh ông đủ dữ liệu để phân chia\\nthành tập phát triển Eyeball và tập phát triển Blac kbox đủ lớn để đáp ứng mục đích\\nsử dụng của chúng. Thay vào đó, toàn bộ tập phát tr iển của bạn có thể phải được sử\\ndụng như là tập phát triển Eyeball, tức là bạn sẽ k iểm tra thủ công toàn bộ tập phát\\ntriển.\\nGiữa tập phát triển Eyeball và tập phát triển Black box, tôi cho rằng tập phát triển\\nEyeball quan trọng hơn (giả định bạn đang giải quyế t một vấn đề mà con người có\\nthể giải quyết tốt và việc kiểm tra mẫu giúp bạn hi ểu rõ hơn). Nếu bạn chỉ có một\\ntập phát triển Eyeball, bạn có thể thực hiện phân t ích lỗi, lựa chọn mô hình và tinh\\nchỉnh siêu tham số, tất cả trên tập dữ liệu này. Nh ược điểm của việc chỉ có một tập\\nphát triển Eyeball là nguy cơ quá khớp trên tập phá t triển là lớn hơn.\\nNếu bạn có quyền truy cập vào nhiều dữ liệu thì kíc h thước của tập phát triển\\nEyeball sẽ chủ yếu dựa trên bao nhiêu mẫu mà bạn có  thời gian để phân tích thủ\\ncông. Ví dụ, tôi hiếm khi thấy ai phân tích thủ côn g hơn 1.000 lỗi.\\n35'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 36}, page_content='19. Điều cần nhớ: Phân tích lỗi cơ bản\\nKhi bạn bắt đầu một dự án mới, đặc biệt nếu bạn khô ng phải là chuyên gia trong\\nlĩnh vực đó, sẽ rất khó để đoán chính xác những hướ ng giải quyết triển vọng nhất.\\nVì vậy đừng cố bắt đầu với việc thiết kế và xây dựn g một hệ thống hoàn hảo.\\nThay vào đó, hãy xây dựng và huấn luyện một hệ thốn g cơ bản một cách nhanh\\nnhất có thể -- thậm chí chỉ trong một vài ngày. Sau  đó, sử dụng phân tích lỗi để\\nxác định những hướng đi triển vọng và từ đó lặp đi lặp lại việc cải thiện thuật toán\\ncủa bạn.\\nThực hiện phân tích lỗi bằng cách kiểm tra thủ công  khoảng 100 mẫu trong tập\\nphát triển mà thuật toán phân loại sai và điểm qua những hạng mục lỗi chính. Sử\\ndụng thông tin này để sắp xếp thứ tự ưu tiên các lo ại lỗi cần khắc phục.\\nXem xét việc tách tập phát triển thành một tập phát  triển Eyeball cho việc kiểm\\ntra thủ công, và một tập phát triển Blackblox mà bạ n sẽ không kiểm tra thủ công.\\nNếu chất lượng trên tập phát triển Eyeball tốt hơn rất nhiều so với trên tập phát\\ntriển Blackbox, bạn đã quá khớp tập phát triển Eyeb all và nên xem xét việc thu\\nthập thêm dữ liệu cho tập này.\\nTập phát triển Eyeball nên đủ lớn để số lượng mẫu m à thuật toán của bạn phân\\nloại sai đủ cho bạn phân tích. Một tập phát triển B lackbox khoảng 1.000-10.000\\nmẫu là đủ cho rất nhiều những ứng dụng.\\nNếu tập phát triển của bạn không đủ lớn để tách ra theo cách này, hãy lấy toàn\\nbộ tập phát triển làm một tập phát triển Eyeball dà nh cho việc phân tích lỗi thủ\\ncông, chọn mô hình, và điều chỉnh siêu tham số.\\n36'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 37}, page_content='Phần 3: Độ chệch và\\nPhương sai\\n37'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 38}, page_content='20. Độ chệch và Phương sai: Hai nguồn lớn của\\nlỗi\\nGiả sử khi huấn luyện, tập phát triển và tập kiểm t ra có cùng phân phối. Khi đó bạn\\ncần luôn cố gắng thu thập thêm dữ liệu huấn luyện, vì dù sao điều đó cũng chỉ giúp\\ncải thiện chất lượng, đúng không?\\nMặc dù có thêm dữ liệu không gây ảnh hưởng xấu, thì  thật không may, điều này\\nkhông phải lúc nào cũng mang lại hiệu quả nhiều như  mong đợi. Việc thu thập thêm\\ndữ liệu có thể trở nên lãng phí thời gian. Vậy làm thế nào để quyết định khi nào nên\\nhoặc không nên thêm dữ liệu?\\nCó hai nguồn lỗi chính trong học máy: độ chệch và p hương sai. Hiểu được chúng sẽ\\ngiúp bạn quyết định liệu việc thêm dữ liệu hay áp d ụng các kỹ thuật khác để cải\\nthiện chất lượng của mô hình có đáng để bỏ thời gia n ra không.\\nGiả sử bạn hy vọng xây dựng được một bộ nhận dạng m èo với 5% lỗi. Hiện tại, tập\\nhuấn luyện và tập phát triển có tỉ lệ lỗi lần lượt là 15% và 16%. Trong trường hợp\\nnày, việc thêm dữ liệu có thể không giúp được gì nh iều. Bạn nên tập trung vào các\\nthay đổi khác. Chắc chắn rằng việc tăng số mẫu cho tập huấn luyện chỉ khiến quá\\ntrình huấn luyện mô hình trên tập này trở nên khó k hăn hơn. (Lý do sẽ được giải\\nthích trong chương sau.)\\nNếu tỉ lệ lỗi trên tập huấn luyện là 15% (tức độ ch ính xác 85%), nhưng mục tiêu của\\nbạn là 5% lỗi (độ chính xác 95%), thì vấn đề trước tiên cần giải quyết là cải thiện\\nchất lượng thuật toán trên tập huấn luyện. Chất lượ ng trên tập phát triển/kiểm tra\\nthường thấp hơn trên tập huấn luyện. Bởi vậy, nếu b ạn đang có độ chính xác 85%\\ntrên các mẫu mà thuật toán từng thấy, thì không thể  nào đạt được độ chính xác 95%\\ncho các mẫu mà thuật toán chưa thấy bao giờ.\\nGiả sử như trên rằng thuật toán của bạn có 16% lỗi (độ chính xác 84%) trên tập phát\\ntriển. Chúng ta tách 16% lỗi này ra hai thành phần:\\nThứ nhất, tỉ lệ lỗi của thuật toán trên tập huấn lu yện, là 15% trong ví dụ này.\\nChúng ta tạm coi giá trị này như độ chệch  của thuật toán.\\nThứ hai, chất lượng của thuật toán trên tập phát tr iển (hoặc kiểm tra) kém hơn\\nbao nhiêu so với trên tập huấn luyện. Trong ví dụ n ày, thuật toán làm việc kém\\nhơn 1% trên tập phát triển so với tập huấn luyện. C húng ta tạm coi giá trị này\\nnhư phương sai  của thuật toán [6].\\nMột số thay đổi trong thuật toán học có thể giải qu yết thành phần thứ nhất của lỗi --\\nđộ chệch  -- và cải thiện chất lượng của nó trên tập huấn lu yện. Một số thay đổi giải\\nquyết thành phần thứ hai -- phương sai  -- và giúp thuật toán tổng quát hóa tốt hơn\\ntừ tập huấn luyện tới tập phát triển/kiểm tra [7]. Việc nắm được thành phần nào\\ntrong hai thành phần lỗi trên là đáng giải quyết hơ n sẽ rất hữu ích để trong việc\\nchọn ra những thay đổi tiềm năng nhất.\\n38'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 39}, page_content='Phát triển trực giác tốt về Độ chệch và Phương sai sẽ giúp bạn chọn những thay đổi\\nhữu hiệu cho thuật toán.\\n[6] Ngành thống kê có những định nghĩa chính thống hơn cho độ chệch và phương\\nsai mà ở đây chúng ta không cần lưu tâm. Đại khái, độ chệch là tỉ lệ lỗi của thuật\\ntoán trên tập huấn luyện khi tập này rất lớn. Phươn g sai là độ giảm chất lượng trên\\ntập kiểm tra so với tập huấn luyện trong thiết lập này. Khi phép đo lỗi là sai số toàn\\nphương trung bình, bạn có thể viết ra công thức tín h hai đại lượng này và chứng\\nminh được rằng Tổng Lỗi = Độ Chệch + Phương Sai. Nh ưng với mục đích xác định\\nlàm thế nào để tạo sự tiến triển trong một bài toán  học máy, thì định nghĩa ít chính\\nthống hơn của độ chệch và phương sai như trình bày ở đây là đã đủ.\\n[7] Cũng có một vài phương pháp có thể đồng thời gi ảm độ chệch và phương sai\\nbằng các thay đổi lớn trong kiến trúc hệ thống. Tuy  nhiên, những phương pháp này\\ncó xu hướng khó phát hiện và triển khai hơn.\\n39'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 40}, page_content='21. Những ví dụ về Độ chệch và Phương sai\\nHãy xem xét việc phân loại mèo của chúng ta. Một bộ  phân loại \"lý tưởng\" (như con\\nngười) có thể đạt được hiệu suất gần như hoàn hảo c ho việc này.\\nGiả sử thuật toán của bạn đạt được:\\nLỗi huấn luyện = 1%\\nLỗi phát triển = 11%\\nVậy vấn đề gặp phải là gì? Áp dụng các định nghĩa t ừ những chương trước, chúng ta\\nước tính độ chệch là 1% và phương sai là 10% (=11%- 1%). Do đó, thuật toán có\\nphương sai cao . Tuy bộ phân loại có lỗi huấn luyện rất thấp, nhưn g nó lại không\\nkhái quát hoá được cho tập phát triển. Hiện tượng n ày cũng được gọi là quá khớp .\\nBây giờ hãy xem xét trường hợp sau:\\nLỗi huấn luyện = 15%\\nLỗi phát triển = 16%\\nChúng ta ước tính độ chệch là 15% và phương sai là 1%. Bộ phân loại này khớp kém\\nvới tập huấn luyện với 15% lỗi nhưng lỗi ở tập phát  triển chỉ cao hơn một chút so với\\ntập huấn luyện. Do đó, bộ phân loại này có độ chệch cao  nhưng phương sai thấp.\\nChúng ta nói thuật toán này đang dưới khớp  (underfit ).\\nBây giờ hãy xem xét trường hợp sau:\\nLỗi huấn luyện = 15%\\nLỗi phát triển = 30%\\nChúng ta ước tính độ chệch là 15% và phương sai là 15%. Bộ phân loại này có độ\\nchệch cao và phương sai cao : Nó hoạt động kém ở tập huấn luyện, do đó có độ\\nchệch cao, và chất lượng của nó trên tập phát triển  còn tệ hơn, do đó nó cũng có\\nphương sai cao. Thuật ngữ quá khớp/dưới khớp rất kh ó áp dụng ở đây vì bộ phân\\nloại đồng thời bị quá khớp và dưới khớp.\\nCuối cùng, hãy xem xét điều này:\\nLỗi huấn luyện = 0,5%\\nLỗi phát triển = 1%\\nBộ phân loại này đang hoạt động tốt vì nó có độ chệ ch thấp và phương sai thấp.\\nChúc mừng bạn đã đạt được một hiệu suất tuyệt vời!\\n40'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 41}, page_content='22. So sánh với tỉ lệ lỗi tối ưu\\nTrong ví dụ nhận dạng mèo của chúng ta, tỉ lệ lỗi \" lý tưởng\" -- tỉ lệ có thể đạt được\\nbởi một bộ phân loại \"tối ưu\" -- là gần với 0%. Gần  như mọi lúc, một người nhìn vào\\nbức ảnh có thể nhận ra có mèo trong đó hay không; d o đó chúng ta có thể hy vọng\\nmáy móc cũng làm được điều tương tự.\\nMột số bài toán khác thì khó hơn. Ví dụ như chúng t a xây dựng một hệ thống nhận\\ndạng giọng nói và nhận ra rằng 14% các đoạn âm than h có quá nhiều nhiễu nền\\nhoặc khó hiểu tới mức ngay cả con người cũng không thể nghe được những gì được\\nnói. Trong trường hợp này, ngay cả hệ thống \"tối ưu \" nhất cũng có thể có lỗi khoảng\\n14%.\\nGiả sử rằng với bài toán nhận dạng giọng nói này, t huật toán của bạn đạt được:\\nLỗi huấn luyện = 15%\\nLỗi phát triển = 30%\\nChất lượng trên tập huấn luyện hiện đã gần với tỉ l ệ lỗi tối ưu là 14%. Do đó, không\\ncó nhiều chỗ để cải thiện độ chệch hoặc chất lượng trên tập huấn luyện. Tuy nhiên,\\nthuật toán này không tổng quát hoá tốt trên tập phá t triển; do đó có rất nhiều chỗ\\nđể cải thiện lỗi do phương sai.\\nVí dụ này tương tự như ví dụ thứ ba trong chương tr ước, cũng có lỗi huấn luyện là\\n15% và lỗi phát triển là 30%. Nếu tỉ lệ lỗi tối ưu là xấp xỉ 0%, thì 15% lỗi huấn luyện\\nđể lại nhiều khả năng cải thiện. Điều này gợi ý rằn g những thay đổi làm giảm độ\\nchệch có thể mang lại nhiều kết quả. Nhưng nếu tỉ l ệ lỗi tối ưu là 14%, thì chất\\nlượng tương tự trên tập huấn luyện cho thấy có rất ít cơ hội để cải thiện độ chệch\\ncủa bộ phân loại.\\nVới các bài toán trong đó tỉ lệ lỗi tối ưu lớn hơn nhiều mức 0%, thì có một cách phân\\ntích chi tiết hơn về lỗi của thuật toán. Tiếp tục v ới ví dụ nhận dạng giọng nói ở trên,\\nlỗi tổng cộng trên tập phát triển là 30% có thể đượ c chia nhỏ như sau (phân tích\\ntương tự có thể áp dụng cho lỗi trên tập kiểm tra):\\nTỉ lệ lỗi tối ưu (\"độ chệch không tránh được\") : 14%. Giả sử chúng ra quyết\\nđịnh rằng, ngay cả khi dùng hệ thống nhận dạng giọn g nói tốt nhất trên thế giới,\\nthì ta vẫn phải chịu 14% lỗi. T a có thể coi lỗi đó là phần \"không tránh được\" trong\\nđộ chệch của thuật toán học máy.\\nĐộ chệch tránh được : 1%. Hiệu giữa lỗi huấn luyện và lỗi tối ưu. [8]\\nPhương sai : 15%. Hiệu giữa lỗi trên tập phát triển và lỗi trê n tập huấn luyện.\\nTừ những định nghĩa trước, thì mối liên hệ giữa Độ chệch và Độ chệch tránh được là:\\n[9]\\nĐộ chệch = Tỉ lệ lỗi tối ưu (\"độ chệch không tránh được\") + Độ chệch tránh được\\n\"Độ chệch tránh được\" phản ánh thuật toán của bạn h oạt động kém hơn bao nhiêu\\n41'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 42}, page_content='so với \"bộ phân loại tối ưu\".\\nKhái niệm phương sai vẫn giữ nguyên như trước. Theo  lý thuyết, chúng ta luôn có\\nthể giảm phương sai về gần bằng không bằng cách huấ n luyện trên một tập huấn\\nluyện cực lớn. Do đó, tất cả phương sai là \"tránh đ ược\" khi tập dữ liệu đủ lớn và\\nkhông có cái gọi là \"phương sai không tránh được\".\\nXem xét thêm một ví dụ nữa, trong đó tỉ lệ lỗi tối ưu là 14%, ta có:\\nLỗi huấn luyện = 15%\\nLỗi phát triển = 16%\\nTrong khi ở chương trước chúng ta gọi đây là một bộ  phân loại có độ chệch cao, bây\\ngiờ chúng ta nói rằng lỗi từ độ chệch tránh được là  1% và lỗi từ phương sai là khoảng\\n1%. Do đó, thuật toán của chúng ta đã là rất tốt và  có rất ít khoảng trống để cải\\nthiện. Nó chỉ kém đúng 2% so với tỉ lệ lỗi tối ưu.\\nTừ những ví dụ này chúng ta thấy rằng tỉ lệ lỗi tối  ưu rất hữu ích cho việc định hướng\\ncác bước tiếp theo. Trong thống kê, tỉ lệ lỗi tối ư u còn được gọi là tỉ lệ lỗi Bayes\\nhay tỉ lệ Bayes.\\nLàm sao chúng ta biết được tỉ lệ lỗi tối ưu? Với nh ững việc mà con người làm tốt, như\\nnhận dạng ảnh hay phiên thoại các đoạn âm thanh, bạ n có thể nhờ ai đó gán nhãn\\nsau đó đo độ chính xác của những nhãn này với tập h uấn luyện. Điều này sẽ cung\\ncấp một con số ước tính của tỉ lệ lỗi tối ưu. Nếu b ạn làm việc với một bài toán mà\\nngay cả con người cũng khó giải (ví dụ như dự đoán xem nên gợi ý bộ phim nào, hay\\nhiện quảng cáo nào trước người dùng), thì có thể sẽ  khó để ước tính được tỉ lệ lỗi tối\\nưu.\\nTrong phần \"So sánh với chất lượng mức con người (c hương 33 tới chương 35)\", tôi\\nsẽ thảo luận chi tiết hơn quá trình so sánh chất lư ợng một thuật toán học máy với\\nchất lượng mức con người.\\nTrong một vài chương trước, bạn đã học cách tính ph ương sai và độ chệch tránh\\nđược/không tránh được bằng cách xem xét tỉ lệ lỗi h uấn luyện và tỉ lệ lỗi phát triển.\\nChương tiếp theo sẽ thảo luận về cách bạn có thể sử  dụng những hiểu biết sâu sắc\\ntừ phân tích đó để ưu tiên các kỹ thuật làm giảm độ  chệch hoặc các kỹ thuật làm\\ngiảm phương sai. Có nhiều kỹ thuật khác nhau nên áp  dụng tuỳ thuộc vào vấn đề\\nhiện tại trong dự án của bạn là độ chệch (tránh đượ c) cao hay phương sai cao. Hãy\\nđọc tiếp!\\nCHÚ THÍCH:\\n[8] Nếu con số này là âm, bạn đang làm tốt hơn ở tr ên tập huấn luyện so với tỉ lệ lỗi\\ntối ưu. Điều này có nghĩa là bạn đang quá khớp tập huấn luyện và thuật toán đã ghi\\nnhớ quá mức tập huấn luyện. Bạn nên tập trung vào c ác phương pháp giảm phương\\nsai hơn là các phương pháp giảm độ chệch khác.\\n[9] Những định nghĩa này được chọn để truyền đạt cá i nhìn sâu sắc về cách cải thiện\\nthuật toán học máy của bạn. Những định nghĩa này kh ác với cách các nhà thống kê\\n42'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 43}, page_content='định nghĩa Độ chệch và Phương sai. Về mặt kỹ thuật,  những gì tôi định nghĩa là \"Độ\\nchệch\" nên được gọi là \"Lỗi chúng ta quy cho độ chệ ch\" và \"Độ chệch tránh được\"\\nnên là \"Lỗi chúng ta quy cho độ chệch của thuật toá n học mà lớn hơn tỉ lệ lỗi tối ưu\"\\n.\\n43'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 44}, page_content='23. Xử lý Độ chệch và Phương sai\\nĐây là công thức đơn giản nhất để giải quyết các vấ n đề độ chệch và phương sai:\\nNếu bạn có độ chệch tránh được cao, hãy tăng kích t hước mô hình (ví dụ: tăng\\nkích thước của mạng nơ-ron bằng cách thêm các tầng/ nơ-ron).\\nNếu bạn có phương sai cao, hãy thêm dữ liệu vào tập  huấn luyện.\\nNếu bạn có thể tăng kích thước của mạng nơ-ron và d ữ liệu huấn luyện lên vô hạn,\\nthì bạn sẽ có khả năng xử lý rất tốt trên nhiều bài  toán học máy.\\nTrong thực tế, việc tăng kích thước của mô hình cuố i cùng sẽ khiến bạn gặp phải\\ncác vấn đề về tính toán bởi vì việc huấn luyện các mô hình cực lớn là rất chậm. Bạn\\ncó thể cũng sẽ làm cạn kiệt khả năng có được nhiều dữ liệu huấn luyện hơn. (Ngay\\ncả trên mạng internet cũng chỉ có một số lượng hữu hạn hình ảnh mèo!)\\nNhững kiến trúc mô hình khác nhau -- ví dụ, các kiế n trúc mạng nơ-ron khác nhau --\\nsẽ có các mức độ chệch/phương sai khác nhau cho vấn  đề của bạn. Những nghiên\\ncứu gần đây về học sâu đã phát triển nhiều kiến trú c mô hình đột phá. Vì vậy, nếu\\nbạn đang sử dụng mạng nơ-ron, những tài liệu học th uật có thể là một nguồn cảm\\nhứng tuyệt vời. Ngoài ra còn có rất nhiều cài đặt m ã nguồn mở tuyệt vời trên\\nGitHub. Nhưng kết quả của việc thử nghiệm các kiến trúc mới khó dự đoán hơn so\\nvới công thức đơn giản của việc tăng kích thước mô hình và thêm dữ liệu.\\nNhìn chung, việc tăng kích thuớc mô hình làm giảm đ ộ chệch, nhưng nó cũng có thể\\nlàm tăng phuơng sai và tăng nguy cơ quá khớp. Tuy n hiên, vấn đề quá khớp này\\nthuờng chỉ phát sinh khi bạn không sử dụng điều chu ẩn (regularization ). Nếu bạn\\nthêm vào một phuơng pháp điều chuẩn được thiết kế t ốt, thì bạn thường có thể tăng\\nkích thuớc mô hình một cách an toàn mà không tăng q uá khớp.\\nGiả sử bạn đang áp dụng học sâu, với điều chuẩn L2 hoặc dropout, với tham số điều\\nchuẩn hoạt động tốt nhất tập phát triển. Nếu bạn tă ng kích thuớc mô hình, thuờng\\nthì chất lượng của mô hình sẽ giữ nguyên hoặc cải t hiện; nó thường không có khả\\nnăng xấu đi đáng kể. Lý do duy nhất của việc tránh sử dụng một mô hình lớn hơn là\\nphần chi phí tính toán tăng thêm.\\n44'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 45}, page_content='24. Đánh đổi giữa Độ chệch và Phương sai\\nBạn có thể đã nghe về \"sự đánh đổi giữa Độ chệch và  Phương sai\". Trong các thay\\nđổi khả dĩ đối với hầu hết các thuật toán học, có m ột số phương pháp giúp giảm sai\\nsố độ chệch nhưng với phải trả giá bằng việc tăng p hương sai và ngược lại. Đây là sự\\n\"đánh đổi\" giữa độ chệch và phương sai.\\nVí dụ việc tăng kích thước mô hình -- như thêm các nơ-ron/tầng trong mạng nơ-ron\\nhoặc thêm các đầu vào đặc trưng -- nhìn chung sẽ gi ảm độ chệch nhưng có thể làm\\ntăng phương sai. Ngoài ra, việc thêm điều chuẩn thư ờng làm tăng độ chệch nhưng\\ngiảm phương sai.\\nNgày nay, chúng ta có thể truy cập vào nguồn dữ liệ u phong phú và có thể sử dụng\\ncác mạng nơ-ron rất lớn (trong học sâu). Vì thế mà ta ít phải đánh đổi hơn. Hiện có\\nnhiều lựa chọn hơn để giảm độ chệch mà không làm ản h hưởng phương sai và\\nngược lại.\\nVí dụ, bạn thường có thể tăng kích thước mạng nơ-ro n và điều chỉnh phương thức\\nđiều chuẩn để giảm độ chệch mà không làm tăng đáng kể phương sai. Bằng cách\\nthêm dữ liệu huấn luyện, bạn cũng thường có thể giả m phương sai mà không ảnh\\nhưởng đến độ chệch.\\nNếu bạn chọn một kiến trúc mô hình phù hợp với tác vụ của mình, bạn cũng có thể\\ngiảm đồng thời độ chệch và phương sai. Tuy nhiên sẽ  rất khó để tìm ra một kiến trúc\\nnhư vậy.\\nTrong một vài chương tới, chúng ta sẽ thảo luận thê m về các kỹ thuật cụ thể để giải\\nquyết các vấn đề liên quan tới độ chệch và phương s ai.\\n45'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 46}, page_content='25. Kỹ thuật giảm độ chệch có thể tránh được\\nNếu thuật toán học gặp vấn đề với độ chệch có thể tránh được  lớn, bạn có thể thử\\nnhững kỹ thuật sau:\\nTăng kích thước mô hình  (ví dụ như số lượng nơ-ron/tầng): Kĩ thuật này giúp\\ngiảm độ chệch vì nó cho phép khớp (ﬁt) tập huấn luy ện tốt hơn. Nếu thấy việc\\nnày làm tăng phương sai, bạn hãy dùng điều chuẩn ( regularization ) -- thường\\ndùng để giảm trừ việc tăng phương sai.\\nThay đổi các đặc trưng đầu vào dựa trên những nhận định từ phân tích\\nlỗi: Giả sử việc phân tích lỗi gợi ý rằng nên tạo thêm  các đặc trưng bổ sung nhằm\\ngiúp thuật toán loại bỏ một nhóm các lỗi đặc thù. ( Chúng ta sẽ bàn vấn đề này\\nchi tiết hơn ở chương sau.) Những đặc trưng mới này  có thể hiệu quả với cả độ\\nchệch và phương sai. Theo lý thuyết, thêm đặc trưng  có thể làm tăng phương sai;\\ntuy nhiên nếu thấy đúng là phương sai bị tăng, thì bạn hãy dùng điều chuẩn --\\nthường dùng để loại bỏ việc tăng phương sai.\\nGiảm hoặc loại bỏ điều chuẩn  (điều chuẩn L2, điều chuẩn L1, dropout): Việc\\nnày sẽ làm giảm độ chệch có thể tránh được, nhưng s ẽ đồng thời làm tăng\\nphương sai.\\nThay đổi kiến trúc mô hình  (ví dụ như kiến trúc mạng nơ-ron) để phù hợp hơn\\nvới bài toán của bạn. Lưu ý rằng, kỹ thuật này có t hể tác động đến cả độ chệch\\nvà phương sai.\\nMột phương pháp không hữu ích:\\nThêm dữ liệu huấn luyện : Kỹ thuật này hữu ích với các vấn đề về phương sai\\nnhưng thường không có tác động đáng kể đến độ chệch .\\n46'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 47}, page_content='26. Phân tích lỗi trên tập huấn luyện\\nThuật toán của bạn phải hoạt động tốt trên tập huấn  luyện trước khi bạn có thể\\nmong đợi nó hoạt động tốt trên tập phát triển/kiểm tra.\\nNgoài các kỹ thuật giải quyết độ chệch cao được mô tả trước đây, đôi khi tôi cũng\\nthực hiện phân tích lỗi trên dữ liệu huấn luyện , theo một quá trình tương tự như\\nphân tích lỗi trên tập phát triển Eyeball. Điều này  có thể hữu ích nếu thuật toán của\\nbạn có độ chệch cao, ví dụ như nếu nó không khớp tố t với tập huấn luyện.\\nVí dụ: giả sử bạn đang xây dựng một hệ thống nhận d ạng giọng nói cho một ứng\\ndụng nào đó và đã thu thập một tập huấn luyện gồm n hiều đoạn âm thanh từ các\\ntình nguyện viên. Nếu hệ thống không hoạt động tốt trên tập huấn luyện, bạn có thể\\nxem xét việc nghe thử một bộ khoảng 100 mẫu mà thuậ t toán hoạt động kém để\\nhiểu các hạng mục lỗi chính trên tập huấn luyện. Tư ơng tự như phân tích lỗi trên tập\\nphát triển, bạn có thể đếm các lỗi theo các hạng mụ c như sau:\\nĐoạn âm\\nthanhNhiễu nền\\nlớnĐoạn nói\\nnhanhMic ở\\nxaChi tiết thêm\\n1 ✔ Tiếng ồn xe hơi\\n2 ✔ ✔ Tiếng ồn nhà hàng\\n3 ✔ ✔Người dùng la hét khắp\\nphòng khách?\\n4 ✔ Quán cà phê\\n% tổng 75% 25% 50%\\nTrong ví dụ này, bạn có thể nhận ra rằng thuật toán  đang gặp khó khăn với các mẫu\\nhuấn luyện có nhiều nhiễu nền. Do đó, bạn có thể tậ p trung vào các kỹ thuật cho\\nphép thuật toán khớp hơn với các mẫu huấn luyện có nhiễu nền.\\nBạn cũng có thể kiểm tra kỹ xem, liệu một người có thể diễn dịch với cùng các đoạn\\nâm thanh đầu vào cho thuật toán học hay không. Nếu có quá nhiều nhiễu nền,\\nnhiều đến nỗi không ai có thể nghe ra những gì được  nói, thì có thể không hợp lý khi\\nhy vọng bất kỳ thuật toán nào có thể nhận ra chính xác những phát ngôn đó. Chúng\\nta sẽ thảo luận về lợi ích của việc so sánh thuật t oán với chất lượng mức con người\\ntrong phần sau.\\n47'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 48}, page_content='27. Các kỹ thuật giảm phương sai\\nNếu như thuật toán có phương sai lớn, bạn có thể th ử các kỹ thuật sau:\\nThêm dữ liệu huấn luyện : Đây là cách đơn giản và đáng tin cậy nhất để giảm\\nphương sai, miễn là bạn có thể lấy dữ liệu nhiều hơ n đáng kể và đủ năng lực tính\\ntoán để xử lý dữ liệu.\\nThêm điều chuẩn  (điều chuẩn L2, điều chuẩn L1, dropout): Kỹ thuật nà y làm\\ngiảm phương sai nhưng cũng làm tăng độ chệch.\\nThêm kỹ thuật dừng sớm  (nghĩa là dừng sớm quá trình hạ gradient, dựa vào l ỗi\\ntrên tập phát triển): Kỹ thuật này giúp giảm phương  sai nhưng làm tăng độ\\nchệch. Kỹ thuật dừng sớm hoạt động rất giống các ph ương pháp điều chuẩn và\\nmột số tác giả cũng coi nó là một kỹ thuật điều chu ẩn.\\nChọn đặc trưng để giảm số lượng/kiểu đặc trưng đầu vào: Kỹ thuật này có\\nthể giúp giải quyết các vấn đề về phương sai, nhưng  nó cũng có thể làm tăng độ\\nchệch. Việc giảm một ít số lượng các đặc trưng (giả  sử từ 1.000 xuống 900 đặc\\ntrưng) dường như không có ảnh hưởng lớn đến độ chệc h. Việc giảm đáng kể số\\nđặc trưng (giả sử từ 1.000 xuống còn 100 đặc trưng,  hay giảm 10 lần) nhiều khả\\nnăng mang lại tác dụng đáng kể, miễn là bạn không l oại trừ quá nhiều các đặc\\ntrưng hữu ích. Trong học sâu hiện đại, khi dữ liệu dồi dào, đã có những thay đổi từ\\nviệc lựa chọn đặc trưng. Giờ đây, hầu như chúng ta dùng tất cả các đặc trưng\\nhiện có cho thuật toán và để nó tự chọn ra những đặ c trưng sẽ sử dụng dựa trên\\nchính tập dữ liệu đó. Nhưng khi tập huấn luyện nhỏ,  kỹ thuật lựa chọn đặc trưng\\nvẫn có thể rất hữu ích.\\nGiảm kích thước mô hình  (chẳng hạn như số lượng nơ-ron/tầng): Sử dụng một\\ncách thận trọng . Kỹ thuật này có thể làm giảm phương sai, trong kh i có thể làm\\ntăng độ chệch. Tuy nhiên, tôi không khuyến khích sử  dụng kỹ thuật này để giảm\\nphương sai. Thêm điều chuẩn thường cho chất lượng p hân loại tốt hơn. Ưu điểm\\ncủa việc giảm kích thước mô hình là giảm chi phí tí nh toán và do đó tăng tốc độ\\nhuấn luyện mô hình. Nếu việc tăng tốc độ huấn luyện  mô hình là hữu ích, thì hãy\\nxem xét việc giảm kích thước mô hình bằng mọi cách.  Nhưng nếu mục tiêu là\\ngiảm phương sai và bạn không quan tâm đến chi phí t ính toán, thì thay vào đó\\nbạn hãy xem xét việc thêm điều chuẩn.\\nDưới đây là hai chiến thuật bổ sung, được lặp lại t ừ chương trước về giải quyết độ\\nchệch:\\nThay đổi các đặc trưng đầu vào dựa trên nhận định t ừ phân tích lỗi : Giả\\nsử việc phân tích lỗi gợi ý rằng nên tạo thêm các đ ặc trưng bổ sung nhằm giúp\\nthuật toán loại bỏ một nhóm các lỗi đặc thù. Những đặc trưng mới này có thể\\nhiệu quả với cả độ chệch và phương sai. Theo lý thu yết, thêm đặc trưng có thể\\nlàm tăng phương sai; nhưng nếu bạn thấy đúng là phư ơng sai bị tăng, thì hãy sử\\ndụng điều chuẩn -- thường dùng để giảm trừ việc tăn g phương sai.\\n48'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 49}, page_content='Thay đổi kiến trúc mô hình  (ví dụ như kiến trúc mạng nơ-ron) để phù hợp hơn\\nvới bài toán của bạn: Kỹ thuật này có thể tác động đến cả độ lệch và phương sai.\\n49'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 50}, page_content='Phần 4: Đồ thị quá trình\\nhọc\\n50'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 51}, page_content='28. Chẩn đoán độ chệch và phương sai: Đồ thị\\nquá trình học\\nChúng ta đã xem qua một số cách ước tính số lượng l ỗi tạo ra bởi độ chệch tránh\\nđược so với phương sai. Một trong số đó là ước lượn g tỉ lệ lỗi tối ưu và tính toán lỗi\\ncủa thuật toán trên tập huấn luyện và tập phát triể n. Hãy cũng thảo luận một kỹ\\nthuật khác thậm chí còn mang lại nhiều thông tin hơ n: biểu diễn một đồ thị quá trình\\nhọc.\\nMột đồ thị quá trình học cho thấy sự tương quan giữ a lỗi của tập phát triển so với số\\nlượng các mẫu huấn luyện. Để biểu diễn nó, bạn cần áp dụng thuật toán của bạn với\\ncác tập huấn luyện có độ lớn khác nhau. Ví dụ, nếu bạn có 1.000 mẫu, bạn có thể\\nhuấn luyện riêng biệt các bản sao của thuật toán tr ên các tập 100, 200, 300, ...,\\n1.000 mẫu. Sau đó bạn có thể biểu diễn sự thay đổi giữa lỗi của tập phát triển so với\\nđộ lớn của tập huấn luyện. Dưới đây là một ví dụ:\\nKhi kích thước tập huấn luyện tăng, lỗi của tập phá t triển nên giảm.\\nChúng ta thường sẽ có một số \"tỉ lệ lỗi mong muốn\" mà chúng ta hy vọng thuật toán\\ncủa mình cuối cùng sẽ đạt được. Ví dụ:\\nNếu chúng ta hy vọng đạt được chất lượng ở cấp độ c on người, thì tỷ lệ lỗi của\\ncon người là \"tỉ lệ lỗi mong muốn\".\\nNếu thuật toán học của chúng ta được dùng trong một  sản phẩm nào đó (ví dụ\\nnhư cung cấp ảnh mèo), chúng ta có thể có một trực giác về mức chất lượng cần\\nthiết để người dùng có được trải nghiệm tốt nhất.\\nNếu bạn đã làm việc trên một ứng dụng quan trọng tr ong thời gian dài, thì bạn sẽ\\ncó trực giác về mức cải thiện hợp lý có thể đạt đượ c trong quý/năm tới.\\nThêm mức chất lượng mong muốn vào đồ thị quá trình học của bạn:\\n51'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 52}, page_content='Bạn có thể ngoại suy đường cong \"lỗi tập phát triển \" (màu đỏ) để ước tính mức độ\\ncải thiện có thể đạt được so với mức chất lượng mon g muốn bằng cách thêm dữ liệu\\nvào. Ví dụ trên cho thấy bạn có thể đạt được mức ch ất lượng mong muốn bằng cách\\ntăng gấp đôi độ lớn tập huấn luyện.\\nTuy nhiên nếu đường cong lỗi tập phát triển đã \"nằm  ngang\" (phẳng), thì bạn có thể\\nhiểu ngay lập tức rằng việc thêm vào dữ liệu cũng s ẽ không giúp bạn đạt được mục\\ntiêu:\\nDo đó nhìn vào đồ thị đường cong học tập có thể giú p bạn tránh khỏi việc dành hàng\\ntháng trời thu thập một lượng dữ liệu lớn gấp đôi, chỉ để nhận ra rằng điều đó là vô\\ních.\\nMột nhược điểm của quá trình này là nếu bạn chỉ nhì n vào đường cong lỗi của tập\\nphát triển, thì có thể bạn sẽ khó ngoại suy và dự đ oán chính xác vị trí đường cong đỏ\\nkhi có thêm dữ liệu. Một đồ thị khác có thể giúp bạ n dự đoán sự tác động của việc\\nthêm dữ liệu đó là: đồ thị lỗi tập huấn luyện.\\n52'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 53}, page_content='29. Vẽ đồ thị sai số huấn luyện\\nSai số tập phát triển (và tập kiểm tra) thường giảm  khi kích thước tập huấn luyện\\ntăng lên. Nhưng sai số tập huấn luyện lại thường xu yên tăng khi kích thước tập huấn\\nluyện tăng.\\nChúng ta hãy mô tả ảnh hưởng này bằng một ví dụ. Gi ả sử tập huấn luyện chỉ gồm 2\\nmẫu: Một ảnh mèo và một ảnh không phải mèo. Khi đó thuật toán học máy có thể\\ndễ dàng ghi nhớ cả 2 mẫu trong tập huấn luyện, và c ho 0% sai số huấn luyện. Thậm\\nchí nếu cả 2 mẫu huấn luyện bị gán nhãn sai, thuật toán vẫn ghi nhớ dễ dàng cả 2\\nnhãn.\\nBây giờ giả định tập huấn luyện có 100 mẫu. Một vài  mẫu thậm chí bị gán nhãn sai,\\nhoặc một vài hình ảnh thì không rõ ràng do bị mờ, n ên ngay cả con người cũng\\nkhông thể khẳng định đó là một chú mèo. Có lẽ thuật  toán học vẫn có thể \"ghi nhớ\"\\nđược hầu hết tập huấn luyện, nhưng nó khó mà đạt đư ợc 100% độ chính xác vào lúc\\nnày. Bằng cách gia tăng tập huấn luyện từ 2 lên 100  mẫu, bạn sẽ nhận ra rằng độ\\nchính xác của tập huấn luyện sẽ giảm một ít.\\nCuối cùng, giả sử tập huấn luyện có 10.000 mẫu. Tro ng trường hợp này, sẽ khó hơn\\ncho thuật toán khớp hoàn hảo 10.000 mẫu, đặc biệt l à nếu có một vài mẫu không rõ\\nràng hoặc bị gán sai nhãn. Do đó, trên tập huấn luy ện thuật toán của bạn sẽ hoạt\\nđộng càng kém hơn trước.\\nChúng ta hãy thêm một đồ thị sai số huấn luyện vào các hình trước đó:\\nBạn có thể thấy rằng đồ thị \"sai số huấn luyện\" (mà u xanh lam) tăng theo kích thước\\ncủa tập huấn luyện. Thêm nữa, thuật toán của bạn th ường hoạt động tốt trên tập\\nhuấn luyện hơn là tập phát triển; do đó đồ thị sai số tập phát triển (màu đỏ) hoàn\\ntoàn nằm trên đồ thị sai số huấn luyện.\\nTiếp theo chúng ta sẽ thảo luận làm thế nào để diễn  giải những đồ thị này.\\n53'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 54}, page_content='30. Diễn giải đồ thị quá trình học: Độ chệch cao\\nGiả sử đường cong sai số trên tập phát triển có dạn g như sau:\\nNhư đã thảo luận, nếu đường cong sai số trên tập ph át triển đã nằm ngang, việc chỉ\\nthêm dữ liệu sẽ khó có thể đem về hiệu suất ta mong  muốn.\\nTuy nhiên, sẽ thật khó để ngoại suy chính xác đường  cong sai số trên tập phát triển\\n(màu đỏ) sẽ trông như thế nào. Trong trường hợp tập  phát triển nhỏ, việc dự đoán\\nchính xác sẽ càng trở nên khó khăn bởi khi đó đường  cong này sẽ có khả năng bị\\nnhiễu.\\nGiả sử chúng ta thêm đường cong sai số tập huấn luy ện vào biểu đồ như hình dưới:\\n54'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 55}, page_content='Lúc này, bạn có thể hoàn toàn chắc chắn việc chỉ th êm dữ liệu là không đủ. Tại sao\\nvậy? Hãy nhớ hai nhận định sau:\\nKhi chúng ta thêm dữ liệu huấn luyện, sai số huấn l uyện chỉ có thể tăng lên. Vì vậy,\\nđường cong chỉ sai số huấn luyện (màu xanh lam) chỉ  có thể giữ nguyên hoặc hướng\\ncao lên. Bởi vậy, đường cong đó chỉ có thể cách xa hơn hiệu suất mong đợi (màu\\nxanh lục).\\nĐường cong sai số tập phát triển (màu đỏ) thường ca o hơn so với đường cong sai số\\ntập huấn luyện (màu xanh lam). Vì vậy, việc lấy thê m dữ liệu không thể nào giảm\\nđường cong sai số tập phát triển xuống mức hiệu suấ t mong muốn khi ngay cả sai\\nsố trên tập huấn luyện vẫn còn lớn hơn mức đó.\\nĐánh giá cả đường cong sai số tập phát triển lẫn đư ờng cong sai số tập huấn luyện\\ntrên cùng một biểu đồ giúp những ngoại suy về đường  cong sai số tập phát triển có\\nđộ tin cậy cao hơn.\\nĐể dễ thảo luận, giả sử hiệu suất mong muốn chính l à ước lượng của tỉ lệ lỗi tối ưu.\\nĐồ thị trên trở thành ví dụ chuẩn \"sách giáo khoa\" về hình dáng của một đồ thị quá\\ntrình học với độ chệch có thể tránh lớn: Khi tập hu ấn luyện có kích cỡ lớn nhất --\\ntương ứng với tất cả dữ liệu trong tập huấn luyện -  có một khoảng cách lớn giữa sai\\nsố huấn luyện và hiệu suất mong muốn. Đây chính là dấu hiệu của độ chệch có thể\\ntránh lớn. Ngược lại, lúc này, khoảng cách nhỏ giữa  đường cong của tập huấn luyện\\nvà đường cong của tập phát triển tương ứng với phươ ng sai nhỏ.\\nTrước kia, chúng ta chỉ đo sai số tập huấn luyện và  sai số tập phát triển tại điểm\\nngoài cùng bên phải của đồ thị, tương ứng với việc sử dụng tất cả dữ liệu trong tập\\nhuấn luyện. Biểu diễn đầy đủ đồ thị quá trình học s ẽ cho chúng ta một bức tranh\\ntổng thể hơn về chất lượng của những thuật toán trê n các kích cỡ tập huấn luyện\\nkhác nhau.\\n55'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 56}, page_content='31. Giải nghĩa các đồ thị quá trình học: Những\\ntrường hợp khác\\nHãy xem xét đồ thị quá trình học này:\\nĐồ thị này thể hiện độ chệch lớn, phương sai lớn ha y cả hai?\\nĐường cong lỗi huấn luyện (màu xanh lam) tương đối thấp và đường cong lỗi phát\\ntriển (màu đỏ) cao hơn nhiều so với lỗi huấn luyện.  Do đó, độ chệch nhỏ, nhưng\\nphương sai lớn. Thêm dữ liệu huấn luyện có thể giúp  thu hẹp khoảng cách giữa lỗi\\nphát triển và lỗi huấn luyện.\\nBây giờ, hãy xem xét đồ thị này:\\nLần này, lỗi huấn luyện lớn, vì nó cao hơn nhiều so  với mức chất lượng mong muốn.\\nLỗi phát triển cũng lớn hơn nhiều so với lỗi huấn l uyện. Vì vậy, bạn có độ chệch đáng\\nkể và phương sai cũng đáng kể. Bạn sẽ phải tìm cách  giảm cả độ chệch và phương\\nsai trong thuật toán của mình.\\n56'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 57}, page_content='32. Vẽ đồ thị quá trình học\\nGiả sử bạn có một tập huấn luyện rất nhỏ gồm 100 mẫ u. Bạn huấn luyện thuật toán\\ncủa mình bằng cách sử dụng một tập hợp con được chọ n ngẫu nhiên gồm 10 mẫu,\\nsau đó 20 mẫu, sau đó 30, lên đến 100, tăng số lượn g mẫu theo các khoảng mười.\\nSau đó, bạn sử dụng 10 điểm dữ liệu này để vẽ đồ th ị quá trình học. Bạn có thể thấy\\nrằng đồ thị trông hơi nhiễu (có nghĩa là các giá tr ị cao hơn/thấp hơn dự kiến) ở kích\\nthước tập huấn luyện nhỏ hơn.\\nKhi huấn luyện chỉ với 10 mẫu được chọn ngẫu nhiên,  bạn có thể không may mắn và\\ncó một tập huấn luyện đặc biệt \"xấu\", chẳng hạn như  một tập có nhiều mẫu không\\nrõ ràng/bị gán nhãn sai. Hoặc, bạn có thể gặp may m ắn và nhận được một tập huấn\\nluyện đặc biệt \"tốt\". Có một tập huấn luyện nhỏ đồn g nghĩa với lỗi trên tập phát\\ntriển và tập huấn luyện có thể dao động ngẫu nhiên.\\nNếu ứng dụng học máy của bạn bị lệch nhiều về một l ớp: chẳng hạn như nhiệm vụ\\nphân loại mèo mà số mẫu âm (không phải mèo) lớn hơn  nhiều số mẫu dương (là\\nmèo). Hoặc, nếu nó có một số lượng lớn các lớp (chẳ ng hạn như nhận dạng 100 loài\\nđộng vật khác nhau), khi đó xác suất chọn một tập h uấn luyện rất không \"mang tính\\nđại diện\" hoặc xấu cũng lớn hơn. Ví dụ: nếu 80% mẫu  của bạn là mẫu âm (y = 0), và\\nchỉ 20% là mẫu dương (y = 1), thì có khả năng một t ập huấn luyện gồm 10 mẫu chỉ\\nchứa các mẫu âm, thì rất khó để thuật toán học được  điều gì đó có ý nghĩa.\\nNếu nhiễu trong đồ thị quá trình học khiến bạn khó nhìn thấy xu hướng thực sự, thì\\nđây là hai giải pháp:\\nThay vì chỉ huấn luyện một mô hình trên 10 mẫu, hãy  chọn ra ngẫu nhiên một vài\\n(ví dụ 3-10) tập huấn luyện khác nhau gồm 10 mẫu bằ ng cách lấy mẫu có hoàn\\nlại [10] từ bộ dữ liệu 100 mẫu ban đầu. Huấn luyện mô hình khác nhau trên mỗi\\ntập đó và tính toán lỗi huấn luyện, lỗi phát triển của từng mô hình sau khi huấn\\nluyện xong. Tính toán và vẽ đồ thị lỗi trung bình t rên tập huấn luyện và lỗi trung\\nbình trên tập phát triển.\\nNếu tập huấn luyện của bạn bị lệch về một lớp, hoặc  nếu nó có nhiều lớp, hãy\\nchọn một tập hợp con \"cân bằng\" thay vì chọn ngẫu n hiên 10 trên 100 mẫu huấn\\nluyện. Ví dụ, bạn có thể chắc chắn rằng 2/10 các mẫ u là các mẫu dương và 8/10\\nlà âm. Tổng quát hơn, bạn có thể đảm bảo tỷ lệ các mẫu trong mỗi lớp càng gần\\nvới tỉ lệ trong tập huấn luyện ban đầu.\\nNếu bạn đã thử vẽ các đồ thị quá trình học và kết l uận rằng các đường cong quá\\nnhiễu để nhìn thấy các xu hướng cơ bản, thì hãy sử dụng một trong những kỹ thuật\\ntrên. Nếu tập huấn luyện của bạn có quy mô lớn, ví dụ hơn 10.000 mẫu, và phân\\nphối lớp của bạn không bị lệch nhiều, có lẽ bạn khô ng cần các kỹ thuật này.\\nCuối cùng, vẽ đồ thị quá trình học có thể tốn kém v ề mặt tính toán: Ví dụ: bạn có\\nthể phải huấn luyện mười mô hình với 1.000, rồi 2.0 00, cho đến 10.000 mẫu. Huấn\\nluyện các mô hình với các bộ dữ liệu nhỏ nhanh hơn nhiều so với huấn luyện các mô\\nhình với các bộ dữ liệu lớn. Do đó, thay vì cách đề u các kích thước tập huấn luyện\\n57'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 58}, page_content='theo tỷ lệ tuyến tính như trên, bạn có thể huấn luy ện các mô hình với 1.000, 2.000,\\n4.000, 6.000 và 10.000 mẫu. Điều này vẫn sẽ cung cấ p cho bạn một cảm giác rõ\\nràng về các xu hướng trong các đồ thị quá trình học . Tất nhiên, kỹ thuật này chỉ\\nthích hợp nếu chi phí tính toán để huấn luyện tất c ả các mô hình bổ sung là đáng\\nkể.\\nCHÚ THÍCH\\n[10] Ở đây, việc lấy mẫu có hoàn lại  có nghĩa là: Bạn sẽ chọn ngẫu nhiên 10 mẫu\\nkhác nhau trong số 100 để tạo thành tập huấn luyện đầu tiên của mình. Sau đó để\\ntạo tập huấn luyện thứ hai, bạn sẽ lại lấy 10 mẫu n gẫu nhiên trong 100 mẫu ban\\nđầu. Vì vậy, có thể một mẫu cụ thể xuất hiện trong cả tập huấn luyện thứ nhất và\\nthứ hai. Ngược lại, nếu bạn lấy mẫu không hoàn lại , tập huấn luyện thứ hai sẽ chỉ\\nđược chọn từ 90 mẫu không được chọn ở lần đầu tiên.  Trong thực tế, sử dụng lấy\\nmẫu có hoàn lại hoặc không hoàn lại không tạo ra sự  khác biệt lớn, nhưng lấy mẫu\\ncó hoàn lại là cách làm phổ biến.\\n58'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 59}, page_content='Phần 5: So sánh với chất\\nlượng mức con người\\n59'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 60}, page_content='33. Tại sao cần so sánh chất lượng mức con\\nngười?\\nNhiều hệ thống học máy hướng tới tự động hóa những thứ con người làm tốt. Ví dụ\\nnhư nhận dạng hình ảnh, nhận dạng giọng nói, và phâ n loại thư rác. Các thuật toán\\nhọc cũng đã được cải thiện rất nhiều, đến mức vượt qua chất lượng mức con người\\ntrong ngày càng nhiều tác vụ.\\nHơn nữa, có rất nhiều lý do khiến việc xây dựng một  hệ thống học máy dễ dàng hơn\\nnếu bạn đang giải quyết một tác vụ mà con người có thể làm tốt:\\n1. Dễ dàng thu thập dữ liệu từ người gán nhãn . Ví dụ, con người nhận diện hình\\nảnh mèo tốt, nên tất nhiên việc dùng người để gán n hãn sẽ cung cấp nhãn có độ\\nchính xác cao cho thuật toán học.\\n2. Phân tích lỗi có thể dựa vào trực giác của con ngườ i. Giả sử rằng một thuật\\ntoán nhận dạng giọng nói hoạt động kém hơn so với c on người. Giả dụ nó ghi\\nnhầm một đoạn âm thanh thành \"This recipe calls for  a pear of apples,\" (dịch là\\n\"công thức nấu ăn này cần một quả lê của táo\") với lỗi từ \"pair\" trở thành \"pear\".\\nBạn có thể dựa vào trực giác và cố gắng hiểu thông tin nào mà con người dùng\\nđể nghe ra được bản ghi thoại chuẩn và dùng thông t in này để điều chỉnh thuật\\ntoán.\\n3. Sử dụng chất lượng mức con người để ước tính tỷ lệ lỗi tối ưu cũng như\\nđặt ra một \"tỷ lệ lỗi mong muốn.\"  Giả sử thuật toán của bạn trả về 10% lỗi\\ntrong một tác vụ, nhưng con người chỉ lỗi 2%. Dựa v ào đó, chúng ta biết rằng tỷ\\nlệ lỗi tối ưu bằng hoặc nhỏ hơn 2% và độ chệch có t hể tránh được ở mức nhỏ nhất\\nlà 8%. Vì vậy, bạn nên thử các kỹ thuật giảm độ chệ ch.\\nMặc dù mục số 3 dường như không quan trọng, tôi thấ y rằng việc đặt mục tiêu về tỷ\\nlệ lỗi ở mức hợp lý sẽ giúp đẩy nhanh tiến độ của n hóm. Việc biết thuật toán của\\nbạn có độ chệch cao có thể tránh được là vô cùng có  giá trị và mở ra nhiều tùy chọn\\nđể thử nghiệm.\\nCó những tác vụ mà ngay cả con người cũng làm không  tốt. Ví dụ, chọn một cuốn\\nsách để giới thiệu cho bạn; hoặc chọn một tin quảng  cáo để hiển thị cho người dùng\\ntrên một trang web; hoặc dự đoán thị trường chứng k hoán. Máy tính đã làm việc\\nhiệu quả hơn hầu hết mọi người trong những tác vụ n ày. Với các ứng dụng này,\\nchúng ta gặp phải các vấn đề sau:\\nKhó khăn hơn khi gán nhãn. Ví dụ, người gán nhãn kh ó có thể dán nhãn một cơ sở\\ndữ liệu người dùng cho tác vụ \"tối ưu\" việc gợi ý s ách. Nếu đang vận hành một\\ntrang web hoặc ứng dụng bán sách, bạn có thể lấy dữ  liệu bằng cách hiển thị\\nsách cho người dùng và xem những gì họ mua. Nếu khô ng vận hành một trang\\nweb như vậy, bạn cần tìm những cách sáng tạo hơn để  lấy dữ liệu.\\nKhó tin tưởng trực giác của con người. Ví dụ, gần n hư không ai có thể dự đoán\\nđược thị trường chứng khoán. Vì thế, nếu thuật toán  dự đoán cổ phiếu của chúng\\n60'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 61}, page_content='ta không tốt hơn dự đoán ngẫu nhiên, thì thật khó đ ể tìm ra cách cải thiện nó.\\nKhó tìm ra tỷ lệ lỗi tối ưu và tỷ lệ lỗi mong muốn hợp lý. Giả sử bạn đã có một hệ\\nthống giới thiệu sách đang hoạt động khá tốt. Làm t hế nào để bạn biết mình có\\nthể cải thiện nó thêm bao nhiêu nếu không có giải p háp cấp con người?\\n61'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 62}, page_content='34. Cách xác định chất lượng mức con người\\nGiả sử bạn đang làm việc trên một ứng dụng hình ảnh  y tế mà tự động đưa ra chẩn\\nđoán từ ảnh X quang. Với tác vụ chuẩn đoán này, một  người bình thường không có\\nnền tảng y học nào ngoài một số đào tạo cơ bản có m ức 15% lỗi. Một bác sĩ trẻ mới\\nra trường có mức 10% lỗi. Một bác sĩ dày dặn kinh n ghiệm đạt được mức 5% lỗi. Và\\nmột nhóm nhỏ các bác sĩ cùng trao đổi và thảo luận từng ảnh đạt được mức 2% lỗi.\\nVậy cái nào trong những tỉ lệ lỗi này được định ngh ĩa là \"chất lượng mức con người\"?\\nTrong trường hợp này, tôi sẽ lấy 2% làm \"chất lượng  mức con người\" cho tỉ lệ lỗi tối\\nưu của chúng ta. Bạn cũng có thể đặt 2% làm mức chấ t lượng mong muốn vì nó\\nthỏa mãn cả ba lý do (trình bày ở chương trước) để so sánh với chất lượng mức con\\nngười:\\nDễ dàng lấy dữ liệu từ người gán nhãn.  Bạn có thể nhờ một nhóm bác sĩ dán\\nnhãn cho bạn với tỉ lệ lỗi 2%.\\nPhân tích lỗi dựa vào trực giác.  Bằng cách thảo luận hình ảnh với một nhóm\\ncác bác sĩ, bạn có thể dựa vào trực giác của họ để phân tích lỗi.\\nDùng chất lượng mức con người để ước tính tỉ lệ lỗi t ối ưu cũng như đặt\\nra \"tỉ lệ lỗi mong muốn\" khả thi.  Việc dùng mức 2% làm ước lượng về tỉ lệ lỗi\\ntối ưu là hợp lý. Tỉ lệ lỗi tối ưu thậm chí có thể thấp hơn 2%, nhưng không thể lớn\\nhơn, vì một nhóm bác sĩ có thể đạt được mức 2% lỗi.  Ngược lại, sẽ không hợp lý\\nkhi sử dụng 5% hoặc 10% làm ước lượng cho tỉ lệ lỗi  tối ưu, vì chúng ta biết các\\nmức ước tính này quá lớn.\\nKhi lấy dữ liệu được gán nhãn, có thể bạn không muố n thảo luận về mọi bức ảnh với\\ntoàn bộ đội ngũ bác sĩ vì thời gian của họ rất đáng  giá. Nhưng bạn có thể nhờ một\\nbác sĩ trẻ mới ra trường gán nhãn cho phần lớn các trường hợp và chỉ dành những\\ntrường hợp khó hơn cho các bác sĩ có kinh nghiệm hơ n hoặc cho đội ngũ bác sĩ.\\nNếu hệ thống hiện tại của bạn có mức 40% lỗi, thì v iệc nhờ một bác sĩ mới ra trường\\n(10% lỗi) hay một bác sĩ có kinh nghiệm (5% lỗi) để  gán nhãn và đưa ra những phán\\nđoán trực giác không đem lại nhiều khác biệt. Nhưng  nếu hệ thống của bạn đang có\\n10% lỗi, thì việc xác định chất lượng mức con người  ở mức 2% sẽ cho bạn các công\\ncụ tốt hơn để tiếp tục cải thiện hệ thống của mình.\\n62'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 63}, page_content='35. Vượt qua chất lượng mức con người\\nBạn đang làm về nhận dạng giọng nói và có một tập d ữ liệu là các đoạn âm thanh.\\nGiả sử, tập dữ liệu đó có nhiều đoạn âm thanh nhiễu  mà thậm chí con người cũng\\nmắc phải 10% lỗi. Giả sử, hệ thống của bạn đã đạt đ ược 8% lỗi. Liệu bạn có thể sử\\ndụng bất kỳ kỹ thuật nào trong ba kỹ thuật được mô tả trong Chương 33 để tiếp tục\\ntiến bộ nhanh chóng không?\\nNếu có thể xác định một tập dữ liệu con mà con ngườ i đạt chất lượng cao hơn đáng\\nkể so với hệ thống của bạn, thì bạn vẫn có thể sử d ụng các kỹ thuật đó để thúc đẩy\\ntiến trình nhanh chóng. Ví dụ, giả sử hệ thống của bạn tốt hơn nhiều so với con\\nngười trong việc nhận dạng giọng nói trong âm thanh  nhiễu, nhưng con người vẫn\\ntốt hơn trong việc ghi lại lời nói rất nhanh.\\nĐối với tập dữ liệu con với lời nói nhanh, bạn có t hể:\\n1. lấy bản ghi thoại từ con người với chất lượng ca o hơn so với đầu ra thuật toán của\\nbạn.\\n2. dựa vào trực giác để hiểu lý do tại sao họ nghe chính xác một phát ngôn nhanh\\nkhi hệ thống của bạn chưa thể.\\n3. dùng chất lượng mức con người trên lời nói nhanh  như một mục tiêu chất lượng\\nmong muốn.\\nTổng quát hơn, miễn là có các mẫu trong tập phát tr iển mà con người làm đúng và\\nthuật toán của bạn làm sai, thì rất nhiều kỹ thuật được mô tả trước đây sẽ áp dụng\\nđược. Điều này vẫn đúng ngay cả khi chất lượng thật  toán của bạn (tính trung bình\\ntrên toàn bộ tập phát triển/kiểm tra) đã vượt qua c hất lượng mức con người.\\nCó nhiều ứng dụng học máy quan trọng mà máy đã vượt  qua chất lượng mức con\\nngười. Ví dụ, máy làm tốt hơn trong việc dự đoán xế p hạng phim, ước lượng thời gian\\ndi chuyển của một chiếc xe giao hàng hoặc có chấp n hận hồ sơ vay vốn hay không.\\nChỉ một phần những kỹ thuật này là áp dụng được một  khi con người còn gặp khó\\nkhăn trong việc xác định các mẫu mà thuật toán còn rõ ràng đang làm sai. Do đó,\\ntiến độ thường chậm hơn trong các vấn đề mà máy đã vượt qua chất lượng mức con\\nngười, và ngược lại, nhanh hơn khi máy vẫn đang cố gắng bắt kịp con người.\\n63'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 64}, page_content='Phần 6: Huấn luyện và\\nkiểm tra trên các phân\\nphối khác nhau\\n64'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 65}, page_content='36. Khi nào bạn nên huấn luyện và kiểm tra\\ntrên những phân phối khác nhau\\nNgười dùng ứng dụng ảnh mèo của bạn đã đăng tải 10. 000 tấm ảnh mà sau đó bạn\\nđã gán nhãn có mèo hoặc không có mèo cho tất cả một  cách thủ công. Bạn cũng có\\nmột tập ảnh lớn hơn gồm 200.000 tấm bạn đã tải từ t rên mạng về. Bạn nên tạo tập\\nhuấn luyện/phát triển/kiểm tra như thế nào?\\nVì 10.000 tấm ảnh của người dùng phản ánh chính xác  phân bố xác suất của dữ liệu\\nmà bạn muốn hệ thống hoạt động tốt trong tương lai,  bạn có thể sử dụng chúng cho\\ntập phát triển và kiểm tra. Nếu bạn đang huấn luyện  một thuật toán học sâu \"đói\"\\ndữ liệu, bạn có thể đưa thêm 200.000 tấm ảnh trên m ạng cho việc huấn luyện. Do\\nvậy, tập huấn luyện và tập phát triển/kiểm tra sẽ đ ến từ những phân phối khác\\nnhau. Điều này ảnh hưởng thế nào tới công việc của bạn?\\nThay vì phân chia dữ liệu của chúng ta ra thành tập  huấn luyện/phát triển/kiểm tra,\\nchúng ta có thể lấy hết 210.000 tấm ảnh mà ta có, v à trộn một cách ngẫu nhiên vào\\ncác tập huấn luyện/phát triển/kiểm tra. Trong trườn g hợp này, tất cả dữ liệu đều đến\\ntừ cùng một phân phối. Nhưng tôi không ủng hộ phươn g pháp này, bởi vì khoảng\\n205.000/210.000 ≈ 97,6% dữ liệu phát triển/kiểm tra  đến từ những ảnh trên mạng\\nnên nó không phản ánh được phân phối thật mà bạn mu ốn hệ thống đạt được chất\\nlượng cao. Hãy nhớ lời khuyên này khi chọn tập phát  triển/kiểm tra:\\nChọn tập phát triển và kiểm tra phản ánh dữ liệu bạ n mong muốn hệ thống hoạt\\nđộng tốt trong tương lai.\\nĐa số các tài liệu học thuật về học máy đều giả địn h tập huấn luyện, tập phát triển\\nvà tập kiểm tra đến từ cùng một phân phối [11]. Tro ng những ngày đầu của học\\nmáy, dữ liệu rất khan hiếm. T a thường chỉ có một bộ  dữ liệu được lấy ra từ một phân\\nbố xác suất nào đó. Bởi vậy, ta thường phân tách mộ t cách ngẫu nhiên dữ liệu đó\\nthành tập huấn luyện/phát triển/kiểm tra, và việc m ặc định tất cả các dữ liệu đến từ\\ncùng một nguồn thường được thỏa mãn.\\nNhưng trong thời đại của dữ liệu lớn, ta nay đã có thể tiếp cận với những tập huấn\\nluyện khổng lồ, chẳng hạn như những tấm ảnh mèo trê n mạng. Kể cả khi tập huấn\\nluyện đến từ một phân phối khác với tập phát triển/ kiểm tra, ta vẫn muốn sử dụng\\nchúng cho quá trình học bởi vì chúng có thể cung cấ p rất nhiều thông tin.\\nVới ví dụ về bộ nhận diện mèo, thay vì bỏ toàn bộ 1 0.000 tấm ảnh do người dùng\\nđăng tải vào tập phát triển/kiểm tra, thay vào đó t a chỉ bỏ 5.000 tấm vào tập phát\\ntriển/kiểm tra. Còn lại 5.000 tấm do người dùng đăn g tải, ta có thể bỏ vào tập huấn\\nluyện. Bằng cách này, tập huấn luyện gồm 205.000 mẫ u sẽ chứa một vài dữ liệu đến\\ntừ phân phối của tập phát triển/kiểm tra cùng với 2 00.000 tấm từ internet. Chúng ta\\nsẽ bàn thêm trong chương sau lý do vì sao phương ph áp này lại hữu dụng.\\nHãy xem xét một ví dụ thứ hai. Giả sử bạn đang xây dựng một hệ thống nhận diện\\ngiọng nói để phiên thoại địa chỉ đường cho một ứng dụng bản đồ/định vị trên di động\\n65'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 66}, page_content='điều khiển bằng giọng nói. Bạn có 20.000 mẫu của ng ười dùng nói về địa chỉ đường.\\nNhưng bạn cũng có 500.000 mẫu là những bản ghi âm k hác của người dùng đang\\nnói về những chủ đề khác. Bạn có thể lấy 10.000 mẫu  nói về địa chỉ đường cho tập\\nphát triển/kiểm tra, và sử dụng 10.000 mẫu còn lại,  cộng thêm 500.000 mẫu, cho\\nviệc huấn luyện.\\nChúng ta sẽ tiếp tục giả định rằng dữ liệu phát tri ển và dữ liệu kiểm tra của bạn đến\\ntừ cùng một phân phối. Nhưng cũng quan trọng khi hi ểu rằng phân bố tập huấn\\nluyện và phát triển/kiểm tra khác nhau sẽ dẫn tới m ột vài thách thức đặc biệt.\\nCHÚ THÍCH:\\n[11] Có một vài nghiên cứu khoa học về việc huấn lu yện và kiểm tra trên các phân\\nphối khác nhau. Những ví dụ bao gồm \"thích ứng miền \", \"học chuyển tiếp\" và \"học\\nđa nhiệm\". Tuy nhiên vẫn còn một khoảng cách lớn gi ữa lý thuyết và thực hành. Nếu\\nbạn huấn luyện trên bộ dữ liệu A và kiểm tra trên m ột vài kiểu dữ liệu rất khác B,\\nmay mắn sẽ có ảnh hưởng rất lớn tới việc thuật toán  của bạn hoạt động tốt thế nào.\\n(Ở đây, \"may mắn\" bao gồm những đặc trưng được tạo thủ công cho một bài toán\\nnhất định của người làm nghiên cứu, cũng như một và i nhân tố khác mà chúng ta\\nvẫn chưa hiểu rõ.) Điều này làm cho đề tài nghiên c ứu khoa học của việc huấn luyện\\nvà kiểm tra trên những phân phối khác nhau khó có t hể hoàn thành một cách có hệ\\nthống.\\n66'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 67}, page_content='37. Làm sao để quyết định có nên sử dụng toàn\\nbộ dữ liệu?\\nGiả sử tập huấn luyện của bộ nhận diện mèo có 10.00 0 hình ảnh do người dùng tải\\nlên. Dữ liệu này đến từ cùng phân phối với một tập phát triển/kiểm tra riêng biệt.\\nChúng đại diện cho phân phối dữ liệu mà bạn muốn hệ  thống đạt được chất lượng\\ncao với nó. Bạn cũng có thêm 20.000 ảnh được tải xu ống từ internet. Bạn có nên\\ncung cấp tất cả 20.000 + 10.000 = 30.000 ảnh cho th uật toán học dưới dạng tập\\nhuấn luyện, hay nên loại bỏ 20.000 ảnh từ internet để tránh làm chệch đi thuật toán\\nhọc của bạn?\\nKhi sử dụng các thuật toán học thế hệ trước (chẳng hạn như các đặc trưng thị giác\\nmáy tính được thiết kế thủ công, theo sau là một bộ  phân loại tuyến tính đơn giản),\\nsẽ có rủi ro khi kết hợp cả hai loại dữ liệu sẽ khi ến chất lượng của hệ thống tệ đi. Do\\nđó, một số kỹ sư sẽ cảnh báo bạn đừng thêm 20.000 ả nh internet vào.\\nNhưng ngày nay với các thuật toán học linh hoạt và mạnh mẽ -- chẳng hạn như các\\nmạng nơ-ron lớn -- rủi ro này đã giảm đi rất nhiều.  Nếu bạn có đủ khả năng để xây\\ndựng một mạng nơ-ron với số lượng đơn vị và tầng ẩn  đủ lớn, bạn có thể an toàn\\nthêm 20.000 hình ảnh vào tập huấn luyện. Việc thêm nhiều hình ảnh học có khả\\nnăng giúp hệ thống nâng cao chất lượng.\\nNhận định này dựa trên thực tế là có một số ánh xạ x -> y hoạt động tốt cho cả hai\\nloại dữ liệu. Nói cách khác, vẫn tồn tại một số hệ thống nhận đầu vào là ảnh internet\\nhoặc ảnh từ ứng dụng di động và dự đoán nhãn ảnh mộ t cách đáng tin cậy, ngay cả\\nkhi không biết nguồn gốc của nó.\\nThêm vào 20.000 hình ảnh bổ sung có những ảnh hưởng  sau:\\n1. Nó cung cấp cho mạng nơ-ron của bạn nhiều mẫu hơ n về những gì giống/không\\ngiống mèo. Điều này rất hữu ích, vì hình ảnh trên i nternet và hình ảnh từ ứng\\ndụng di động do người dùng tải lên có chung một số điểm tương đồng. Mạng nơ-\\nron của bạn có thể áp dụng một số kiến thức thu đượ c từ hình ảnh internet vào\\nhình ảnh ứng dụng di động.\\n2. Nó buộc mạng nơ-ron phải sử dụng một số nguồn lự c của nó để tìm hiểu về các\\nthuộc tính dành riêng cho hình ảnh trên internet (c hẳng hạn như độ phân giải cao\\nhơn, các phân phối khác nhau về cách các hình ảnh đ ược đóng khung, v.v.) Nếu\\ncác thuộc tính này khác nhiều so với hình ảnh ứng d ụng di động, nó sẽ \"sử dụng\\nhết\" khả năng biễu diễn của mạng nơ-ron. Vì vậy khả  năng nhận biết dữ liệu trên\\nphân phối ảnh ứng dụng di động sẽ ít hơn, trong khi  đó mới là điều bạn thực sự\\nquan tâm. Trên lý thuyết, điều này có thể gây tổn t hương đến chất lượng thuật\\ntoán của bạn.\\nĐể mô tả ảnh hưởng thứ hai theo các thuật ngữ khác nhau, chúng ta có thể mượn\\nnhân vật hư cấu Sherlock Holmes, người nói rằng bộ não của bạn giống như một căn\\ngác; nó chỉ có một không gian hữu hạn. Anh ta nói r ằng \"mỗi lần bổ sung kiến thức,\\n67'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 68}, page_content='bạn sẽ quên đi những điều mà bạn biết trước đây. Do  đó, điều quan trọng bậc nhất\\nlà không để những thông tin vô dụng lấn át những th ông tin hữu ích.\" [12]\\nMay mắn thay, nếu bạn có đủ khả năng tính toán để x ây dựng một mạng nơ-ron lớn\\n-- nói như trên là có một căn gác đủ lớn -- thì đây  không phải là một vấn đề nghiêm\\ntrọng. Bạn có đủ năng lực để học từ cả hình ảnh int ernet và từ hình ảnh ứng dụng di\\nđộng mà không có sự cạnh tranh về dung lượng giữa h ai loại dữ liệu. \"Bộ não\" của\\nthuật toán cần đủ lớn để bạn không phải lo lắng về việc hết không gian căn gác.\\nNhưng nếu bạn không có một mạng nơ-ron đủ lớn (hoặc  một thuật toán học rất linh\\nhoạt nào đó), thì bạn nên chú ý hơn đến dữ liệu huấ n luyện tương đồng với phân\\nphối trên tập phát triển/kiểm tra của bạn.\\nNếu bạn nghĩ rằng dữ liệu nào đó không giá trị, bạn  nên loại bỏ dữ liệu đó vì khả\\nnăng tính toán là có hạn. Ví dụ: giả sử tập huấn lu yện/kiểm tra của bạn chứa chủ\\nyếu là hình ảnh thông thường về người, địa điểm, đị a danh, động vật. Giả sử bạn\\ncũng có một bộ sưu tập lớn bản scan các tài liệu lị ch sử:\\nNhững tài liệu này nhìn không có gì giống mèo cả. C húng cũng trông hoàn toàn\\nkhông giống như tập phân phối phát triển/kiểm tra c ủa bạn. Hoàn toàn không có ý\\nnghĩa gì khi giữ lại dữ liệu này để làm mẫu thử âm tính vì lợi ích thứ nhất như nêu ở\\ntrên là không đáng kể -- mạng nơ-ron hầu như không thể học được gì từ dữ liệu này\\nđể có thể áp dụng cho phân phối tập phát triển/kiểm  tra của bạn. Giữ lại chúng sẽ\\nlãng phí tài nguyên tính toán và khả năng biễu diễn  của mạng nơ-ron.\\nCHÚ THÍCH:\\n[12] Trích từ \"A Study in Scarlet\" của Arthur Conan  Doyle\\n68'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 69}, page_content='38. Làm thế nào để quyết định có nên bao gồm\\ndữ liệu không nhất quán\\nGiả sử bạn có thuật toán học dự đoán giá nhà ở Thàn h phố New York. Với kích thước\\ncủa một ngôi nhà (đặc trưng đầu vào x), bạn muốn dự  đoán mức giá (nhãn mục tiêu\\ny).\\nGiá nhà ở Thành phố New York rất cao. Giả sử bạn có  bộ dữ liệu thứ hai về giá nhà\\nđất ở Detroit, Michigan, nơi giá nhà đất thấp hơn n hiều. Bạn có nên bao gồm dữ liệu\\nnày trong tập huấn luyện của bạn không?\\nVới cùng kích thước x, giá của ngôi nhà y rất khác nhau tùy thuộc vào việc nó ở\\nThành phố New York hay ở Detroit. Nếu bạn chỉ quan tâm đến việc dự đoán giá nhà\\nở Thành phố New York, việc đặt hai bộ dữ liệu lại v ới nhau sẽ làm tổn hại đến hiệu\\nsuất của bạn. Trong trường hợp này, tốt hơn hết là bỏ qua dữ liệu không nhất quán\\nở Detroit. [13]\\nVí dụ về Thành phố New York và Detroit này khác gì so với ví dụ về ảnh mèo từ ứng\\ndụng di động và ảnh trên internet?\\nVí dụ về ảnh mèo khác trường hợp trên bởi vì, với m ột ảnh đầu vào x, ta có thể dự\\nđoán một cách đáng tin cậy nhãn y liệu có mèo trong  ảnh hay không mà không cần\\nbiết hình ảnh đó là từ internet hay từ ứng dụng di động. Nghĩa là, có một hàm f(x)\\nánh xạ đáng tin cậy từ đầu vào x đến đầu ra mục tiê u y, ngay cả khi không biết\\nnguồn gốc của x. Do đó, nhiệm vụ nhận dạng hình ảnh  từ internet là nhiệm vụ nhất\\nquán với nhiệm vụ nhận dạng hình ảnh từ ứng dụng di  động. Điều này có nghĩa là có\\nrất ít nhược điểm (ngoài chi phí tính toán) khi bao  gồm tất cả các dữ liệu nhưng lại\\ncó thể có những ưu điểm lớn. Ngược lại, dữ liệu của  Thành phố New York với Detroit\\nvà Michigan không nhất quán. Cho cùng một x (kích t hước của ngôi nhà), giá nhà rất\\nkhác nhau tùy thuộc vào vị trí ngôi nhà.\\nCHÚ THÍCH:\\n[13] Có một cách để giải quyết vấn đề dữ liệu Detro it không nhất quán với dữ liệu\\ncủa Thành phố New York, đó là thêm một đặc trưng bi ểu diễn thành phố. Cho một\\nđầu vào x mà có chứa thêm đặc trưng biểu diễn thành  phố, giá trị mục tiêu y bây giờ\\nkhông còn mập mờ nữa. Tuy nhiên, trong thực tế tôi không thấy điều này được thực\\nhiện thường xuyên.\\n69'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 70}, page_content='39. Đánh trọng số dữ liệu\\nGiả sử bạn có 200.000 hình ảnh từ internet và 5.000  hình ảnh từ người dùng ứng\\ndụng di động của bạn. Tỷ lệ kích thước giữa các bộ dữ liệu này là 40:1. Về lý thuyết,\\nmiễn là bạn xây dựng một mạng nơ-ron khổng lồ và hu ấn luyện nó đủ lâu trên tất cả\\n205.000 hình ảnh thì sẽ không có vấn đề gì khi cố g ắng làm cho thuật toán hoạt\\nđộng tốt trên cả hình ảnh từ internet và hình ảnh t ừ di động.\\nNhưng trên thực tế, việc có hình ảnh từ internet gấ p 40 lần so với hình ảnh từ ứng\\ndụng di động có thể nghĩa là bạn cần phải sử dụng 4 0 lần (hoặc nhiều hơn) tài\\nnguyên tính toán để mô hình hóa cả hai, so với nếu bạn chỉ đào tạo trên 5.000 hình\\nảnh.\\nNếu bạn không có tài nguyên tính toán khổng lồ, bạn  có thể thoả hiệp bằng cách\\ngán trọng số với giá trị thấp hơn đáng kể cho các h ình ảnh từ internet.\\nVí dụ, giả sử mục tiêu tối ưu của bạn là sai số bìn h phương (Đây không phải là một\\nlựa chọn tốt cho một tác vụ phân loại, nhưng nó sẽ đơn giản hóa lời giải thích của\\nchúng ta.) Vì vậy, thuật toán học tập của chúng ta cố gắng tối ưu hóa:\\nTổng đầu tiên phía trên là trên 5.000 hình ảnh từ d i động và tổng thứ hai là trên\\n200.000 hình ảnh từ internet. Bạn cũng có thể tối ư u với một tham số bổ sung β:\\nNếu bạn chọn trọng số β = 1/40, thuật toán sẽ đối x ử với 5.000 hình ảnh từ di động\\ntương đương với 200.000 hình ảnh từ internet. Bạn c ũng có thể chọn các giá trị khác\\ncho β, chẳng hạn như tinh chỉnh theo tập phát triển .\\nKhi giảm trọng số các hình ảnh được bổ sung từ Inte rnet, bạn không cần phải xây\\ndựng một mạng nơ-ron khổng lồ để đảm bảo thuật toán  thực hiện tốt trên cả hai tác\\nvụ. Việc đánh lại trọng số này chỉ cần thiết khi bạ n nghi ngờ dữ liệu bổ sung (hình\\nảnh từ internet) có phân phối rất khác so với tập p hát triển/kiểm tra, hoặc nếu dữ\\nliệu bổ sung lớn hơn nhiều so với dữ liệu mà có cùn g phân phối với tập phát\\ntriển/kiểm tra (hình ảnh từ di động).\\n70'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 71}, page_content='40. Tổng quát hóa từ tập huấn luyện đến tập\\nphát triển\\nGiả sử bạn đang áp dụng học máy cho một ứng dụng mà  phân phối của tập huấn\\nluyện và tập phát triển/kiểm tra khác nhau. Tập huấ n luyện chứa ảnh Internet + ảnh\\nĐiện Thoại trong khi tập phát triển/kiểm tra chỉ ch ứa ảnh Điện Thoại. Tuy nhiên,\\nthuật toán của bạn không hoạt động tốt: Mức lỗi trê n tập phát triển/kiểm tra cao hơn\\nnhiều con số mong muốn. Một số nguyên nhân có thể g ây ra vấn đề trên là:\\n1. Thuật toán không hoạt động tốt trên tập huấn luy ện. Đây là vấn đề của độ chệnh\\ncao (tránh được) trên phân phối của tập huấn luyện.\\n2. Thuật toán hoạt động tốt trên tập huấn luyện, nh ưng không tổng quát hóa tốt\\ntrên dữ liệu được trích xuất từ cùng phân phối với tập huấn luyện  mà thuật toán\\nchưa thấy trước đó. Trường hợp này là phương sai ca o.\\n3. Thuật toán tổng quát hóa tốt với dữ liệu mới, đư ợc trích xuất từ cùng phân phối\\nvới tập huấn luyện, nhưng không tốt với dữ liệu trí ch xuất từ phân phối của tập\\nphát triển/kiểm tra. Chúng ta gọi vấn đề này là dữ liệu không tương đồng  bởi\\ndữ liệu của tập huấn luyện khớp kém so với dữ liệu của tập phát triển/kiểm tra.\\nVí dụ, giả sử con người đạt chất lượng hoàn hảo tro ng việc nhận dạng mèo. Thuật\\ntoán của bạn đạt được các kết quả như sau:\\n1% lỗi trên tập huấn luyện\\n1.5% lỗi trên dữ liệu trích xuất từ cùng phân phối với tập huấn luyện mà thuật\\ntoán chưa thấy trước đó\\n10% lỗi trên tập phát triển\\nTrường hợp này, bạn rõ ràng có vấn đề về dữ liệu kh ông tương đồng. Để khắc phục,\\nbạn có thể cố gắng xử lý dữ liệu huấn luyện sao cho  giống hơn với dữ liệu trên tập\\nphát triển/kiểm tra. Chúng ta sẽ bàn luận các kỹ th uật xử lý vấn đề này về sau.\\nĐể chẩn đoán mức độ tác động tới thuật toán từ mỗi vần đề 1-3 ở trên, việc sở hữu\\nmột bộ dữ liệu khác sẽ rất hữu ích. Cụ thể, thay vì  áp dụng thuật toán với toàn bộ dữ\\nliệu huấn luyện, bạn có thể chia nó thành hai tập c on: Tập huấn luyện thực tế mà\\nthuật toán sẽ huấn luyện và một tập riêng, ở đây ch úng tôi gọi là tập \"phát triển\\nhuấn luyện\" và nó sẽ không được dùng cho việc huấn luyện.\\nBạn giờ đây có bốn tập con dữ liệu:\\nTập huấn luyện: Đây là dữ liệu mà thuật toán sẽ học  từ nó (ví dụ: ảnh Internet +\\nảnh Điện Thoại). Tập dữ liệu này không nhất thiết p hải được trích xuất từ cùng\\nphân phối như là đối với tập phát triển/kiểm tra.\\nTập phát triển huấn luyện: Đây là dữ liệu trích xuấ t từ cùng phân phối với tập\\nhuấn luyện (ví dụ: ảnh Internet + ảnh Điện Thoại). Tập dữ liệu này thường nhỏ\\nhơn tập huấn luyện và chỉ cần đủ lớn để có thể đánh  giá và theo dõi quá trình học\\n71'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 72}, page_content='của thuật toán.\\nTập phát triển: Đây là dữ liệu trích xuất từ cùng p hân phối với tập kiểm tra, nó\\nphản ánh phân phối dữ liệu mà chúng ta mong muốn th uật toán thực hiện tốt\\nnhất. (Ví dụ: ảnh điện thoại)\\nTập kiểm tra: Đây là dữ liệu trích xuất từ cùng phâ n phối với tập phát triển. (Ví\\ndụ: ảnh điện thoại)\\nĐược trang bị với bốn tập dữ liệu riêng biệt, bạn g iờ đây có thể đánh giá:\\nLỗi huấn luyện, bằng cách đánh giá tập huấn luyện.\\nKhả năng tổng quát hóa của thuật toán đối với dữ li ệu mới, được trích xuất từ\\ncùng phân phối với tập huấn luyện, bằng cách đánh g iá tập phát triển huấn\\nluyện.\\nĐánh giá chất lượng của thuật toán ở tác vụ mà bạn quan tâm trên tập phát triển\\nvà/hoặc tập kiểm tra.\\nPhần lớn những hướng dẫn ở Chương 5-7 về lựa chọn k ích thước của tập phát triển\\ncó thể áp dụng được với tập phát triển huấn luyện.\\n72'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 73}, page_content='41. Xác định lỗi về độ chệch, phương sai và dữ\\nliệu không tương đồng\\nGiả sử con người đạt được chất lượng gần như hoàn h ảo (lỗi ≈0%) trong việc phát\\nhiện mèo và do vậy tỷ lệ lỗi tối ưu là khoảng 0%. G iả sử bạn có:\\n1% lỗi trên tập huấn luyện.\\n5% lỗi trên tập phát triển huấn luyện.\\n5% lỗi trên tập phát triển.\\nNhư vậy nói lên được điều gì? Ở đây, bạn biết rằng mình đang có phương sai cao.\\nBạn có thể cải tiến thêm với các kỹ thuật giảm phươ ng sai được mô tả trước đây.\\nBây giờ, giả sử thuật toán của bạn đạt được:\\n10% lỗi trên tập huấn luyện.\\n11% lỗi trên tập phát triển huấn luyện.\\n12% lỗi trên tập phát triển.\\nĐiều này cho bạn biết rằng bạn có độ chệch tránh đư ợc cao trên tập huấn luyện.\\nTức là, thuật toán đang hoạt động kém trên tập huấn  luyện. Kỹ thuật giảm độ chệch\\nsẽ có ích trong trường hợp này.\\nTrong hai ví dụ trên, thuật toán chỉ có vấn đề về đ ộ chệch tránh được cao hoặc\\nphương sai cao. Một thuật toán có thể mắc phải một hoặc nhiều vấn đề về độ chệch\\ntránh được cao, phương sai cao hoặc dữ liệu không t ương đồng. Ví dụ như:\\n10% lỗi trên tập huấn luyện.\\n11% lỗi trên tập phát triển huấn luyện.\\n20% lỗi trên tập phát triển.\\nThuật toán này có độ chệch tránh được cao và lỗi dữ  liệu không tương đồng. Tuy\\nnhiên, nó không có vấn đề phương sai cao trong phân  phối tập huấn luyện.\\nĐể dễ hiểu hơn, mối quan hệ giữa các loại lỗi được trình bày trong bảng sau:\\n73'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 74}, page_content='Tiếp tục với ví dụ về bộ phát hiện hình ảnh mèo, bạ n có thể thấy rằng có hai phân\\nphối dữ liệu khác nhau trên trục x. Trên trục y, ch úng ta có ba loại lỗi: lỗi ở mức con\\nngười, lỗi trên các mẫu mà thuật toán đã được học v à lỗi trên các mẫu mà thuật\\ntoán chưa được học. Chúng ta có thể điền vào các ô với các loại lỗi khác nhau đã\\nđược xác định được trong chương trước.\\nNếu muốn, bạn cũng có thể điền vào hai ô còn lại: B ạn có thể điền vào ô phía trên\\nbên phải (Chất lượng mức con người trên Hình ảnh tả i lên từ điện thoại) bằng cách\\nnhờ một vài người dán nhãn dữ liệu ảnh mèo tải lên từ điện thoại và đo mức lỗi gán\\nnhãn của họ. Bạn có thể điền vào ô kế tiếp bằng các h bỏ một phần nhỏ những tấm\\nảnh mèo chụp từ điện thoại (có Phân phối B) vào tập  huấn luyện để mạng nơ-ron\\ncũng có thể học theo chúng. Sau đó, bạn đo lỗi của mô hình đã học trên tập dữ liệu\\ncon đó. Việc điền thêm vào hai mục này đôi khi có t hể cung cấp cái nhìn sâu sắc hơn\\nvề những gì thuật toán đang thực hiện trên các phân  phối dữ liệu khác nhau (Phân\\nphối A và B).\\nBằng cách hiểu được loại lỗi mà thuật toán đang gặp  nhiều nhất, bạn sẽ ở vị thế tốt\\nhơn để quyết định nên tập trung vào việc giảm độ ch ệch, giảm phương sai hay giảm\\nđộ không tương đồng của dữ liệu.\\n74'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 75}, page_content='42. Xử lý dữ liệu không tương đồng\\nGiả sử, bạn đã phát triển một hệ thống nhận dạng gi ọng nói hoạt động rất tốt trên\\ntập huấn luyện và tập phát triển huấn luyện. Tuy nh iên, hệ thống đó lại hoạt động\\nkém trên tập phát triển: Bạn có vấn đề về dữ liệu k hông tương đồng. Bạn có thể làm\\ngì?\\nTôi đề xuất bạn nên: (i) Cố gắng hiểu những thuộc t ính của dữ liệu mà khác biệt\\ngiữa phân phối của tập huấn luyện và tập phát triển . (ii) Cố gắng lấy thêm dữ liệu\\nhuấn luyện tương đồng hơn với các mẫu trong tập phá t triển mà thuật toán của bạn\\nđang gặp vấn đề.\\nGiả sử bạn thực hiện phân tích lỗi nhận dạng giọng nói trên tập phát triển: Bạn nghe\\nthủ công qua 100 mẫu và cố gắng hiểu xem thuật toán  đang mắc lỗi ở những đâu.\\nBạn phát hiện rằng, hệ thống của bạn hoạt động kém vì hầu hết những đoạn âm\\nthanh trong tập phát triển được thu bên trong xe hơ i, trong khi hầu hết các ví dụ để\\nhuấn luyện được thu trong môi trường yên tĩnh. Tiến g ồn từ động cơ và đường phố\\nlàm ảnh hưởng nghiêm trọng đến chất lượng của hệ th ống. Trong trường hợp này,\\nbạn có thể cố gắng thu thập thêm dữ liệu huấn luyện  bao gồm các đoạn âm thanh\\nđược thu trong xe hơi. Mục đích của việc phân tích lỗi là để hiểu những khác biệt nào\\nlà đáng kể giữa tập huấn luyện và tập phát triển, đ ây vốn là nguyên nhân dẫn đến\\ndữ liệu không tương đồng.\\nNếu tập huấn luyện và tập phát triển huấn luyện của  bạn chứa những đoạn âm\\nthanh thu trong xe hơi, bạn nên kiểm tra kĩ lưỡng c hất lượng của hệ thống trên tập\\ncon dữ liệu này. Nếu hệ thống hoạt động tốt với dữ liệu xe hơi trong tập huấn luyện\\nnhưng không tốt với dữ liệu xe hơi trong tập phát t riển huấn luyện, điều đó càng\\nkhẳng định giả thuyết rằng lấy thêm dữ liệu xe hơi sẽ có ích. Đó là lí do tại sao\\nchúng ta thảo luận trong chương trước về khả năng t hêm một số dữ liệu lấy từ tập\\nphát triển/tập kiểm tra với cùng phân phối vào tron g dữ liệu huấn luyện. Làm như\\nvậy cho phép bạn so sánh chất lượng [hệ thống] trên  tập huấn luyện so với trên tập\\nphát triển/kiểm tra.\\nĐáng tiếc là không có một sự bảo đảm nào trong quá trình này. Ví dụ, nếu bạn\\nkhông có cách nào để có thể lấy thêm dữ liệu huấn l uyện tương đồng với dữ liệu\\ntrong tập phát triển, bạn có thể không định ra được  một lộ trình rõ ràng để cải thiện\\nchất lượng hệ thống.\\nGHI CHÚ:\\n[14] Cũng có một số nghiên cứu về \"thích ứng miền\" -- làm sao để huấn luyện một\\nthuật toán trên một phân phối mà vẫn tổng quát hóa được trên một phân phối khác.\\nNhững phương pháp này thường chỉ ứng dụng được với một số loại bài toán đặc biệt\\nvà ít được sử dụng hơn nhiều so với những ý tưởng đ ã được trình bày trong chương\\nnày.\\n75'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 76}, page_content='43. Tổng hợp dữ liệu nhân tạo\\nHệ thống giọng nói của bạn cần thêm dữ liệu nghe gi ống như được lấy từ trong xe\\nhơi. Thay vì thu thập nhiều dữ liệu trong khi lái x e, bạn có thể lấy chúng dễ dàng\\nhơn bằng tổng hợp nhân tạo.\\nGiả sử bạn có một số lượng lớn đoạn âm thanh tiếng ồn xe hơi/đường phố. Bạn có\\nthể tải dữ liệu này từ một số trang web. Giả sử bạn  cũng có một tập huấn luyện lớn\\ncủa tiếng người đang nói trong một căn phòng yên tĩ nh. Nếu bạn lấy đoạn âm thanh\\ncủa một người đang nói và \"thêm\" vào một đoạn âm th anh tiếng ồn xe hơi/đường\\nphố, thì bạn sẽ có được một đoạn âm thanh nghe như thể người đó đang nói trong\\nmột chiếc xe ồn ào. Theo quy trình này, bạn có thể \"tổng hợp\" lượng dữ liệu khổng\\nlồ mà nghe như thể được ghi âm bên trong một chiếc xe hơi.\\nTổng quát hơn, có một số trường hợp mà tổng hợp dữ liệu nhân tạo cho phép bạn\\ntạo một tập dữ liệu khổng lồ phù hợp với tập phát t riển. Hãy sử dụng bộ nhận dạng\\nảnh mèo làm ví dụ thứ hai. Bạn nhận thấy rằng, nhữn g ảnh của tập phát triển hay bị\\nmờ chuyển động nhiều hơn bởi vì chúng thường do ngư ời dùng điện thoại di động tải\\nlên -- họ thường hơi di chuyển điện thoại khi chụp ảnh. Bạn có thể lấy những ảnh\\nkhông bị mờ từ tập huấn luyện của ảnh Internet và t hêm vào mô phỏng của hiệu\\nứng mờ chuyển động cho giống với tập phát triển hơn .\\nHãy nhớ rằng tổng hợp dữ liệu nhân tạo có những thá ch thức của nó: đôi khi dễ\\ndàng tạo ra dữ liệu tổng hợp có vẻ giống thật với n gười hơn là tạo dữ liệu có vẻ\\ngiống thật với máy tính. Giả sử bạn có 1.000 giờ dữ  liệu huấn luyện giọng nói, nhưng\\nchỉ có một giờ tiếng ồn xe hơi. Nếu bạn liên tục sử  dụng cùng một giờ tiếng ồn xe\\nhơi với các phần khác nhau từ 1.000 giờ dữ liệu huấ n luyện ban đầu, bạn sẽ nhận\\nđược với một tập dữ liệu tổng hợp trong đó tiếng ồn  xe hơi giống nhau lặp đi lặp lại.\\nMặc dù một người nghe âm thanh này có thể sẽ không thể phân biệt được -- với\\nphần lớn mọi người thì tất cả tiếng ồn của xe hơi đ ều giống nhau -- nhưng có thể\\nthuật toán học sẽ \"quá khớp\" một giờ tiếng ồn của x e hơi đó. Do đó, thuật toán có\\nthể khái quát kém khi gặp một đoạn âm thanh mới với  tiếng ồn xe hơi khác.\\nNgoài ra, giả sử bạn có 1.000 giờ tiếng ồn xe hơi k hác biệt, nhưng tất cả đều được\\nlấy từ 10 chiếc xe khác nhau. Trong trường hợp này,  thuật toán có thể \"quá khớp\"\\n10 chiếc xe này và đạt chất lượng kém nếu được thử nghiệm trên âm thanh từ một\\nchiếc xe khác. Đáng tiếc là những vấn đề này thường  khó phát hiện.\\n76'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 77}, page_content='Lấy một ví dụ nữa, giả sử bạn đang xây dựng một hệ thống thị giác máy để nhận\\ndiện xe hơi. Giả sử bạn hợp tác với một công ty sản  xuất game có mô hình đồ họa\\nmáy tính của một số xe hơi. Để huấn luyện thuật toá n, bạn sử dụng các mô hình\\nnày để tạo ra hình ảnh xe hơi. Ngay cả khi các hình  ảnh tổng hợp trông rất giống\\nthật, phương pháp này (đã được nhiều người độc lập đề xuất) có thể sẽ không hoạt\\nđộng tốt. Trong toàn bộ game có thể có gần ~20 thiế t kế xe hơi. Việc xây dựng một\\nmô hình 3D của một chiếc xe hơi rất tốn kém; Nếu bạ n từng chơi game, thì có lẽ bạn\\ncó thể nhận thấy rằng phần lớn xe hơi trong game là  giống nhau và có lẽ chỉ khác\\nnhau về màu sơn. Tức là, dữ liệu này tuy trông rất giống thật với bạn, nhưng so với\\ntập hợp tất cả các xe hơi trên đường phố (hay những  gì bạn có thể thấy trong tập\\nphát triển/kiểm tra), thì bộ 20 chiếc xe được tổng hợp này chỉ chiếm một phần rất\\nnhỏ trong phân phối xe hơi trên toàn thế giới. Do đ ó, nếu 100.000 mẫu huấn luyện\\ncủa bạn đều đến từ 20 chiếc xe này, hệ thống của bạ n sẽ \"quá khớp\" với 20 thiết kế\\nxe cụ thể này và sẽ không thể khái quát tốt cho các  tập phát triển/kiểm tra bao gồm\\ncác thiết kế xe khác.\\nKhi tổng hợp dữ liệu, hãy suy nghĩ kỹ xem bạn có th ực sự tổng hợp được một tập các\\nmẫu mang tính đại diện hay không. Cố gắng tránh đưa  ra các thuộc tính dữ liệu tổng\\nhợp mà thuật toán học có thể phân biệt được mẫu nào  là được tổng hợp với mẫu\\nnào không. Ví dụ, nếu tất cả dữ liệu được tổng hợp đến từ một trong 20 thiết kế xe\\nhơi hoặc tất cả âm thanh được tổng hợp chỉ từ một g iờ tiếng ồn xe hơi. Lời khuyên\\nnày đôi khi là rất khó để làm theo.\\nKhi làm việc về tổng hợp dữ liệu, các nhóm của tôi đôi khi phải mất hàng tuần trời\\nđể tạo ra dữ liệu với các chi tiết đủ gần giống với  phân phối thực tế để có thể cho\\nhiệu quả rõ rệt. Nhưng nếu bạn có thể có được các c hi tiết này đúng, bạn có thể tức\\nthì có được một tập huấn luyện lớn hơn nhiều so với  trước đấy.\\n77'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 78}, page_content='Phần 7: Gỡ lỗi các Thuật\\ntoán suy luận\\n78'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 79}, page_content='44. Bài kiểm tra xác minh tối ưu\\nGiả sử bạn đang xây dựng một hệ thống nhận dạng giọ ng nói. Hệ thống hoạt động\\nbằng cách nhập một đoạn âm thanh A, và tính toán một giá trị Điểm ( S) cho mỗi\\ncâu đầu ra khả dĩ S. Ví dụ: bạn có thể thử ước tính Điểm ( S) = P( S|A), tức xác suất\\nbản ghi thoại đầu ra chính xác là câu S với điều kiện âm thanh đầu vào là A.\\nKhi có cách tính Điểm ( S), bạn vẫn phải tìm câu tiếng Anh S để tối đa hóa nó:\\nLàm thế nào để tính toán được \"arg max\" ở trên? Nếu  tiếng Anh có 50.000 từ thì sẽ\\ncó (50.000)  câu khả dĩ có độ dài N -- quá nhiều để liệt kê một cách triệt để.\\nVì vậy, bạn cần áp dụng thuật toán tìm kiếm gần đún g, để cố gắng tìm giá trị S\\nnhằm tối ưu hóa (tối đa hóa) Điểm ( S). Ví dụ, với thuật toán tìm kiếm chùm tia\\n(beam search), thuật toán này chỉ giữ K ứng viên hàng đầu trong quá trình tìm kiếm.\\n(Đối với mục đích của chương này, bạn không cần phả i hiểu chi tiết về tìm kiếm\\nchùm tia.) Các thuật toán như thế này không đảm bảo  được việc tìm giá trị của S mà\\ntối đa hóa Điểm ( S).\\nGiả sử rằng một đoạn âm thanh A ghi lại một người nào đó nói rằng \"Tôi yêu thích\\nhọc máy\". Tuy nhiên, thay vì xuất ra bản ghi thoại chính xác, hệ thống của bạn lại\\nđưa ra một phiên bản không chính xác \"Tôi yêu thích  người máy\". Có hai khả năng\\ngiải thích cho việc thiếu chính xác này:\\n1. Vấn đề về thuật toán tìm kiếm . Thuật toán tìm kiếm gần đúng (tìm kiếm\\nchùm tia) không thể tìm thấy giá trị S thỏa mãn việc tối đa hóa Điểm ( S).\\n2. Vấn đề về hàm mục tiêu (hàm tính điểm).  Ước lượng của chúng ta về\\nĐiểm ( S) = P( S|A) không chính xác. Cụ thể, việc chọn cách tính Điểm ( S) thất bại\\ntrong việc xác định \"Tôi yêu thích học máy\" là bản ghi thoại chính xác.\\nTùy thuộc vào nguyên nhân nào dẫn đến thất bại mà b ạn ưu tiên tập trung vào các\\nhướng giải quyết khác nhau. Nếu #1 là vấn đề, bạn n ên cải thiện thuật toán tìm\\nkiếm. Nếu #2 là vấn đề, bạn nên làm việc với thuật toán học ước lượng Điểm ( S).\\nĐối mặt với tình huống này, một số nhà nghiên cứu s ẽ ngẫu nhiên quyết định làm\\nviệc trên thuật toán tìm kiếm; những người khác sẽ ngẫu nhiên làm việc theo cách\\ntốt hơn để thuật toán học các giá trị cho Điểm ( S). Nhưng nếu bạn không biết\\nnguyên nhân nào trong số này là nguyên nhân cơ bản tạo nên lỗi, nỗ lực của bạn có\\nthể trở nên lãng phí. Làm thế nào bạn có thể quyết định nên làm gì một cách có hệ\\nthống hơn?\\nĐặt S  là bản ghi thoại đầu ra (\"Tôi yêu thích người  máy\"). Đặt S  là bản ghi thoại\\nchính xác (\"Tôi yêu thích học máy\"). Để hiểu vấn đề  #1 hay #2 ở trên là nguyên\\nnhân, bạn có thể thực hiện Bài kiểm tra xác minh tối ưu : Đầu tiên, tính Điểm ( S)\\nvà Điểm ( S). Sau đó kiểm tra xem Điểm ( S) > Điểm ( S) có đúng hay không.\\nCó hai khả năng:A\\nA\\nA\\nN\\nA\\nA\\nA\\nA A\\nA\\nA\\nout*\\nA*\\nA out A*A out\\n*79'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 80}, page_content='Trường hợp 1: Điểm ( S) > Điểm ( S)\\nTrong trường hợp này, thuật toán học của bạn đã tín h S  cao hơn S . Tuy nhiên,\\nthuật toán tìm kiếm gần đúng đã chọn S  thay vì S . Đ iều này cho bạn biết rằng\\nthuật toán tìm kiếm gần đúng của bạn có lỗi trong v iệc chọn giá trị S tối đa hóa\\nĐiểm ( S). Trong trường hợp này, Bài kiểm tra xác minh tối ưu cho bạn biết rằng bạn\\ncó vấn đề về thuật toán tìm kiếm và nên tập trung v ào đó. Ví dụ, bạn có thể thử\\ntăng độ rộng chùm tia của tìm kiếm chùm tia.\\nTrường hợp 2: Điểm ( S) ≤ Điểm ( S)\\nTrong trường hợp này, bạn biết việc bạn tính toán Đ iểm (.) có lỗi: Không thể cho\\nđiểm đầu ra chính xác S cao hơn hẳn so với S  không chính xác. Bài kiểm tra  xác\\nminh tối ưu cho bạn biết rằng bạn có vấn đề về hàm mục tiêu (tính điểm). Vì vậy,\\nbạn nên tập trung vào việc cải thiện thuật toán học  hoặc cách xấp xỉ Điểm ( S) cho\\ncác câu S khác nhau.\\nThảo luận của chúng ta tới giờ mới chỉ tập trung và o một ví dụ duy nhất. Để áp dụng\\nBài kiểm tra xác minh tối ưu trong thực tế, bạn nên  kiểm tra lỗi trong tập phát triển\\ncủa mình. Với mỗi lỗi, bạn sẽ kiểm tra xem liệu Điể m (S) > Điểm ( S) không. Mỗi\\nví dụ trong tập phát triển mà bất đẳng thức này tho ả mãn được đánh dấu là lỗi gây\\nra bởi thuật toán tối ưu. Mỗi ví dụ không thỏa mãn (Điểm (S ) ≤ Điểm (S )) được\\nđánh dấu là một lỗi do cách tính Điểm (.).\\nVí dụ, giả sử bạn tìm ra rằng 95% các lỗi là do hàm  tính điểm Điểm (.) và chỉ 5% có\\nnguyên do từ phía thuật toán tối ưu. Giờ bạn biết r ằng dù có cải thiện quá trình tối\\nưu thế nào thì bạn cũng chỉ có thể loại bỏ được kho ảng 5% lỗi. Thay vào đó, bạn nên\\ntập trung cải thiện cách ước lượng Điểm (.).A*A out\\n*out\\nout*\\nA\\nA*A out\\nA\\n*out\\nA\\nA*A out\\nA*A out\\nA\\nA\\nA\\n80'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 81}, page_content='45. Dạng tổng quát của bài kiểm tra xác minh\\ntối ưu\\nBạn có thể áp dụng Bài kiểm tra xác minh tối ưu khi , với đầu vào x, bạn biết cách\\ntính Điểm ( y) dùng để thể hiện mức độ phản hồi y tốt như thế nào với x. Hơn nữa,\\nbạn đang sử dụng thuật toán gần đúng để cố gắng tìm  arg max  Điểm ( y), nhưng\\nnghi ngờ rằng thuật toán tìm kiếm đôi khi không tìm  thấy giá trị lớn nhất. Trong ví\\ndụ nhận dạng giọng nói trước đây, x=A là một đoạn âm thanh và đầu ra y=S là bản\\nghi thoại.\\nGiả sử y* là đầu ra \"chính xác\" nhưng thuật toán th ay vào đó tìm ra y . Khi đó bài\\nkiểm tra then chốt là đo xem liệu Điểm (y*) > Điểm (y ) có đúng hay không. Nếu\\nbất đẳng thức này đúng thì chúng ta coi lỗi là do t huật toán tối ưu. Tham khảo\\nchương trước để đảm bảo bạn hiểu logic đằng sau điề u này. Ngược lại, chúng ta coi\\nlỗi thuộc về cách tính Điểm (y).\\nXem xét một ví dụ nữa. Giả sử bạn đang xây dựng một  hệ thống dịch máy từ tiếng\\nTrung sang tiếng Anh. Hệ thống của bạn nhận một câu  tiếng Trung C và tính giá trị\\nĐiểm ( E) cho mỗi bản dịch khả dĩ E. Ví dụ, bạn có thể sử d ụng Điểm ( E) = P( E|C),\\nxác suất dịch ra E với câu đầu vào C.\\nThuật toán của bạn dịch các câu bằng cách cố gắng t ính:\\nTuy nhiên, tập hợp các câu tiếng Anh khả dĩ E quá lớn nên bạn dựa vào thuật toán\\ntìm kiếm thực nghiệm.\\nGiả sử thuật toán cho ra một bản dịch không chính x ác E thay vì một bản dịch\\nchính xác E* nào đó. Khi đó bài kiểm tra xác minh t ối ưu sẽ yêu cầu bạn tính toán\\nxem liệu Điểm ( E*) > Điểm ( E) đúng hay không. Nếu bất đẳng thức này đúng thì\\ncách tính Điểm (.) đã nhận dạng chính xác E* tốt hơn  so với E; do đó, bạn sẽ coi\\nlỗi này là do thuật toán tìm kiếm gần đúng. Ngược l ại, bạn coi lỗi này thuộc về cách\\ntính Điểm (.)\\nĐây là một “mẫu thiết kế” rất phổ biến trong AI khi  đầu tiên học một hàm tính điểm\\ngần đúng Điểm (.), sau đó sử dụng một thuật toán tối  đa xấp xỉ. Nếu bạn có thể\\nphát hiện ra kiểu mẫu này, bạn sẽ có thể sử dụng Bà i kiểm tra xác minh tối ưu để\\nhiểu nguồn gốc lỗi của mình.*\\ny *\\nout\\n* * out\\n*\\nC C\\nout\\nC C out\\nC out\\nC\\n*\\n81'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 82}, page_content='46. Ví dụ về Học tăng cường\\nGiả sử như bạn đang sử dụng học máy để dạy trực thă ng bay theo những chuyển\\nđộng phức tạp. Đây là một tấm ảnh time-lapse của mộ t chiếc trực thăng được máy\\ntính điều khiển thực hiện việc hạ cánh khi động cơ đã tắt.\\nĐây được gọi là kĩ thuật \"quay tự động\". Nó cho phé p trực thăng hạ cánh ngay cả\\nkhi động cơ bị hỏng ngoài dự kiến. Phi công thực hà nh kĩ thuật bay này như một\\nphần trong công tác huấn luyện bay. Nhiệm vụ của bạ n là sử dụng một thuật toán\\nhọc tập để lái chiếc trực thăng qua một quỹ đạo T và kết thúc với một pha hạ cánh\\nan toàn.\\nĐể áp dụng học tăng cường, bạn phải phát triển một \"hàm điểm thưởng\" R(.) trả về\\nmột chỉ số đánh giá mức độ tốt của mỗi quỹ đạo T. Lấy ví dụ, nếu T kết thúc bằng\\nviệc trực thăng bị rơi, thì có thể nhận điểm thưởng  R(T) = -1.000 -- một điểm thưởng\\nâm rất lớn. Một quỹ đạo T kết thúc bằng việc trực thăng hạ cánh an toàn có thể  sẽ\\ncho R(T) dương với giá trị chính xác phụ thuộc vào việc hạ cánh êm ái như thế nào.\\nHàm điểm thưởng R(.) thường được chọn thủ công để định lượng mức độ mong\\nmuốn của những quỹ đạo T khác nhau. Nó phải đánh đổi giữa những đặc tính nh ư độ\\nxóc khi hạ cánh, trực thăng có hạ cánh đúng vị trí mong muốn không, quá trình hạ\\nđộ cao có nhiều biến động đối với hành khách không,  cùng nhiều yếu tố khác. Thiết\\nkế hàm điểm thưởng tốt là một việc không hề dễ dàng .\\nVới một hàm điểm thưởng R(T) cho trước, công việc của thuật toán học tăng cường\\nlà điều khiển trực thăng sao cho nó đạt được điểm t hưởng cao nhất max R(T). Tuy\\nnhiên, thuật toán học tăng cường có nhiều phép xấp xỉ và có thể sẽ không thànhT\\n82'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 83}, page_content='công trong việc tối ưu này.\\nGiả sử bạn đã có một hàm điểm thưởng R(.) nào đó và đã chạy thuật toán học của\\nbạn. Tuy nhiên, chất lượng của nó còn thua xa chất lượng của người lái (ví dụ: hạ\\ncánh xóc hơn và có vẻ kém an toàn hơn so với chất l ượng của phi công). Làm sao để\\nbạn biết được liệu đó có phải là lỗi của thuật toán  học tăng cường -- được dùng để\\ntính toán một quỹ đạo để tối đa max R(T) -- hay là lỗi của hàm điểm thưởng -- được\\ndùng để đo cũng như xác định mức đánh đổi lý tưởng giữa độ xóc của chuyến bay\\nvà độ chính xác của vị trí hạ cánh?\\nĐể áp dụng Bài kiểm tra xác minh tố ưu, cho T  là quỹ đạo bay của phi công và\\ncho T là quỹ đạo đạt được của thuật toán. Dựa theo mô tả  phía trên, T  là quỹ\\nđạo tốt hơn so với T. Do vậy, bài kiểm tra then chốt là: Liệu có đúng k hông khi\\nR(T ) > R(T)?\\nTrường hợp 1: Nếu bất đẳng thức này đúng, thì hàm đ iểm thưởng R(.) đang đánh giá\\nđúng rằng T  vượt trội hơn so với T. Nhưng vậy thì thuật toán học tăng cường\\nđang tìm T kém hơn. Điều này gợi ý rằng bỏ công sức để cải thi ện thuật toán học\\ntăng cường là xứng đáng.\\nTrường hợp 2: Bất đẳng thức trên không đúng: R(T ) ≤ R(T). Tức là R(.) đang\\ngán cho T  một điểm số tệ hơn dù cho nó là quỹ đạo tốt hơn. B ạn nên cải thiện\\nR(.) để có thể nắm bắt việc đánh đổi giữa các tiêu chí tương đương với một cú hạ\\ncánh tốt.\\nNhiều ứng dụng machine learning có chung \"khuôn mẫu \" là tối ưu xấp xỉ một hàm\\ntính điểm Điểm (.) sử dụng một thuật toán tìm kiếm x ấp xỉ. Đôi khi, cũng không tồn\\ntại một đầu vào x được chỉ định trước vậy nên hàm chỉ còn là Điểm(.) . Trong ví dụ\\ntrên, hàm tính điểm chính là hàm điểm thưởng Điểm( T) = R( T) và thuật toán tối ưu\\nlà thuật toán học tăng cường đang cố thực thi một q uỹ đạo bay T tốt.\\nMột điểm khác biệt so với những ví dụ trước là, tha y vì so sánh với một kết quả \"tối\\nưu\", bạn so sánh với chất lượng mức con người T . Chúng ta giả sử T  khá là\\ntốt, dù có thể không tối ưu. Nhìn chung, miễn là bạ n có kết quả y* (trong ví dụ này,\\nT ) tốt hơn so với thuật toán học hiện thời -- mặc dù  có thể nó không phải là kết\\nquả \"tối ưu\" -- thì Bài kiểm tra xác minh tối ưu có  thể chỉ ra liệu cải thiện thuật toán\\ntối ưu hay cải thiện hàm tính điểm sẽ hứa hẹn hơn.T\\nngười\\nra người\\nra\\nngười ra\\nngười ra\\nra\\nngười ra\\nngười\\nx\\nngười người\\nngười\\n83'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 84}, page_content='Phần 8: Học sâu đầu-cuối\\n84'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 85}, page_content='47. Sự trỗi dậy của học đầu-cuối\\nGiả sử bạn muốn xây dựng một hệ thống để kiểm tra c ác đánh giá trực tuyến cho\\nsản phẩm và tự động cho biết liệu người viết đánh g iá có thích sản phẩm đó hay\\nkhông. Ví dụ, bạn muốn hệ thống đó phân loại phản h ồi dưới đây là tích cực:\\n\"Cây lau nhà này thật tuyệt!\"\\nvà phản hồi dưới đây là tiêu cực:\\n\"Cây lau nhà này thật kém chất lượng -- Tôi hối hận  vì đã mua nó.\"\\nBài toán về nhận dạng quan điểm tích cực hoặc tiêu cực được gọi là \"phân loại cảm\\nxúc\". Để xây dựng hệ thống này, bạn có thể tạo một \"pipeline\" gồm hai phần:\\n1. Bộ phân tích cú pháp: Một hệ thống tạo chú thích  văn bản trích xuất thông tin từ\\nnhững từ quan trọng nhất [15]. Ví dụ, bạn có thể sử  dụng bộ phân tích cú pháp\\nđể tạo nhãn cho tất cả tính từ và danh từ. Từ đó có  được đoạn chú thích như sau:\\nCây lau nhà  này thật tuyệt !\\n2. Bộ phân loại cảm xúc: Một thuật toán học sử dụng  đầu vào là văn bản đã chú\\nthích để dự đoán cảm xúc tổng thể. Những chú thích của bộ phân tích cú pháp có\\nthể giúp ích thuật toán học này rất nhiều: Bằng việ c tập trung hơn vào các tính\\ntừ, thuật toán có thể nhanh chóng xác định các từ q uan trọng như \"tuyệt\", và lờ\\nđi những từ ít quan trọng hơn như \"này\".\\nChúng ta có thể hình dung \"pipeline\" của hai thành phần này như sau:\\nXu hướng gần đây là thay đổi hệ thống pipeline bởi một thuật toán duy nhất. Một\\nthuật toán học đầu-cuối  cho tác vụ này chỉ cần nhận vào đoạn văn bản gốc \" Cây\\nlau nhà này thật tuyệt!\", rồi cố gắng trực tiếp nhậ n ra cảm xúc từ văn bản gốc đó:\\nDanh Từ Tính từ\\n85'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 86}, page_content='Mạng nơ-ron được sử dụng phổ biến trong các hệ thốn g đầu-cuối. Thuật ngữ \"đầu-\\ncuối\" phản ánh việc chúng ta yêu cầu thuật toán chạ y trực tiếp từ đầu vào cho đến\\nđầu ra mong muốn: Thuật toán học trực tiếp nhận \"đầ u vào\" và trả về \"đầu ra\" của\\nhệ thống.\\nVới các bài toán có dữ diệu dồi dào, hệ thống đầu-c uối hoạt động khá hiệu quả. Tuy\\nnhiên, không phải lúc nào các hệ thống đầu-cuối cũn g là lựa chọn tốt. Các chương\\ntiếp theo sẽ cung cấp thêm một số ví dụ về hệ thống  đầu-cuối cũng như lời khuyên\\nđể bạn biết thời điểm nào nên hoặc không nên sử dụn g chúng.\\nGHI CHÚ\\n[15] Bộ phân tích cú pháp có thể cung cấp nhiều hơn  các chú thích cho văn bản, tuy\\nnhiên định nghĩa giản lược này là đủ để giải thích hệ thống học sâu đầu-cuối.\\n86'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 87}, page_content='48. Những ví dụ học đầu-cuối khác\\nGiả sử bạn muốn xây dựng một hệ thống nhận dạng giọ ng nói. Bạn có thể xây dựng\\nhệ thống với ba thành phần sau:\\nCác thành phần sẽ hoạt động như sau:\\n1. Tính toán đặc trưng: Trích xuất các đặc trưng đư ợc thiết kế thủ công, ví dụ như\\nđặc trưng MFCC (Hệ số Mel-frequency cepstrum), được  sử dụng để nắm bắt nội\\ndung của đoạn phát biểu trong khi bỏ qua những thuộ c tính ít liên quan hơn như\\nâm sắc của người nói.\\n2. Bộ nhận dạng âm vị: Một số nhà ngôn ngữ học tin rằng trong ngôn ngữ có các\\nđơn vị cơ bản gọi là \"âm vị.\" Ví dụ, âm bắt đầu \"k\"  trong từ \"keep\" thì phát âm\\ngiống âm \"c\" trong từ \"cake\". Hệ thống này sẽ cố gắ ng để nhận diện các âm vị\\ntrong các đoạn âm thanh.\\n3. Bộ nhận dạng sau cuối: Dùng các chuỗi âm vị đã đ ược nhận dạng và cố gắng xâu\\nchuỗi chúng với nhau thành một bản ghi thoại ở đầu ra.\\nNgược lại, một hệ thống đầu-cuối có thể nhận đầu và o là một đoạn âm thanh, và cố\\ngắng trả về trực tiếp một bản ghi thoại:\\nCho đến giờ, chúng ta chỉ mới mô tả các \"pipeline\" học máy hoàn toàn tuyến tính:\\nđầu ra được truyền tuần tự từ thành phần này sang t hành phần khác. Nhiều pipeline\\ncó thể phức tạp hơn như trong ví dụ về một hệ thống  xe tự lái đơn giản sau:\\n87'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 88}, page_content='Hệ thống bao gồm ba thành phần: Một thành phần phát  hiện những xe khác qua\\nnhững hình ảnh từ máy quay; Một thành phần khác phá t hiện người đi bộ; thành\\nphần cuối cùng hoạch định một lộ trình giúp xe trán h những xe khác và người đi bộ.\\nKhông phải tất cả thành phần trong pipeline đều cần  được huấn luyện. Ví dụ, trong\\ncác nghiên cứu về \"hoạch định chuyển động của robot \" đã có rất nhiều thuật toán\\ncho bước hoạch định lộ trình của chiếc xe. Trong đó  có nhiều thuật toán không cần\\nphải huấn luyện.\\nNgược lại, hướng tiếp cận đầu-cuối có thể cố gắng l ấy đầu vào là những tín hiệu từ\\ncảm biến và trực tiếp trả về hướng bẻ lái:\\nMặc dù phương pháp học đầu-cuối đã đạt được nhiều k ết quả tốt, nó không luôn là\\nhướng đi tốt nhất. Ví dụ, phương pháp nhận dạng giọ ng nói đầu-cuối đạt kết quả tốt\\nnhưng tôi không tin tưởng việc sử dụng học đầu-cuối  cho xe tự lái. Những chương kế\\ntiếp sẽ giải thích tại sao.\\n88'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 89}, page_content='49. Ưu nhược điểm của học đầu-cuối\\nXét một ví dụ về pipeline nhận dạng tiếng nói trong  các chương trước:\\nRất nhiều thành phần của pipeline này được \"thiết k ế thủ công\".\\nMFCCs là một tập hợp các đặc trưng âm thanh được th iết kế thủ công. Mặc dù\\nchúng cung cấp một tóm tắt khá hợp lý cho dữ liệu â m thanh đầu vào, chúng\\ncũng đã đơn giản hóa tín hiệu đầu vào bằng cách loạ i bỏ một số thông tin.\\nHệ âm vị, một phát kiến của ngành ngôn ngữ học, là một biểu diễn không hoàn\\nhảo của âm thanh thoại. Trong những trường hợp mà h ệ âm vị là một xấp xỉ kém\\ncủa thực tế, áp đặt một thuật toán sử dụng biểu diễ n âm vị sẽ giới hạn chất lượng\\ncủa hệ thống tiếng nói.\\nCác thành phần được thiết kế thủ công này giới hạn chất lượng tiềm năng của hệ\\nthống tiếng nói. Tuy nhiên, việc sử dụng các thành phần được thiết kế thủ công\\ncũng có một vài ưu điểm:\\nĐặc trưng MFCC có tính kháng tốt đối với một vài th uộc tính không ảnh hưởng tới\\nnội dung của tiếng nói, chẳng hạn như cao độ của gi ọng nói. Bởi vậy, chúng giúp\\nđơn giản hóa vấn đề cho thuật toán học.\\nXét theo hướng hệ âm vị là một biểu diễn hợp lý của  tiếng nói, chúng cũng có thể\\ngiúp thuật toán học hiểu được các thành phần cơ bản  của âm thanh và vì vậy cải\\nthiện chất lượng của hệ thống.\\nCó nhiều thành phần được thiết kế thủ công hơn nhìn  chung cho phép một hệ thống\\ntiếng nói có thể học với ít dữ liệu hơn. Đặc trưng được thiết kế thủ công bởi MFCC và\\nâm vị \"bù đắp\" thông tin thuật toán lấy được từ dữ liệu. Các đặc trưng này rất hữu\\ních khi chúng ta không có nhiều dữ liệu.\\nBây giờ, xét hệ thống đầu-cuối sau:\\nHệ thống này thiếu đặc trưng được thiết kế thủ công . Bởi vậy, khi tập huấn luyện\\n89'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 90}, page_content='nhỏ, nó có thể có chất lượng tệ hơn pipeline với đặ c trưng được thiết kế thủ công.\\nTuy nhiên, khi tập huấn luyện lớn, nó không bị cản trở bởi giới hạn biểu diễn của\\nMFCC hay hệ âm vị. Nếu thuật toán học là một mạng n ơ-ron đủ lớn và được huấn\\nluyện trên dữ liệu đủ lớn, nó có tiềm năng hoạt độn g tốt và còn có thể đạt được tỉ lệ\\nlỗi tối ưu.\\nHệ thống học đầu-cuối có xu hướng làm việc tốt khi có nhiều dữ liệu được gán nhãn\\ncho \"cả hai đầu\" -- đầu vào và đầu ra. Trong ví dụ này, chúng ta cần một tập dữ liệu\\nlớn các cặp (âm thanh, bản ghi). Khi chúng ta không  có dữ liệu kiểu này, cần đặc\\nbiệt lưu ý khi sử dụng học đầu-cuối.\\nNếu bạn đang làm việc với một bài toán học máy mà t ập huấn luyện rất nhỏ, hầu\\nhết các đặc trưng cho thuật toán phải đến từ hiểu b iết của con người: Từ các thành\\nphần được \"thiết kế thủ công\".\\nNếu bạn chọn không sử dụng hệ thống đầu-cuối, bạn s ẽ phải quyết định từng bước\\ntrong pipeline và cách chúng được kết nối với nhau.  Trong một vài chương tiếp theo,\\nchúng tôi sẽ cung cấp một vài gợi ý khi thiết kế cá c pipeline dạng này.\\n90'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 91}, page_content='50. Lựa chọn các thành phần cho pipeline: Tính\\nsẵn có của dữ liệu\\nKhi xây dựng một hệ thống pipeline không phải đầu-c uối, các thành phần nào là\\nnhững ứng viên tốt cho pipeline? Cách bạn thiết kế pipeline sẽ có tác động lớn tới\\ntoàn bộ chất lượng của hệ thống. Một nhân tố quan t rọng là liệu rằng bạn có thể dễ\\ndàng thu thập dữ liệu để huấn luyện mỗi thành phần.\\nVí dụ, xét kiến trúc xe tự hành dưới đây:\\nBạn có thể sử dụng học máy để phát hiện xe và người  đi bộ. Hơn nữa, không khó để\\nthu thập những dữ liệu này: Có vô vàn tập dữ liệu t hị giác máy tính với lượng lớn xe\\nhơi và người đi bộ đã được gán nhãn. Bạn cũng có th ể dùng các dịch vụ cộng đồng\\n(Amazon Mechanical Turk chẳng hạn) để có được những  tập dữ liệu thậm chí lớn\\nhơn. Bởi vậy khá dễ để thu thập dữ liệu huấn luyện cho việc xây dựng một bộ phát\\nhiện xe hơi và phát hiện người đi bộ.\\nNgược lại, xét một hướng tiếp cận thuần đầu-cuối:\\nĐể huấn luyện hệ thống này, chúng ta sẽ cần một tập  dữ liệu lớn các cặp (Ảnh,\\nHướng Bẻ Lái). Sẽ rất mất thời gian và tiền của để thu thập dữ liệu hướng bẻ lái\\nbằng cách cho người lái xe trên đường. Bạn cần nhữn g chiếc xe được gắn các thiết\\nbị đặc biệt để thu thập một lượng lớn dữ liệu đảm b ảo bao quát đầy đủ các tình\\nhuống khả dĩ. Việc này khiến hệ thống đầu-cuối rất khó để huấn luyện. Việc thu thập\\nmột tập dữ liệu lớn với ảnh xe hơi và người đi bộ t hường đơn giản hơn rất nhiều.\\nTổng quát hơn, nếu có rất nhiều dữ liệu sẵn có để h uấn luyện \"các mô-đun trung\\n91'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 92}, page_content='gian\" của một pipeline (chẳng hạn như một bộ phát h iện xe hơi và một bộ phát hiện\\nngười đi bộ), thì bạn có thể xem xét sử dụng một pi peline với nhiều bước. Kiến trúc\\nnày có thể ưu việt bởi vì bạn có thể sử dụng tất cả  dữ liệu sẵn có để huấn luyện các\\nmô-đun trung gian.\\nCho tới khi có thêm nhiều dữ liệu đầu-cuối hơn nữa,  tôi tin rằng hướng tiếp cận\\nkhông phải đầu-cuối vẫn có tiềm năng đáng kể hơn ch o xe tự hành: Kiến trúc của nó\\nphù hợp hơn với tính sẵn có của dữ liệu.\\n92'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 93}, page_content='51. Lựa chọn các thành phần cho pipeline: tính\\nđơn giản của tác vụ\\nNgoài sự sẵn có của dữ liệu, bạn cũng nên xem xét m ột nhân tố thứ hai khi lựa chọn\\ncác thành phần của một pipeline: Việc giải quyết từ ng tác vụ bằng các thành phần\\nriêng lẻ đơn giản đến mức nào? Bạn nên cố gắng chọn  những thành phần pipeline\\ncó thể dễ dàng xây dựng hay học riêng lẻ. Nhưng các  thành phần \"dễ\" học nghĩa là\\ngì?\\nXét những tác vụ học máy này, được liệt kê theo thứ  tự độ khó tăng dần:\\n1. Phân loại bức ảnh có bị phơi sáng quá mức hay kh ông (như trong ví dụ trên)\\n2. Phân loại bức ảnh được chụp trong nhà hay ngoài trời\\n3. Phân loại bức ảnh có chứa một con mèo hay không\\n4. Phân loại bức ảnh có chứa một con mèo khoang đen  trắng hay không\\n5. Phân loại bức ảnh có chứa một con mèo Xiêm (tên một loại mèo) hay không\\nMỗi tác vụ trên là một bài toán phân loại ảnh nhị p hân: từ một bức ảnh đầu vào, mô\\nhình phải cho ra giá trị 0 hoặc 1. Nhưng những tác vụ đầu tiên trong danh sách này\\ncó vẻ quá \"dễ\" đối với một mạng nơ-ron. Bạn sẽ có t hể huấn luyện những tác vụ dễ\\nhơn với ít mẫu huấn luyện hơn.\\nHọc máy chưa có một định nghĩa chính thức nào về mộ t tác vụ là dễ hay khó[16].\\nVới sự phát triển của học sâu và mạng nơ-ron đa tần g, chúng ta nói một tác vụ là\\n\"dễ\" nếu có có thể được thực hiện với ít bước tính toán hơn (ứng với mạng nơ-ron\\nnông), và \"khó\" nếu nó đòi hỏi nhiều bước tính toán  hơn (đòi hỏi một mạng nơ-ron\\nsâu hơn). Nhưng đây đều là các định nghĩa không chí nh thức.\\nNếu bạn có thể lấy một tác vụ phức tạp, và chia nhỏ  nó thành những tác vụ con đơn\\ngiản hơn. Sau đó bằng cách viết mã nguồn cụ thể cho  từng tác vụ con đó, bạn đang\\ncung cấp cho thuật toán một tri thức tiền đề giúp n ó học một tác vụ hiệu quả hơn.\\n93'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 94}, page_content='Giả sử bạn đang xây dựng bộ phát hiện một con mèo X iêm. Dưới đây là một kiến\\ntrúc thuần đầu-cuối:\\nNgược lại, bạn cũng có thể sử dụng một pipeline với  hai bước sau:\\nBước đầu tiên (bộ phát hiện mèo) tìm tất cả con mèo  trong bức ảnh.\\n94'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 95}, page_content='Bước thứ hai đưa những phần ảnh được cắt ra từ bộ p hát hiện mèo (từng phần một)\\nvào bộ phân loại mèo, và cuối cùng đưa ra 1 nếu có một phần bất kỳ được xác định\\nlà một con mèo Xiêm.\\nSo với việc huấn luyện bộ phân loại thuần đầu-cuối chỉ sử dụng nhãn 0/1, từng phần\\ncủa pipeline -- bộ phát hiện mèo và bộ phân loại mè o -- có vẻ dễ hơn nhiều để học\\nvà đòi hỏi lượng dữ liệu ít hơn[17].\\n95'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 96}, page_content='Ví dụ cuối cùng, cùng nhìn lại pipeline xe tự lái:\\nBằng cách sử dụng pipeline này, bạn đang chỉ cho th uật toán rằng có 3 bước chính\\nđể lái xe: (1) Phát hiện những chiếc xe hơi khác, ( 2) Phát hiện người đi bộ và (3)\\nHoạch định đường đi cho xe của bạn. Ngoài ra, mỗi b ước này là một hàm số tương\\nđối đơn giản hơn -- và có thể được học với ít dữ li ệu hơn -- so với hướng tiếp cận\\nthuần đầu-cuối.\\nT óm lại, khi lựa chọn các thành phần cho một pipeli ne, hãy cố gắng xây dựng một\\npipeline mà mỗi thành phần là một hàm số tương đối \"đơn giản\" sao cho nó có thể\\nhọc được từ chỉ một lượng dữ liệu vừa phải.\\nCHÚ THÍCH:\\n[16] Lý thuyết thông tin có khái niệm về \"Độ phức t ạp Kolmogorov\", lý thuyết này\\nnói rằng độ phức tạp của hàm số học được đo bằng độ  dài của chương trình máy\\ntính ngắn nhất để tính toán hàm số đó. Tuy nhiên, k hái niệm lý thuyết này ít có ứng\\ndụng thực tế trong trí tuệ nhân tạo. Xem thêm\\nhttps://en.wikipedia.org/wiki/Kolmogorov_complexity\\n[17] Nếu bạn quen với các thuật toán thực tế về phá t hiện vật thể, bạn sẽ nhận ra\\nrằng chúng không chỉ học với ảnh có nhãn 0/1 mà tha y vào đó được huấn luyện với\\ncác khung chứa từ dữ liệu huấn luyện. Thảo luận về vấn đề đó nằm ngoài phạm vi\\ncủa chương này. Tham khảo khóa \"Deep Learning speci alization\" trên Coursera\\n(http://deeplearning.ai ) nếu bạn muốn học thêm về thuật toán đó.\\n96'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 97}, page_content='52. Trực tiếp học những đầu ra phức tạp\\nMột thuật toán phân loại sẽ nhận đầu vào là một ảnh  x rồi trả về một số nguyên thể\\nhiện nhãn phân loại của đồ vật trong ảnh đó. Thay v ào đó, liệu một thuật toán có\\nthể đưa ra một câu mô tả hoàn chỉnh cho bức ảnh đó?\\nVí dụ:\\nx = \\ny = \"Một chiếc xe buýt màu vàng đang đi xuống một co n đường với nền xanh của\\ncây cỏ.\"\\nNhững ứng dụng truyền thống của các thuật toán học có giám sát học một hàm h:\\nX→Y, trong đó đầu ra y thường là một số nguyên hoặc mộ t số thực. Ví dụ:\\nBài toán X Y\\nPhân loại email\\nrácEmailemail rác/ không\\nrác(0/1)\\nNhận dạng ảnh Ảnh Nhãn số nguyên\\nDự đoán giá nhà\\nđấtĐặc trưng của căn nhà Giá theo Đô-la\\nGợi ý sản phẩmĐặc trưng của sản phẩm và người\\ndùngXác suất mua sản\\nphẩm\\nMột trong những hướng phát triển thú vị nhất của họ c sâu đầu-cuối là nó cho phép\\nchúng ta trực tiếp học những kết quả phức tạp hơn r ất nhiều so với đầu ra của việc\\nhọc truyền thống. Trong ví dụ chú thích hình ảnh ở trên, bạn có thể cho hình ảnh ( x)\\nvào một mạng nơ-ron và trực tiếp thu về một câu chú  thích miêu tả hình ảnh đó ( y)\\nDưới đây là một số ví dụ khác:\\n97'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 98}, page_content='Bài toán X Y Trích dẫn ví dụ\\nChú thích hình ảnh Ảnh Văn bản Mao et al., 2014\\nDịch máy Văn bản tiếng AnhVăn bản tiếng\\nPhápSuskever et al.,\\n2014\\nHỏi đápCặp (Văn bản, Câu\\nhỏi)Văn bản trả lời Bordes et al., 2015\\nNhận dạng giọng\\nnóiÂm thanh Bản ghi thoại Hannun et al., 2015\\nVăn bản sang\\ngiọng nóiĐặc trưng văn bản Âm thanhvan der Oord et al.,\\n2016\\nĐây là một xu hướng đang ngày càng phát triển trong  học sâu. Với các cặp có nhãn\\n(đầu vào, đầu ra) phù hợp, đôi khi bạn có thể học đ ầu-cuối ngay cả khi đầu ra là\\nmột câu, hình ảnh, âm thanh hoặc các đầu ra khác ph ức tạp hơn nhiều thay vì chỉ\\nmột con số.\\n98'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 99}, page_content='Phần 9: Phân tích lỗi từng\\nphần\\n99'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 100}, page_content='53. Phân tích lỗi từng phần\\nGiả sử hệ thống của bạn được xây dựng dựa trên một pipeline học máy phức tạp và\\nbạn muốn cải thiện chất lượng của nó. Bạn nên cải t hiện phần nào trong pipeline\\nnày? Bạn có thể sắp xếp thứ tự ưu tiên công việc bằ ng cách quy lỗi cụ thể cho từng\\nphần trong pipeline.\\nHãy sử dụng ví dụ bộ phân loại mèo Xiêm của chúng t a:\\nPhần đầu tiên, bộ phát hiện mèo xác định vị trí của  mèo và cắt chúng ra khỏi tấm\\nảnh. Phần thứ hai, bộ phân loại giống mèo xác định xem đó có phải là một con mèo\\nXiêm hay không. Việc cải thiện bất kì bộ phận nào t rong pipeline này cũng có thể\\ntốn tới hàng năm trời. Làm sao để bạn quyết định đư ợc (những) bộ phận nào cần tập\\ntrung cải thiện?\\nBằng việc thực hiện phân tích lỗi từng phần , bạn có thể cố quy trách nhiệm cho\\nmột (hoặc đôi khi là cả hai) phần trong pipeline tr ên từng dự đoán sai của thuật\\ntoán. Ví dụ, thuật toán phân loại sai tấm ảnh này k hông có một con mèo Xiêm ở\\ntrong đó (y=0) mặc dù nhãn chính xác là y=1.\\n100'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 101}, page_content='Hãy kiểm chứng một cách thủ công xem hai bước của t huật toán đã làm gì. Giả sử\\nbộ phát hiện mèo Xiêm đã phát hiện ra một chú mèo n hư dưới đây:\\nTức là bộ phân loại giống mèo được đưa cho tấm hình  sau:\\nSau đó, bộ phân loại giống mèo xác định chính xác r ằng tấm hình này không có mèo\\nXiêm. Vậy nên, bộ phân loại giống mèo không có lỗi:  Nó được đưa cho cho xem một\\nđống đá và trả ra nhãn y=0 rất hợp lý. Vì trên thực  tế, con người cũng phân loại tấm\\nảnh toàn đá ở trên là không có mèo mà thôi -- y=0. Do vậy, bạn rõ ràng có thể quy\\nlỗi này cho bộ phát hiện mèo.\\n101'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 102}, page_content='Mặt khác, nếu giả sử bộ phát hiện mèo có cho ra kết  quả khung chứa như dưới đây:\\nthì bạn sẽ kết luận rằng bộ phát hiện mèo đã hoàn t hành công việc của nó, và lỗi là\\ndo bộ phân loại giống mèo mà ra.\\nGiả sử bạn kiểm chứng 100 tấm ảnh bị phân loại nhầm  trong tập phát triển và nhận\\nra rằng 90 trong số đó là do lỗi của bộ phát hiện m èo, chỉ có 10 tấm là do lỗi của bộ\\nphân loại giống mèo. Bạn có thể an toàn kết luận rằ ng mình nên tập trung nhiều\\nhơn vào việc cải thiện bộ phát hiện mèo.\\nNgoài ra, bạn cũng đã tìm ra 90 mẫu mà bộ phát hiện  mèo trả về khung chứa chưa\\nchính xác. Bạn có thể sử dụng 90 mẫu này để thực hi ện việc phân tích lỗi kĩ hơn trên\\nbộ phát hiện mèo và tìm cách cải thiện nó.\\nViệc làm thế nào để quy lỗi cho một phần của pipeli ne vẫn đang được mô tả một\\ncách không hợp thức: bạn nhìn vào đầu ra của mỗi ph ần để xem liệu có thể quyết\\nđịnh phần nào gây ra lỗi. Phương pháp không hợp thứ c này có thể là đủ với bạn. Tuy\\nnhiên ở chương sau, bạn sẽ thấy một cách hợp thức h ơn của việc quy lỗi.\\n102'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 103}, page_content='54. Quy lỗi cho một thành phần\\nCùng tiếp tục với ví dụ này:\\nGiả sử bộ phát hiện mèo cho kết quả khung chứa như sau:\\nKhi đó bộ phân loại giống mèo nhận một vùng ảnh, và  cho kết quả không chính xác\\nlà y=0, tức là không có con mèo nào trong hình.\\nBộ phát hiện mèo đã hoạt động không tốt. Tuy nhiên,  một người giàu kinh nghiệm\\nvẫn có thể nhận dạng mèo Xiêm từ bức ảnh bị cắt lệc h. Trường hợp này chúng ta\\nnên quy lỗi cho bộ phát hiện mèo, bộ phân loại giốn g mèo, hay là cả hai? Có sự\\nkhông rõ ràng ở đây.\\nNếu số lượng các trường hợp không rõ ràng là nhỏ, t hì bất kỳ quyết định nào mà bạn\\nlựa chọn đều sẽ đạt kết quả tương đương. Tuy nhiên một bài kiểm tra hợp thức hơn\\nsẽ giúp bạn quy lỗi chính xác cho một thành phần:\\n1. Thay đầu ra của bộ phát hiện mèo bằng một khung chứa thủ công:\\n103'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 104}, page_content='2. Nạp ảnh bị cắt tương ứng vào bộ phân loại giống mèo. Nếu bộ phân loại giống\\nmèo vẫn phân loại sai thì quy lỗi cho bộ phân loại giống mèo. Ngược lại thì quy lỗi\\ncho bộ phát hiện mèo.\\nNói cách khác, thực hiện thử nghiệm mà ở đó bạn cun g cấp cho bộ phân loại giống\\nmèo một đầu vào \"hoàn hảo\". Hai trường hợp có thể x ảy ra:\\nTrường hợp 1: Kể cả với một khung chứa \"hoàn hảo\", bộ phân loại giống mèo vẫn\\nđưa ra kết quả không chính xác y=0. Trong trường hợ p này rõ ràng là bộ phân\\nloại giống mèo có lỗi.\\nTrường hợp 2: Với một khung chứa \"hoàn hảo\", bộ phâ n loại giống mèo đưa ra kết\\nquả chính xác y=1. Điều này cho thấy nếu bộ phát hi ện mèo có thể đưa ra khung\\nchứa chính xác hơn, thì kết quả tổng thể của toàn h ệ thống sẽ được cải thiện.\\nTrong trường hợp này bộ phát hiện mèo có lỗi.\\nBằng cách phân tích các ảnh bị phân loại sai trên t ập phát triển, bạn có thể quy lỗi\\nchính xác cho một thành phần. Điều này cho phép bạn  ước tính tỉ lệ lỗi cho từng\\nthành phần của pipeline, từ đó quyết định thành phầ n cần tập trung khắc phục.\\n104'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 105}, page_content='55. Trường hợp tổng quát của việc quy lỗi\\nĐây là những bước tổng quát cho việc quy lỗi. Giả s ử một pipeline có ba thành phần\\nA, B và C; trong đó A cung cấp thông tin trực tiếp cho B, và B cung cấp thông tin\\ntrực tiếp cho C.\\nVới từng lỗi của hệ thống trên tập phát triển:\\n1. Thử điều chỉnh thủ công kết quả đầu ra ở A cho \" hoàn hảo\" (ví dụ, một khung\\nchứa hình mèo \"hoàn hảo\"), và sau đó tiến hành chạy  thuật toán cho pipeline\\ngồm có B và C với đầu ra này. Nếu thuật toán trả về  kết quả cuối cùng chính xác,\\nđiều đó chỉ ra rằng, thuật toán sẽ cho ra kết quả c hính xác nếu A trả về kết quả\\ntốt hơn. Vậy ta có thể quy lỗi cho A. Nếu không, ta  sẽ kiểm chứng thêm ở bước 2.\\n2. Thử điều chỉnh thủ công kết quả đầu ra ở công đo ạn B cho \"hoàn hảo\". Nếu thuật\\ntoán cho ra kết quả đầu ra cuối cùng chính xác, ta có thể quy lỗi cho B. Ngược lại,\\nta tiến hành bước 3.\\n3. Quy lỗi cho thành phần C.\\nChúng ta hãy cùng tìm hiểu một ví dụ phức tạp hơn s au đây:\\nXe tự lái của bạn sử dụng pipeline như trên. Bạn sẽ  sử dụng kỹ thuật phân tích lỗi\\ntừng phần như thế nào để quyết định (những) thành p hần nào cần tập trung cải\\nthiện?\\nBạn có thể gọi tên ba thành phần trong hệ thống là A, B, C tương ứng với các chức\\nnăng như sau:\\nA: Phát hiện xe hơi\\n105'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 106}, page_content='B: Phát hiện người đi bộ \\nC: Hoạch định đường đi cho xe\\nVới hệ thống xe tự hành mô tả như trên, giả sử bạn kiểm tra xe của bạn trên một\\ncung đường kín và xác định trường hợp nào xe chọn h ướng bẻ lái giật nhiều hơn so\\nvới một người lái có kinh nghiệm điều khiển. Trong lĩnh vực lái xe tự động, một\\ntrường hợp như thế thường được gọi là \"tình huống\".  Bạn cần thực hiện:\\n1. Thử điều chỉnh thủ công kết quả đầu ra của thành  phần A (phát hiện xe hơi) sao\\ncho \"hoàn hảo\" (ví dụ, cho xe biết vị trí của những  chiếc xe khác). Sau đó tiếp tục\\nchạy phần còn lại của pipeline gồm có B, C, nhưng c ho phép C (hoạch định đường\\nđi) sử dụng đầu ra đã hoàn hảo của A. Nếu thuật toá n hoạch định đường đi cho\\nxe tốt hơn, điều đó cho thấy rằng, kết quả cuối cùn g của thuật toán tự lái sẽ được\\ncải thiện nếu mà A trả về kết quả tốt hơn. Như vậy,  bạn có thể quy lỗi cho A. Nếu\\nkhông, ta tiếp tục bước 2.\\n2. Thử điều chỉnh thủ công kết quả đầu ra ở công đo ạn B (phát hiện người đi bộ) cho\\n\"hoàn hảo\". Nếu thuật toán cho kết quả đầu ra cuối cùng chính xác, ta có thể quy\\nlỗi cho B. Ngược lại, ta tiến hành bước 3.\\n3. Quy lỗi cho thành phần C.\\nCác thành phần của một mô hình học máy dạng pipelin e nên được sắp xếp theo Đồ\\nthị có hướng không chu trình (Directed Acyclic Grap h - DAG), nghĩa là bạn có thể\\ntính toán chúng theo thứ tự cố định từ trái sang ph ải nào đó, và các thành phần sau\\nchỉ nên phụ thuộc vào đầu ra của các thành phần trư ớc đó. Miễn là việc xâu chuỗi\\ncác thành phần theo thứ tự A->B->C tuân thủ theo qu y tắc DAG, thì việc phân tích\\nlỗi sẽ diễn ra tốt đẹp. Bạn có thể nhận được các kế t quả hơi khác nhau nếu hoán\\nchuyển vị trí của A và B cho nhau như sau:\\nA: Phát hiện người đi bộ (trước đây là Phát hiện xe )\\nB: Phát hiện xe (trước đây là Phát hiện người đi bộ )\\nC: Hoạch định đường đi cho xe\\nNhưng các kết quả của việc phân tích lỗi sẽ vẫn hợp  lệ và cho ta định hướng tới\\nnhững thành phần nào cần tập trung cải thiện.\\n106'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 107}, page_content='56. Phân tích lỗi từng phần và so sánh với chất\\nlượng mức con người\\nThực hiện phân tích lỗi của thuật toán học giống vớ i việc sử dụng khoa học dữ liệu\\nphân tích lỗi của hệ thống học máy để biết chính xá c những việc cần làm kế tiếp. Cơ\\nbản nhất, phân tích lỗi từng phần sẽ cho ta biết đư ợc chất lượng của (những) phần\\nnào cần được cải thiện.\\nGiả sử bạn có bộ dữ liệu về khách hàng mua đồ trên một trang mạng. Một nhà khoa\\nhọc dữ liệu có thể có rất nhiều cách khác nhau để p hân tích dữ liệu đó. Người đó có\\nthể đưa ra nhiều kết luận khác nhau như có nên tăng  giá, giá trị vòng đời khách\\nhàng đạt được thông qua các chiến dịch tiếp thị khá c nhau, v.v. Không có một việc\\nphân tích dữ liệu \"chuẩn mực\" nào, và có thể có rất  nhiều kết luận hữu ích có thể rút\\nra. Tương tự, không chỉ có một cách \"chuẩn mực\" cho  việc thực hiện phân tích lỗi.\\nThông qua các chương này bạn đã học được những cách  phổ biến nhất để rút ra\\nnhững nhận định chính xác về hệ thống học máy của b ạn, nhưng bạn cũng nên thử\\nnghiệm những phương pháp phân tích lỗi khác.\\nChúng ta hãy quay trở lại ứng dụng xe tự lái, trong  đó thuật toán phát hiện xe đưa\\nra vị trí (có thể có thêm vận tốc) của những chiếc xe gần đó, thuật toán phát hiện\\nngười đi bộ đưa ra vị trí của người đi bộ gần đó, v à hai đầu ra này cuối cùng được sử\\ndụng để hoạch định đường đi cho xe.\\nĐể kiểm tra lỗi pipeline này, thay vì tuân thủ nghi êm ngặt quy trình đã thấy trong\\nchương trước, bạn nên đặt những câu hỏi như:\\n1. Cách biệt về khả năng xác định xe giữa thuật toá n và con người là bao xa?\\n2. Cách biệt về khả năng phát hiện người đi bộ giữa  thuật toán và con người là bao\\nxa?\\n3. Cách biệt giữa khả năng của toàn hệ thống và con  người tới cỡ nào? Ở đây, chất\\nlượng của con người được giả sử là cách con người t ính đường đi cho xe chỉ dựa\\nvào kết quả đầu ra từ hai thành phần trước đó trong  pipeline (thay vì dựa vào\\nhình ảnh camera). Nói cách khác, với cùng thông tin  đầu vào, khả năng ước lượng\\nđường đi của thuật toán so với con người sẽ như thế  nào?\\n107'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 108}, page_content='Nếu bạn thấy rằng một trong những thành phần này th ua xa chất lượng mức con\\nngười, thì bây giờ bạn biết phần nào cần được cải t hiện. Hãy tập trung vào việc cải\\nthiện chất lượng của phần đó.\\nNhiều quy trình phân tích lỗi hoạt động tốt nhất kh i chúng ta cố gắng tự động hóa\\nmột thứ gì đó mà con người có thể làm, do đó có thể  so sánh với con người. Hầu hết\\ncác ví dụ trước của chúng ta ngầm giả định điều này . Nếu bạn đang xây dựng một\\nhệ thống học máy trong đó đầu ra hoặc một số thành phần trung gian đang làm\\nnhững việc mà thậm chí con người không thể làm tốt,  thì một trong số những quy\\ntrình này sẽ không được áp dụng.\\nĐây là một thuận lợi của việc giải quyết các vấn đề  mà con người có thể giải quyết--\\nbạn có các công cụ mạnh mẽ để phân tích lỗi, do đó bạn có thể ưu tiên các công\\nviệc trong nhóm một cách hiệu quả hơn.\\n108'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 109}, page_content='57. Phát hiện một pipeline học máy bị lỗi\\nNếu mỗi thành phần đơn lẻ trong pipeline học máy củ a bạn đều hoạt động ở chất\\nlượng mức con người hoặc gần mức con người, nhưng p ipeline tổng thể lại kém xa\\nmức con người thì sao? Điều này thường có nghĩa là pipeline có lỗi và cần được thiết\\nkế lại. Việc phân tích lỗi có thể giúp bạn nhận địn h liệu bạn có cần thiết kế lại\\npipeline của mình.\\nTrong chương trước, chúng ta đã đặt câu hỏi liệu mỗ i trong số ba thành phần có ở\\nchất lượng mức con người. Giả sử câu trả lời cho cả  ba câu hỏi là có. Điều đó có\\nnghĩa là:\\n1. Thành phần Phát hiện xe hơi đạt chất lượng (xấp xỉ) mức con người trong việc\\nphát hiện xe hơi từ ảnh camera.\\n2. Thành phần Phát hiện người đi bộ đạt chất lượng (xấp xỉ) mức con người trong\\nviệc phát hiện xe hơi từ ảnh camera.\\n3. So sánh với một người phải lập kế hoạch đường đi ch o xe khi chỉ dựa trên đầu ra\\ncủa hai thành phần pipeline trước đó (thay vì được tiếp cận với hình ảnh từ\\ncamera) , thành phần Lập kế hoạch có chất lượng ở mức tương  đương.\\nTuy nhiên, chiếc xe tự lái tổng thể của bạn lại hoạ t động kém hơn chất lượng mức\\ncon người một cách rõ rệt. Có nghĩa là, con người đ ược tiếp cận hình ảnh từ camera\\ncó thể dự tính những đường đi tốt hơn nhiều cho xe.  Bạn có thể rút ra kết luận gì?\\nKết luận khả dĩ duy nhất là pipeline học máy đã bị lỗi. Trong trường hợp này, thành\\nphần Lên kế hoạch đã hoạt động ở mức tốt nhất có th ể với những đầu vào của nó ,\\nnhưng đầu vào không chứa đủ thông tin. Bạn nên tự h ỏi liệu những thông tin nào\\nkhác, ngoài đầu ra của hai thành phần pipeline trướ c, là cần thiết cho việc lên kế\\nhoạch đường đi thật tốt cho xe tự lái. Nói cách khá c, những thông tin nào mà một\\nngười lái xe có kinh nghiệm cần đến?\\nVí dụ, giả sử bạn nhận ra rằng người lái xe cũng cầ n biết vị trí của vạch kẻ làn\\nđường. Điều này gợi ý rằng bạn nên thiết kế lại pip eline như sau:\\n109'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 110}, page_content='Cuối cùng, nếu bạn không nghĩ rằng pipeline hoàn ch ỉnh sẽ đạt chất lượng mức con\\nngười, ngay cả khi mỗi thành phần đơn lẻ đạt chất l ượng mức con người (nhớ rằng\\nbạn đang so sánh với một người được cung cấp cùng m ột đầu vào như các thành\\nphần), có nghĩa là pipeline có lỗi và cần được thiế t kế lại.\\nGHI CHÚ:\\n[18] Trong ví dụ về xe tự hành ở trên, theo lý thuy ết ta có thể giải quyết vấn đề\\nbằng cách cũng cho hình ảnh thô từ camera vào thành  phần lên kế hoạch. Tuy\\nnhiên, điều đó sẽ vi phạm nguyên tắc thiết kế \"Tính  đơn giản của tác vụ\" đã được\\ntrình bày ở Chương 51, vì thành phần lên kế hoạch đ ường đi giờ đây cần có đầu vào\\nlà ảnh thô và có một tác vụ rất phức tạp để giải qu yết. Thế nên thêm một thành\\nphần Phát hiện giải phân cách là một lựa chọn tốt h ơn -- giúp lấy thêm những thông\\ntin quan trọng vốn thiếu về làn đường cho khối lên kế hoạch đường đi, đồng thời bạn\\ncũng tránh được việc làm bất cứ mô-đun nào trở nên quá phức tạp để xây\\ndựng/huấn luyện.\\n110'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 111}, page_content='Phần 10: Tổng kết\\n111'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 112}, page_content='58. Xây dựng một biệt đội siêu anh hùng - Hãy\\nđể đồng đội của bạn đọc điều này\\nChúc mừng bạn đã hoàn thành quyển sách này!\\nTrong chương 2, chúng ta đã nói về việc quyển sách này có thể giúp bạn trở thành\\nsiêu anh hùng trong nhóm của bạn.\\nĐiều duy nhất tuyệt vời hơn trở thành một siêu anh hùng là trở thành một phần của\\nmột biệt đội siêu anh hùng. Tôi hy vọng bạn sẽ giới  thiệu bản sao của quyển sách\\nnày cho bạn bè và đồng đội của bạn và tạo ra những siêu anh hùng khác.\\n112'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 113}, page_content='Bảng thuật ngữ Anh Việt\\n113'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 114}, page_content=\"A-D\\nEnglish Tiếng Việt Thảo luận tại\\naccuracy độ chính xác\\nactivation function hàm kích hoạt\\nalgorithm's performance chất lượng của thuật toán\\navoidable bias độ chệch tránh được\\nartificial data synthesis tổng hợp dữ liệu nhân tạo\\nbackground noise nhiễu nền 193\\nbenchmark đánh giá xếp hạng #87\\nbias (bias as variance) độ chệch #125\\nbig data big data\\nBlackbox dev set tập phát triển Blackbox #162\\nbounding box khung chứa #353\\nclassifier bộ phân loại\\nconstrain ràng buộc\\ncross validation kiểm định chéo\\ndata mismatch dữ liệu không tương đồng\\ndeep learning học sâu\\ndevelopment set tập phát triển\\ndev set tập phát triển\\ndev set performancechất lượng trên tập phát\\ntriển\\ndistribution phân phối\\ndomain adaptation thích ứng miền\\ndropout\\n114\"), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 115}, page_content='E-L\\nEnglish Tiếng Việt Thảo luận tại\\nearly stopping dừng sớm\\nend-to-end đầu-cuối #334\\nerror analysis phân tích lỗi\\nerror rate tỉ lệ lỗi\\nevaluation metric phép đánh giá\\nexample mẫu\\nEyeball dev set Tập phát triển Eyeball #162\\nF1 score chỉ số F1\\nfalse negative âm tính giả\\nfalse positive dương tính giả\\nfeature đặc trưng\\nfit khớp #391\\ngradient descent hạ gradient #87, #389\\nhand-engineering thiết kế thủ công\\nheuristic thực nghiệm\\nhidden unit nút ẩn\\nhuman-level performancechất lượng mức con\\nngười#259 , #287\\nhyperparameter siêu tham số\\niteration vòng lặp\\nlayer tầng\\nlearning curve đồ thị quá trình học #87\\nlearning algorithm thuật toán học\\nlinear regression hồi quy tuyến tính\\nlogistic regression hồi quy logistic\\n115'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 116}, page_content='M-R\\nEnglish Tiếng Việt Thảo luận tại\\nmachine learning học máy\\nmetric phép đo\\nmisclassified bị phân loại nhầm\\nmislabeledbị gán nhãn\\nnhầm\\nmodel mô hình\\nmultiple-number evaluation metric phép đo đa trị\\nmultitask learning học đa nhiệm\\nnegative sample/example mẫu âm\\nneural network mạng nơ-ron #87 #115\\noptimizing metric phép đo để tối ưu #87\\noverfit quá khớp #87, #391\\nperformance chất lượng #259\\nplateau (danh từ) vùng nằm ngang\\nplateau (động từ) nằm ngang\\npipeline pipeline #334\\npositive sample/example mẫu dương\\nprecision precision\\nrecall recall\\nrecognition nhận dạng\\nregularization/regularize điều chuẩn #401\\nreinforcement learning học tăng cường\\nreward function hàm điểm thưởng\\nrunning time thời gian chạy\\n116'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 117}, page_content='S-Z\\nEnglish Tiếng Việt Thảo luận tại\\nsampling with replacement lấy mẫu có hoàn lại #251\\nsampling without replacement lấy mẫu không hoàn lại #251\\nsatisficing metric phép đo thỏa mãn #87\\nscroing function hàm tính điểm\\nsentiment classification phân loại cảm xúc\\nsingle-number evaluation\\nmetricphép đo đơn trị\\nspam email email rác\\nsupervised learning học có giám sát\\ntest set tập kiểm tra\\ntest set performance chất lượng trên tập kiểm tra\\ntraining set tập huấn luyện\\ntraining dev set tập phát triển huấn luyện\\ntraining set performancechất lượng trên tập huấn\\nluyện\\ntranscript bản ghi thoại #332\\ntranscribe phiên thoại\\ntrue negative âm tính thật\\ntrue positive dương tính thật\\ntune parameters điều chỉnh tham số\\nunavoidable bias độ chệch không tránh được\\nunderfit dưới khớp #87, #391\\nvariance (bias as variance) phương sai #125\\n117'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 118}, page_content='Lời Nhóm Dịch\\nSau hơn hai tháng kêu gọi và thực hiện việc dịch, c uốn sách đã nhận được sự tiếp\\nnhận nồng ấm từ độc giả. Rất nhiều thành viên đã th am gia dịch và giúp đỡ các vấn\\nđề kỹ thuật. Tới thời điểm này (28/12/2019), chúng tôi vui mừng thông báo cuốn\\nsách có thể được coi đã hoàn thành. Mọi sự thay đổi  nếu có đều có thể thực hiện\\nmột cách nhanh chóng.\\nDự án dịch sách này không thể thành công nếu không có  sự đóng góp của\\ncộng đồng.  Xin gửi lời cảm ơn tới Forum Machine Learning Cơ Bản  đã theo dõi và\\nủng hộ suốt quá trình dự án.\\nHy vọng quyển sách này sẽ trở thành một sổ tay Học Máy hữu ích cho các độc giả.\\nVà hy vọng đây sẽ là dự án đầu tiên đặt nền móng ch o các dự án cộng đồng tương\\ntự khác. Hiện tại, các thành viên trong nhóm đang t riển khai dự án thứ hai -- dịch\\nDive into Deep Learning -- Đắm mình vào Học Sâu . Nếu bạn đang đọc những dòng\\nnày và nghĩ mình có thể đóng góp, mời bạn tham gia đóng góp thực hiện.\\nThông tin chi tiết đóng góp các thành viên cho dự á n \"Machine Learning Yearning\" --\\n\"Khát khao học máy\". Các đóng góp dịch, phản biệt, hiệu đính được thống kê dựa\\ntrên tên tài khoản Github cùng đường dẫn tới các re po tương ứng.\\nGiai đoạn 1\\nĐây là giai đoạn dịch từ bản tiếng Anh sang bản tiế ng Việt lần đầu tiên. Bản dịch\\nnày phải đảm bảo ý nghĩa của bản dịch sát với bản g ốc, việc trau chuốt ngôn từ sẽ\\nđược làm kỹ hơn ở giai đoạn 2.\\n118'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 119}, page_content='ChươngThảo\\nluậnDịch Phản biện\\n1. #40 ngcthuong tiepvupsu\\n2. #54 ngcthuong tiepvupsu, SumoBBQ, sonvx\\n3. #90 quangnhat185 ngcthuong, tiepvupsu\\n4. #83 ngcthuongtiepvupsu, 1612628, SumoBBQ,\\nquangnhat185, lkhphuc, duythanhvn\\n5. #82 habom2310ngcthuong, tiepvupsu, SumoBBQ,\\n1612628, vudaoanhtuan\\n6.#91\\n#262quangnhat185,\\nngcthuongtiepvupsu, ngcthuong, SumoBBQ,\\n1612628, freeloneman\\n7. #70 lkhphuc tiepvupsu, ngcthuong, SumoBBQ\\n8. #80 khoapip ngcthuong, tiepvupsu, 1612628\\n9. #77 naml3i ngcthuong, tiepvupsu\\n10. #117 patrickphatnguyenngcthuong, damminhtien, xuantubk,\\n1612628\\n11. #150 tiepvupsu 1612628, sonvx, freeloneman\\n12. #113 tiena2cva kiemrong08, sonvx, tiepvupsu\\n13. #160 duythanhvn 1612628, naml3i, william-vu, thhung\\n14. #140 william-vu tiepvupsu, ngcthuong\\n15. #161 quangnhat185duythanhvn, william-vu, 1612628,\\nSumoBBQ, thhung\\n16. #164 rootonchairwilliam-vu, naml3i, tiepvupsu, 1612628,\\nSumoBBQ\\n17. #168 khoapipwilliam-vu, 1612628, ngcthuong,\\ntiepvupsu\\n18. #156 phamdinhkhanh tiepvupsu, khoapip, thhung, william-vu\\n19. #169 seanphan tiepvupsu, william-vu, ngcthuong\\n20. #172 tiepvupsu thhung, william-vu, 1612628\\n119'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 120}, page_content='ChươngThảo\\nluậnDịch Phản biện\\n21. #173 seanphan tiepvupsu\\n22. #181 william-vu tiepvupsu\\n23. #175 seanphantiepvupsu, duythanhvn, ngcthuong,\\nthhung\\n24. #192 seanphan phamdinhkhanh, ngcthuong\\n25. #195 naml3i ngcthuong, william-vu, tiepvupsu, sonvx\\n26. #193 seanphan william-vu, tiepvupsu\\n27. #211 thhung william-vu, tiepvupsu, sonvx\\n28. #234 quangnhat185 sonvx, tiepvupsu, khoapip\\n29. #225 phamdinhkhanh tiepvupsu, 1612628\\n30. #228 khoapiptiepvupsu, 1612628, william-vu,\\nSumoBBQ, ngcthuong\\n31. #248 thhung tiepvupsu\\n32. #251 william-vu1612628, sonvx, SumoBBQ, naml3i,\\nngcthuong\\n33. #247 honghanhhtiepvupsu, 1612628, naml3i,\\nphamdinhkhanh\\n34. #254 seanphantiepvupsu, thhung, naml3i, lkhphuc,\\nngcthuong\\n35. #276 duythanhvn lkhphuc, ngcthuong, hungvminh\\n36. #273 rootonchair lkhphuc, tiepvupsu, william-vu\\n37. #279 seanphanquangnhat185, sonvx, 1612628,\\nngcthuong\\n38. #302 honghanhh tiepvupsu, phamdinhkhanh\\n39. #258 honghanhh naml3i, lkhphuc, tiena2cva, tiepvupsu\\n120'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 121}, page_content='ChươngThảo\\nluậnDịch Phản biện\\n40. #282 quangnhat185seanphan, rootonchair, ngcthuong,\\nhonghanhh, tiepvupsu\\n41. #278 lkhphuc sonvx, ngcthuong, tiepvupsu\\n42. #298 naml3i tiepvupsu\\n43. #296 seanphan tiepvupsu, ngcthuong, rootonchair\\n44.#301 ,\\n#312honghanhh,\\ntiepvupsutiepvupsu\\n45. #304 tiena2cvarootonchair, tiepvupsu, ngcthuong,\\n1612628, lkhphuc\\n46. #329 lkhphuc sonvx, ngcthuong, tiepvupsu\\n47.#333 ,\\n#336rootonchair,\\nquangnhat185tiepvupsu\\n48. #360 nerophung lkhphuc, tiepvupsu\\n49. #340 tiepvupsu lkhphuc, rootonchair\\n50. #342 tiepvupsuwilliam-vu, lkhphuc, rootonchair,\\n1612628\\n51. #349 tiepvupsuwilliam-vu, lkhphuc, ngcthuong,\\nnmdang\\n52. #363 khoapip tiepvupsu, lkhphuc, thhung\\n53. #355 lkhphuc tiepvupsu, rootonchair\\n54. #352 quangnhat185 tiepvupsu\\n55. #364 goldenretriever2015tiepvupsu, lkhphuc, nmdang,\\nngcthuong\\n56. #362 ffyyytt van-tienhoang, ngdthanhcs, tiepvupsu\\n57. #392 naml3i nmdang\\n58. #317 tuanbieber tiepvupsu\\nTổng hợp đóng góp dịch và phản biện giai đoạn một d ưới dạng biểu đồ sau.\\n121'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 122}, page_content='Mỗi chương được một hai bạn dịch chính sau đó các t hành viên khác đóng góp phản\\nbiện.\\nTrung bình mỗi chương có ba phản biện với tổng số 1 76 phản biện trên 58 chương\\nsách.\\nGiai đoạn 2\\nTrong giai đoạn này, các chương sẽ được trau chuốt hơn về mặt ngôn từ, cách diễn\\n122'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 123}, page_content='đạt.\\nChương Dịch Phản biện\\n1 - 4 nmdang tiepvupsu, ngcthuong, sonvx\\n5 - 8 ngdthanhcs tiepvupsu, ngcthuong\\n9 - 12 lkhphuc tiepvupsu, ngcthuong\\n13 - 16 nmdang tiepvupsu\\n17 - 19 thhung tiepvupsu\\n20 - 23 rootonchair tiepvupsu, ngcthuong\\n24 - 27 ngcthuong tiepvupsu, william-vu\\n28 - 32 nmdang samthehai, lkhphuc\\n33 - 35 ngcthuong lkhphuc, samthehai, tiepvupsu\\n36 - 39 lkhphuc tiepvupsu, samthehai\\n40 - 43 ngcthuong lkhphuc, rootonchair\\n44 - 46 rootonchair lkhphuc\\n47 - 49 khoapiptiepvupsu, lkhphuc, ngcthuong,\\nrootonchair\\n50 - 52 tiepvupsu samthehai, quangnhat185, ngcthuong\\n53 - 55 duythanhvn quangnhat185, ngcthuong, tiepvupsu\\n56 - 58 tiepvupsu ngcthuong, lkhphuc\\nGiai đoạn hai được hoàn thành với 16 bài hiệu đính (mỗi bài từ 3 - 4 chương) và 35\\nđóng góp phản biện. Tính trung bình, có 2.2 phản bi ện trên một hiệu đính. Chi tiết\\nđóng góp như sau\\n123'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 124}, page_content='Các đóng góp khác\\nNgoài các đóng góp về bài dịch, phản biện, cũng như  hiệu đính tuyệt vời nêu trên,\\ncũng không thể không nêu những đóng góp thầm lặng k hác cho đề tài như\\n124'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 125}, page_content='STT Nội dung Đóng góp\\n1Định dạng thư mục, tệp\\nhướng dẫntiepvupsu, xuantubk\\n2Sao chép và định dạng bản\\ndịchduythanhvn, tiepvupsu, ngcthuong\\n3Sao chép và chỉnh sửa hình\\nvẽsamthehai, quangnhat185, rootonchair,\\nduythanhvn\\n4Sao chép và chỉnh sửa bảng\\nbiểutiena2cva\\n5 Tạo tệp pdf cho bản đầy đủquangnhat185, rootonchair, duythanhvn,\\ntiepvupsu\\n6 Thiết kế bìa bản tiếng Việt duythanhvn\\n7Tổng hợp nội dung, lời cảm\\nơnngcthuong, tiepvupsu\\nTên các thành viên\\nChi tiết tên và tài khoản github các thành viên có đóng góp cho đề tài không theo\\nthứ tự nào cả.\\n125'), Document(metadata={'source': 'datasets/Machinelearningyearning-Vi.pdf', 'page': 126}, page_content=' GitHub ID Họ & Tên\\ntiepvupsu Vũ Hữu Tiệp\\nngcthuong Nguyễn Cảnh Thướng\\nlkhphuc Lê Khắc Hồng Phúc\\nsonvx Vũ Xuân Sơn\\nrootonchair Phạm Hồng Vinh\\nwilliam-vu Vũ Đình Quyền\\nSumoBBQ Phạm Chí Thành\\nquangnhat185 Nguyễn Lê Quang Nhật\\nseanphan Phan Duy Khánh\\nduythanhvn Đoàn Võ Duy Thanh\\nnmdang Đặng Ngọc Minh\\nkhoapip Ngô Thế Anh Khoa\\nhonghanhh Trần Thị Hồng Hạnh\\ntiena2cva Ngọc Việt Tiến\\nxuantubk Nguyễn Xuân Tú\\n1612628\\nphamdinhkhanh\\nthhung\\nnaml3i\\nvudaoanhtuan\\nngdthanhcs\\ndamminhtien\\nvan-tienhoang\\nkiemrong08\\nfreeloneman\\n126')]\n"
     ]
    }
   ],
   "source": [
    "print(openPdfFile('datasets/Machinelearningyearning-Vi.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7857fd88",
   "metadata": {},
   "source": [
    "# Chia nhỏ ra thành từng đoạn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b40cfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(docs):\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        chunk_size=512, # Tách 512 độ dài \n",
    "        chunk_overlap=100, # Lấy 100 độ dài ở đằng trước\n",
    "        separator=\"\\n\", # Tách theo dòng\n",
    "        length_function=len # hàm tính độ dài. dùng len() để tính theo kí tự\n",
    "    )\n",
    "    texts = text_splitter.split_documents(docs)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6388dc",
   "metadata": {},
   "source": [
    "# Hàm Embedding Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c5bf4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddingText(text):\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-nomic-embed-text-v1.5\",\n",
    "        input=text,\n",
    "        encoding_format=\"float\",\n",
    "        \n",
    "    )\n",
    "\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579b752c",
   "metadata": {},
   "source": [
    "# Đọc dữ liệu từ các file và thêm vào cơ sở dữ liệu\n",
    "\n",
    "* ### Bước 1: Lấy tên các file pdf đang có ở trong folder\n",
    "* ### Bước 2: Đọc file pdf và chia nhỏ thành từng đoạn\n",
    "* ### Bước 3: Embedding\n",
    "* ### Bước 4: Thêm vào cơ sở dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13227ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bước 1: \n",
    "\n",
    "# Tên thư mục cần kiểm tra\n",
    "folder_name = 'datasets'\n",
    "faiss_name = \"faiss_index.index\"\n",
    "# Khởi tạo danh sách để chứa các file PDF\n",
    "pdf_files = []\n",
    "\n",
    "# Kiểm tra xem thư mục có tồn tại không\n",
    "if os.path.exists(folder_name) and os.path.isdir(folder_name):\n",
    "    # Duyệt qua tất cả các file trong thư mục\n",
    "    for file in os.listdir(folder_name):\n",
    "        # Kiểm tra nếu file có phần mở rộng là .pdf\n",
    "        if file.lower().endswith('.pdf'):\n",
    "            pdf_files.append(f\"{folder_name}/{file}\")\n",
    "\n",
    "# Bước 2:\n",
    "\n",
    "documents = []\n",
    "for pdf_file in pdf_files:\n",
    "    document = text_split(openPdfFile(pdf_file))\n",
    "    documents = documents + document\n",
    "\n",
    "# for document in documents:\n",
    "#     print(document.page_content)\n",
    "\n",
    "# Bước 3:\n",
    "embedding_vectors = [embeddingText(doc.page_content) for doc in documents]\n",
    "embedding_vectors_np = np.array(embedding_vectors).astype(np.float32)\n",
    "\n",
    "# Bước 4:\n",
    "\n",
    "dim = embedding_vectors_np.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(embedding_vectors_np)\n",
    "faiss.write_index(index, faiss_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853e05d5",
   "metadata": {},
   "source": [
    "# Tìm kiếm trong cơ sở dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef6194d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def faiss_query(question, k=7):\n",
    "    index = faiss.read_index(faiss_name)\n",
    "    query_embedding =  embeddingText(question)\n",
    "    query_embedding_np = np.array([query_embedding]).astype(np.float32)\n",
    "    _, indices = index.search(query_embedding_np, k)\n",
    "    contexts = [documents[i] for i in indices[0]]\n",
    "    content = \"\"\n",
    "    for context in contexts:\n",
    "        content+=context.page_content + \"\\n\\n\"\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6536313d",
   "metadata": {},
   "source": [
    "# LLM Tạo câu trả lời"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18cffc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_gemini(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen3-0.6b\",\n",
    "        messages=messages,\n",
    "        temperature=0.3,\n",
    "        \n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d74e5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        'content': \"Giới thiệu về học tăng cường trong AI\"\n",
    "    }\n",
    "]\n",
    "\n",
    "question = messages[-1]['content']\n",
    "content = faiss_query(question,7)\n",
    "\n",
    "system_prompt = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": f\"\"\"Bạn là một trợ lí ảo của Nguyễn Ngọc An. Tên của bạn là 13Bee.\n",
    "    Dựa vào những kiến thức dưới đây để trả lời:\n",
    "    '{content}'\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "\n",
    "messages = [system_prompt] + messages\n",
    "# print(messages)\n",
    "# print(chat_with_gemini(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6034a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'độ cao có nhiều biến động đối với hành khách không,  cùng nhiều yếu tố khác. Thiết\\nkế hàm điểm thưởng tốt là một việc không hề dễ dàng .\\nVới một hàm điểm thưởng R(T) cho trước, công việc của thuật toán học tăng cường\\nlà điều khiển trực thăng sao cho nó đạt được điểm t hưởng cao nhất max R(T). Tuy\\nnhiên, thuật toán học tăng cường có nhiều phép xấp xỉ và có thể sẽ không thànhT\\n82\\n\\nHệ âm vị, một phát kiến của ngành ngôn ngữ học, là một biểu diễn không hoàn\\nhảo của âm thanh thoại. Trong những trường hợp mà h ệ âm vị là một xấp xỉ kém\\ncủa thực tế, áp đặt một thuật toán sử dụng biểu diễ n âm vị sẽ giới hạn chất lượng\\ncủa hệ thống tiếng nói.\\nCác thành phần được thiết kế thủ công này giới hạn chất lượng tiềm năng của hệ\\nthống tiếng nói. Tuy nhiên, việc sử dụng các thành phần được thiết kế thủ công\\ncũng có một vài ưu điểm:\\n\\nthể giúp giải quyết các vấn đề về phương sai, nhưng  nó cũng có thể làm tăng độ\\nchệch. Việc giảm một ít số lượng các đặc trưng (giả  sử từ 1.000 xuống 900 đặc\\ntrưng) dường như không có ảnh hưởng lớn đến độ chệc h. Việc giảm đáng kể số\\nđặc trưng (giả sử từ 1.000 xuống còn 100 đặc trưng,  hay giảm 10 lần) nhiều khả\\nnăng mang lại tác dụng đáng kể, miễn là bạn không l oại trừ quá nhiều các đặc\\ntrưng hữu ích. Trong học sâu hiện đại, khi dữ liệu dồi dào, đã có những thay đổi từ\\n\\nkhác nhau tùy thuộc vào vị trí ngôi nhà.\\nCHÚ THÍCH:\\n[13] Có một cách để giải quyết vấn đề dữ liệu Detro it không nhất quán với dữ liệu\\ncủa Thành phố New York, đó là thêm một đặc trưng bi ểu diễn thành phố. Cho một\\nđầu vào x mà có chứa thêm đặc trưng biểu diễn thành  phố, giá trị mục tiêu y bây giờ\\nkhông còn mập mờ nữa. Tuy nhiên, trong thực tế tôi không thấy điều này được thực\\nhiện thường xuyên.\\n69\\n\\ntừ cùng một phân phối. Nhưng cũng quan trọng khi hi ểu rằng phân bố tập huấn\\nluyện và phát triển/kiểm tra khác nhau sẽ dẫn tới m ột vài thách thức đặc biệt.\\nCHÚ THÍCH:\\n[11] Có một vài nghiên cứu khoa học về việc huấn lu yện và kiểm tra trên các phân\\nphối khác nhau. Những ví dụ bao gồm \"thích ứng miền \", \"học chuyển tiếp\" và \"học\\nđa nhiệm\". Tuy nhiên vẫn còn một khoảng cách lớn gi ữa lý thuyết và thực hành. Nếu\\nbạn huấn luyện trên bộ dữ liệu A và kiểm tra trên m ột vài kiểu dữ liệu rất khác B,\\n\\ncho bước hoạch định lộ trình của chiếc xe. Trong đó  có nhiều thuật toán không cần\\nphải huấn luyện.\\nNgược lại, hướng tiếp cận đầu-cuối có thể cố gắng l ấy đầu vào là những tín hiệu từ\\ncảm biến và trực tiếp trả về hướng bẻ lái:\\nMặc dù phương pháp học đầu-cuối đã đạt được nhiều k ết quả tốt, nó không luôn là\\nhướng đi tốt nhất. Ví dụ, phương pháp nhận dạng giọ ng nói đầu-cuối đạt kết quả tốt\\nnhưng tôi không tin tưởng việc sử dụng học đầu-cuối  cho xe tự lái. Những chương kế\\ntiếp sẽ giải thích tại sao.\\n88\\n\\nCHÚ THÍCH:\\n[2] Trên lý thuyết, ta cũng có thể kiểm tra xem một  thay đổi trong thuật toán có tạo\\nra sự khác biệt đáng kể về mặt thống kê trên tập ph át triển hay không. Trong thực\\ntế, hầu hết mọi người đều không quan tâm đến điều n ày (trừ khi họ muốn công bố\\ncác các bài báo khoa học). Tôi thường thấy các bài kiểm định thống kê không mấy\\nhữu ích trong việc đánh giá tiến độ phát triển.\\n16\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f036f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user wants an introduction to reinforcement learning in AI. Let me start by recalling what I know from the previous information.\n",
      "\n",
      "First, the main points from the provided text: Reinforcement learning (RL) is about training agents to make decisions that maximize cumulative rewards. It's different from supervised and unsupervised methods because it learns through interaction with an environment. The text mentions that RL has a reward function and aims to maximize R(T), which is the total reward.\n",
      "\n",
      "Then there's something about the complexity of RL algorithms, like overfitting, which might be relevant here. Also, the mention of the \"hệ âm vị\" (audio version) as a method for improving systems when it doesn't fully represent real-world data. But I need to check if that's part of the introduction or just additional info.\n",
      "\n",
      "The user also provided some examples from previous interactions where they mentioned challenges with data consistency and different training distributions. Maybe I should connect RL with these concepts, like how RL can handle inconsistent data by using a reward function that adapts over time.\n",
      "\n",
      "I should structure the intro to cover: definition, key aspects (reward maximization, interaction), challenges (overfitting, system limitations), and mention the methods used in AI like RL. Also, include examples from the text about different approaches (like reinforcement learning for autonomous vehicles) to make it concrete.\n",
      "</think>\n",
      "\n",
      "**Giới thiệu về học tăng cường trong AI**\n",
      "\n",
      "Học tăng cường (Reinforcement Learning – RL) là một lĩnh vực của AI được phát triển dựa trên nguyên tắc **\"luyện tập thông qua tương tác với môi trường\"**, nơi hành động của con người hoặc hệ thống được đánh giá bằng kết quả. Trong đó, mục tiêu là tối ưu hóa **điểm thưởng** (reward) để đạt được hiệu quả cao nhất trong các hoạt động cụ thể.\n",
      "\n",
      "### Đặc điểm chính của học tăng cường:\n",
      "1. **Khả năng điều chỉnh**:  \n",
      "   Hành vi được dạy thông qua việc nhận thức và phản hồi từ môi trường, giúp hệ thống tự thích nghi theo thời gian.\n",
      "\n",
      "2. **Tối ưu hóa mục tiêu**:  \n",
      "   Một thuật toán học tăng cường cần thiết để **tối đa hóa hàm mục tiêu** (R(T)), tức là giá trị tổng cộng của các hành động được thực hiện.\n",
      "\n",
      "3. **Khó khăn và thách thức**:  \n",
      "   - **Phép xấp xỉ**: Các phương pháp học tăng cường có thể gặp khó khăn trong việc tránh overfitting, dẫn đến sự sai lầm nếu không kiểm soát tốt.\n",
      "   - **Môi trường không hoàn hảo**: HỆ THỐNG AI có thể bị giới hạn bởi các yếu tố như dữ liệu không chính xác hoặc môi trường không đồng nhất.\n",
      "\n",
      "4. **Phân tích và cải tiến**:  \n",
      "   Các nghiên cứu đã thử nghiệm cách đánh giá hiệu quả của học tăng cường, ví dụ như kiểm tra tính ổn định (statistical validation) để đảm bảo kết quả phù hợp với thực tế.\n",
      "\n",
      "### Ví dụ minh họa:\n",
      "- Trong lĩnh vực tự lái xe, học tăng cường được áp dụng để tối ưu hóa hành động điều khiển dựa trên tín hiệu từ cảm biến và phản hồi người驾驶.\n",
      "- Một nghiên cứu thử nghiệm cho thấy việc sử dụng hệ thống AI với học tăng cường có thể cải thiện độ chính xác trong các tình huống phức tạp hơn khi dữ liệu không đầy đủ.\n",
      "\n",
      "Học tăng cường là một công cụ mạnh mẽ giúp AI thích nghi, học hỏi và đạt được hiệu quả cao trong nhiều lĩnh vực khác nhau.\n"
     ]
    }
   ],
   "source": [
    "print(chat_with_gemini(messages))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
